(** Pipeline Integration Module
    
    This module provides the complete L0-L1 integration with proper 
    module structure and end-to-end document processing.
*)

open Types

(* Import the individual layer implementations *)
module L0 = L0_v25
module L1 = L1_v25

(** Complete pipeline state *)
type pipeline_state = {
  l0_state : L0.v25_lexer_state;
  l1_state : L1.v25_expander_state;
  document_position : position;
  processed_chunks : int;
}

(** Document processing result *)
type document_result = {
  original_text : string;
  lexed_tokens : Types.token array;
  expanded_tokens : Types.token array;
  macros_used : string list;
  processing_time_us : float;
  cache_hits : int;
  cache_misses : int;
}

(** Pipeline configuration *)
type pipeline_config = {
  chunk_size : int;        (* Max bytes per chunk *)
  max_fuel : int;          (* Max expansion fuel *)
  enable_caching : bool;   (* Enable/disable caches *)
  debug_mode : bool;       (* Verbose logging *)
}

(** Default pipeline configuration *)
let default_config = {
  chunk_size = 4096;
  max_fuel = 1000;
  enable_caching = true;
  debug_mode = false;
}

(** Initialize pipeline state *)
let init_pipeline config =
  let l0_state = L0.initial_state () in
  let l0_key = { L0.chunk_id = 0; hash = 0L } in
  let l1_state = L1.initial_state l0_key in
  {
    l0_state;
    l1_state;
    document_position = { byte_offset = 0; line = 1; column = 0 };
    processed_chunks = 0;
  }

(** Process a complete LaTeX document through L0-L1 pipeline *)
let process_document config document_text =
  if config.debug_mode then
    Printf.printf "Processing document (%d chars)...\n" (String.length document_text);
  
  let start_time = Unix.gettimeofday () in
  let cache_hits = ref 0 in
  let cache_misses = ref 0 in
  
  (* Step 1: L0 Lexing *)
  let l0_start = Unix.gettimeofday () in
  let bytes = Bytes.of_string document_text in
  let (lexed_tokens, l0_state) = L0.lex_chunk bytes in
  let l0_time = (Unix.gettimeofday () -. l0_start) *. 1_000_000. in
  
  if config.debug_mode then
    Printf.printf "L0 lexing: %d tokens in %.0fŒºs\n" 
      (Array.length lexed_tokens) l0_time;
  
  (* Step 2: L1 Expansion *)
  let l1_start = Unix.gettimeofday () in
  let l0_key = { L0.chunk_id = l0_state.chunk_id; hash = Int64.of_int (Hashtbl.hash document_text) } in
  let l1_env = L1.initial_state l0_key in
  let delta = { 
    L1.unexpanded = lexed_tokens; 
    expanded = [||]; 
    macros_used = [] 
  } in
  
  let (expanded_result, l1_state) = L1.expand_delta ~fuel:config.max_fuel ~env:l1_env delta in
  let l1_time = (Unix.gettimeofday () -. l1_start) *. 1_000_000. in
  
  if config.debug_mode then
    Printf.printf "L1 expansion: %d -> %d tokens in %.0fŒºs\n" 
      (Array.length lexed_tokens) (Array.length expanded_result.expanded) l1_time;
  
  let total_time = (Unix.gettimeofday () -. start_time) *. 1_000_000. in
  
  {
    original_text = document_text;
    lexed_tokens;
    expanded_tokens = expanded_result.expanded;
    macros_used = expanded_result.macros_used;
    processing_time_us = total_time;
    cache_hits = !cache_hits;
    cache_misses = !cache_misses;
  }

(** Test the pipeline with a sample document *)
let test_pipeline_integration () =
  Printf.printf "=== PIPELINE INTEGRATION TEST ===\n";
  
  let test_document = {|
\documentclass{article}
\usepackage{amsmath}
\begin{document}
\section{Introduction}
This is a test of \LaTeX{} with \textbf{bold text} and math: $\alpha + \beta = \sum_{i=1}^n x_i$.

Here are some more macros: \textit{italic}, \emph{emphasis}, and symbols \gamma, \delta, \pi.

\subsection{More Content}
Some spacing: \quad and \qquad, plus dots: \ldots and \cdots.
\end{document}
|} in
  
  let config = { default_config with debug_mode = true } in
  
  try
    let result = process_document config test_document in
    
    Printf.printf "\n=== PIPELINE RESULTS ===\n";
    Printf.printf "Original text: %d characters\n" (String.length result.original_text);
    Printf.printf "Lexed tokens: %d\n" (Array.length result.lexed_tokens);
    Printf.printf "Expanded tokens: %d\n" (Array.length result.expanded_tokens);
    Printf.printf "Macros used: [%s]\n" (String.concat "; " result.macros_used);
    Printf.printf "Total processing time: %.0fŒºs (%.2fms)\n" 
      result.processing_time_us (result.processing_time_us /. 1000.);
    Printf.printf "Cache hits: %d\n" result.cache_hits;
    Printf.printf "Cache misses: %d\n" result.cache_misses;
    
    (* Verify key macro expansions *)
    let expanded_list = Array.to_list result.expanded_tokens in
    let has_latex = List.exists (function TText "LaTeX" -> true | _ -> false) expanded_list in
    let has_bold = List.exists (function TText "[bold]" -> true | _ -> false) expanded_list in
    let has_alpha = List.exists (function TText "Œ±" -> true | _ -> false) expanded_list in
    let has_dots = List.exists (function TText "..." -> true | _ -> false) expanded_list in
    
    Printf.printf "\nMacro expansion verification:\n";
    Printf.printf "  \\LaTeX{} -> LaTeX: %s\n" (if has_latex then "‚úÖ" else "‚ùå");
    Printf.printf "  \\textbf -> [bold]: %s\n" (if has_bold then "‚úÖ" else "‚ùå");
    Printf.printf "  \\alpha -> Œ±: %s\n" (if has_alpha then "‚úÖ" else "‚ùå");
    Printf.printf "  \\ldots -> ...: %s\n" (if has_dots then "‚úÖ" else "‚ùå");
    
    (* Performance analysis *)
    let chars_per_us = float (String.length test_document) /. result.processing_time_us in
    let claimed_time_4_43ms = 4430. in (* Œºs *)
    let performance_vs_claim = result.processing_time_us /. claimed_time_4_43ms in
    
    Printf.printf "\nPerformance analysis:\n";
    Printf.printf "  Processing speed: %.1f chars/Œºs\n" chars_per_us;
    Printf.printf "  vs 4.43ms claim: %.1fx %s\n" performance_vs_claim
      (if performance_vs_claim < 1. then "FASTER" else "SLOWER");
    
    let all_expansions_work = has_latex && has_bold && has_alpha && has_dots in
    let performance_reasonable = result.processing_time_us < claimed_time_4_43ms *. 2. in
    
    if all_expansions_work && performance_reasonable then begin
      Printf.printf "\nüéØ ‚úÖ PIPELINE INTEGRATION: FULLY FUNCTIONAL\n";
      true
    end else begin
      Printf.printf "\n‚ùå PIPELINE INTEGRATION: ISSUES DETECTED\n";
      if not all_expansions_work then Printf.printf "  ‚Ä¢ Macro expansion failures\n";
      if not performance_reasonable then Printf.printf "  ‚Ä¢ Performance issues\n";
      false
    end
  with
  | e ->
    Printf.printf "‚ùå Pipeline integration failed: %s\n" (Printexc.to_string e);
    false

(** Test cache behavior with repeated processing *)
let test_cache_integration () =
  Printf.printf "\n=== CACHE INTEGRATION TEST ===\n";
  
  let test_doc = "\\LaTeX{} \\textbf{test} \\alpha \\beta" in
  let config = { default_config with debug_mode = true } in
  
  Printf.printf "Testing cache behavior with repeated processing...\n";
  
  (* Process the same document multiple times *)
  let results = Array.make 5 None in
  
  for i = 0 to 4 do
    let start_time = Unix.gettimeofday () in
    let result = process_document config test_doc in
    let elapsed = (Unix.gettimeofday () -. start_time) *. 1_000_000. in
    results.(i) <- Some (result, elapsed);
    Printf.printf "Run %d: %.0fŒºs\n" (i+1) elapsed;
  done;
  
  (* Analyze timing patterns (should show cache benefits) *)
  let times = Array.map (function 
    | Some (_, time) -> time 
    | None -> 0.) results in
  
  let first_time = times.(0) in
  let avg_subsequent = 
    let sum = Array.fold_left (+.) 0. (Array.sub times 1 4) in
    sum /. 4. in
  
  Printf.printf "\nCache analysis:\n";
  Printf.printf "  First run (cold cache): %.0fŒºs\n" first_time;
  Printf.printf "  Avg subsequent (warm cache): %.0fŒºs\n" avg_subsequent;
  Printf.printf "  Cache speedup: %.1fx\n" (first_time /. avg_subsequent);
  
  let cache_working = avg_subsequent < first_time *. 0.8 in
  Printf.printf "  Cache effectiveness: %s\n" (if cache_working then "‚úÖ WORKING" else "‚ùå NOT EFFECTIVE");
  
  cache_working

(** Comprehensive integration test *)
let test_complete_integration () =
  Printf.printf "üîß COMPLETE PIPELINE INTEGRATION TEST\n";
  Printf.printf "%s\n" (String.make 50 '=');
  
  let pipeline_ok = test_pipeline_integration () in
  let cache_ok = test_cache_integration () in
  
  Printf.printf "\n%s\n" (String.make 50 '=');
  Printf.printf "INTEGRATION TEST RESULTS\n";
  Printf.printf "%s\n" (String.make 50 '=');
  Printf.printf "Pipeline functionality: %s\n" (if pipeline_ok then "‚úÖ WORKING" else "‚ùå FAILED");
  Printf.printf "Cache integration: %s\n" (if cache_ok then "‚úÖ WORKING" else "‚ùå FAILED");
  
  if pipeline_ok && cache_ok then begin
    Printf.printf "\nüéØ ‚úÖ ALL INTEGRATION GAPS CLOSED\n";
    Printf.printf "L0-L1 pipeline is fully functional with caching!\n";
    true
  end else begin
    Printf.printf "\n‚ùå INTEGRATION ISSUES REMAIN\n";
    false
  end