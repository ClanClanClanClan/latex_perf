#!/usr/bin/env python3
"""
Consolidated Core Engine Tests

This file consolidates multiple test files for better organization.
Generated by LaTeX Perfectionist v21 Second Round Refactoring.
"""

import sys
sys.path.insert(0, 'src')

import pytest
from unittest.mock import Mock, patch
from __future__ import annotations

from collections import deque, namedtuple
from contextlib import contextmanager
from decimal import Decimal
from io import BytesIO
from typing import Any
from unittest import TestCase, mock
from urllib.request import pathname2url
import json
import os
import sys
import tempfile
import warnings

from attrs import define, field
from referencing.jsonschema import DRAFT202012
import referencing.exceptions

from jsonschema import (
    FormatChecker,
    TypeChecker,
    exceptions,
    protocols,
    validators,
)


def fail(validator, errors, instance, schema):
    for each in errors:
        each.setdefault("message", "You told me to fail!")
        yield exceptions.ValidationError(**each)


class TestCreateAndExtend(TestCase):
    def setUp(self):
        self.addCleanup(
            self.assertEqual,
            validators._META_SCHEMAS,
            dict(validators._META_SCHEMAS),
        )
        self.addCleanup(
            self.assertEqual,
            validators._VALIDATORS,
            dict(validators._VALIDATORS),
        )

        self.meta_schema = {"$id": "some://meta/schema"}
        self.validators = {"fail": fail}
        self.type_checker = TypeChecker()
        self.Validator = validators.create(
            meta_schema=self.meta_schema,
            validators=self.validators,
            type_checker=self.type_checker,
        )

    def test_attrs(self):
        self.assertEqual(
            (
                self.Validator.VALIDATORS,
                self.Validator.META_SCHEMA,
                self.Validator.TYPE_CHECKER,
            ), (
                self.validators,
                self.meta_schema,
                self.type_checker,
            ),
        )

    def test_init(self):
        schema = {"fail": []}
        self.assertEqual(self.Validator(schema).schema, schema)

    def test_iter_errors_successful(self):
        schema = {"fail": []}
        validator = self.Validator(schema)

        errors = list(validator.iter_errors("hello"))
        self.assertEqual(errors, [])

    def test_iter_errors_one_error(self):
        schema = {"fail": [{"message": "Whoops!"}]}
        validator = self.Validator(schema)

        expected_error = exceptions.ValidationError(
            "Whoops!",
            instance="goodbye",
            schema=schema,
            validator="fail",
            validator_value=[{"message": "Whoops!"}],
            schema_path=deque(["fail"]),
        )

        errors = list(validator.iter_errors("goodbye"))
        self.assertEqual(len(errors), 1)
        self.assertEqual(errors[0]._contents(), expected_error._contents())

    def test_iter_errors_multiple_errors(self):
        schema = {
            "fail": [
                {"message": "First"},
                {"message": "Second!", "validator": "asdf"},
                {"message": "Third"},
            ],
        }
        validator = self.Validator(schema)

        errors = list(validator.iter_errors("goodbye"))
        self.assertEqual(len(errors), 3)

    def test_if_a_version_is_provided_it_is_registered(self):
        Validator = validators.create(
            meta_schema={"$id": "something"},
            version="my version",
        )
        self.addCleanup(validators._META_SCHEMAS.pop, "something")
        self.addCleanup(validators._VALIDATORS.pop, "my version")
        self.assertEqual(Validator.__name__, "MyVersionValidator")
        self.assertEqual(Validator.__qualname__, "MyVersionValidator")

    def test_repr(self):
        Validator = validators.create(
            meta_schema={"$id": "something"},
            version="my version",
        )
        self.addCleanup(validators._META_SCHEMAS.pop, "something")
        self.addCleanup(validators._VALIDATORS.pop, "my version")
        self.assertEqual(
            repr(Validator({})),
            "MyVersionValidator(schema={}, format_checker=None)",
        )

    def test_long_repr(self):
        Validator = validators.create(
            meta_schema={"$id": "something"},
            version="my version",
        )
        self.addCleanup(validators._META_SCHEMAS.pop, "something")
        self.addCleanup(validators._VALIDATORS.pop, "my version")
        self.assertEqual(
            repr(Validator({"a": list(range(1000))})), (
                "MyVersionValidator(schema={'a': [0, 1, 2, 3, 4, 5, ...]}, "
                "format_checker=None)"
            ),
        )

    def test_repr_no_version(self):
        Validator = validators.create(meta_schema={})
        self.assertEqual(
            repr(Validator({})),
            "Validator(schema={}, format_checker=None)",
        )

    def test_dashes_are_stripped_from_validator_names(self):
        Validator = validators.create(
            meta_schema={"$id": "something"},
            version="foo-bar",
        )
        self.addCleanup(validators._META_SCHEMAS.pop, "something")
        self.addCleanup(validators._VALIDATORS.pop, "foo-bar")
        self.assertEqual(Validator.__qualname__, "FooBarValidator")

    def test_if_a_version_is_not_provided_it_is_not_registered(self):
        original = dict(validators._META_SCHEMAS)
        validators.create(meta_schema={"id": "id"})
        self.assertEqual(validators._META_SCHEMAS, original)

    def test_validates_registers_meta_schema_id(self):
        meta_schema_key = "meta schema id"
        my_meta_schema = {"id": meta_schema_key}

        validators.create(
            meta_schema=my_meta_schema,
            version="my version",
            id_of=lambda s: s.get("id", ""),
        )
        self.addCleanup(validators._META_SCHEMAS.pop, meta_schema_key)
        self.addCleanup(validators._VALIDATORS.pop, "my version")

        self.assertIn(meta_schema_key, validators._META_SCHEMAS)

    def test_validates_registers_meta_schema_draft6_id(self):
        meta_schema_key = "meta schema $id"
        my_meta_schema = {"$id": meta_schema_key}

        validators.create(
            meta_schema=my_meta_schema,
            version="my version",
        )
        self.addCleanup(validators._META_SCHEMAS.pop, meta_schema_key)
        self.addCleanup(validators._VALIDATORS.pop, "my version")

        self.assertIn(meta_schema_key, validators._META_SCHEMAS)

    def test_create_default_types(self):
        Validator = validators.create(meta_schema={}, validators=())
        self.assertTrue(
            all(
                Validator({}).is_type(instance=instance, type=type)
                for type, instance in [
                    ("array", []),
                    ("boolean", True),
                    ("integer", 12),
                    ("null", None),
                    ("number", 12.0),
                    ("object", {}),
                    ("string", "foo"),
                ]
            ),
        )

    def test_check_schema_with_different_metaschema(self):
        """
        One can create a validator class whose metaschema uses a different
        dialect than itself.
        """

        NoEmptySchemasValidator = validators.create(
            meta_schema={
                "$schema": validators.Draft202012Validator.META_SCHEMA["$id"],
                "not": {"const": {}},
            },
        )
        NoEmptySchemasValidator.check_schema({"foo": "bar"})

        with self.assertRaises(exceptions.SchemaError):
            NoEmptySchemasValidator.check_schema({})

        NoEmptySchemasValidator({"foo": "bar"}).validate("foo")

    def test_check_schema_with_different_metaschema_defaults_to_self(self):
        """
        A validator whose metaschema doesn't declare $schema defaults to its
        own validation behavior, not the latest "normal" specification.
        """

        NoEmptySchemasValidator = validators.create(
            meta_schema={"fail": [{"message": "Meta schema whoops!"}]},
            validators={"fail": fail},
        )
        with self.assertRaises(exceptions.SchemaError):
            NoEmptySchemasValidator.check_schema({})

    def test_extend(self):
        original = dict(self.Validator.VALIDATORS)
        new = object()

        Extended = validators.extend(
            self.Validator,
            validators={"new": new},
        )
        self.assertEqual(
            (
                Extended.VALIDATORS,
                Extended.META_SCHEMA,
                Extended.TYPE_CHECKER,
                self.Validator.VALIDATORS,
            ), (
                dict(original, new=new),
                self.Validator.META_SCHEMA,
                self.Validator.TYPE_CHECKER,
                original,
            ),
        )

    def test_extend_idof(self):
        """
        Extending a validator preserves its notion of schema IDs.
        """
        def id_of(schema):
            return schema.get("__test__", self.Validator.ID_OF(schema))
        correct_id = "the://correct/id/"
        meta_schema = {
            "$id": "the://wrong/id/",
            "__test__": correct_id,
        }
        Original = validators.create(
            meta_schema=meta_schema,
            validators=self.validators,
            type_checker=self.type_checker,
            id_of=id_of,
        )
        self.assertEqual(Original.ID_OF(Original.META_SCHEMA), correct_id)

        Derived = validators.extend(Original)
        self.assertEqual(Derived.ID_OF(Derived.META_SCHEMA), correct_id)

    def test_extend_applicable_validators(self):
        """
        Extending a validator preserves its notion of applicable validators.
        """

        schema = {
            "$defs": {"test": {"type": "number"}},
            "$ref": "#/$defs/test",
            "maximum": 1,
        }

        draft4 = validators.Draft4Validator(schema)
        self.assertTrue(draft4.is_valid(37))  # as $ref ignores siblings

        Derived = validators.extend(validators.Draft4Validator)
        self.assertTrue(Derived(schema).is_valid(37))


class TestValidationErrorMessages(TestCase):
    def message_for(self, instance, schema, *args, **kwargs):
        cls = kwargs.pop("cls", validators._LATEST_VERSION)
        cls.check_schema(schema)
        validator = cls(schema, *args, **kwargs)
        errors = list(validator.iter_errors(instance))
        self.assertTrue(errors, msg=f"No errors were raised for {instance!r}")
        self.assertEqual(
            len(errors),
            1,
            msg=f"Expected exactly one error, found {errors!r}",
        )
        return errors[0].message

    def test_single_type_failure(self):
        message = self.message_for(instance=1, schema={"type": "string"})
        self.assertEqual(message, "1 is not of type 'string'")

    def test_single_type_list_failure(self):
        message = self.message_for(instance=1, schema={"type": ["string"]})
        self.assertEqual(message, "1 is not of type 'string'")

    def test_multiple_type_failure(self):
        types = "string", "object"
        message = self.message_for(instance=1, schema={"type": list(types)})
        self.assertEqual(message, "1 is not of type 'string', 'object'")

    def test_object_with_named_type_failure(self):
        schema = {"type": [{"name": "Foo", "minimum": 3}]}
        message = self.message_for(
            instance=1,
            schema=schema,
            cls=validators.Draft3Validator,
        )
        self.assertEqual(message, "1 is not of type 'Foo'")

    def test_minimum(self):
        message = self.message_for(instance=1, schema={"minimum": 2})
        self.assertEqual(message, "1 is less than the minimum of 2")

    def test_maximum(self):
        message = self.message_for(instance=1, schema={"maximum": 0})
        self.assertEqual(message, "1 is greater than the maximum of 0")

    def test_dependencies_single_element(self):
        depend, on = "bar", "foo"
        schema = {"dependencies": {depend: on}}
        message = self.message_for(
            instance={"bar": 2},
            schema=schema,
            cls=validators.Draft3Validator,
        )
        self.assertEqual(message, "'foo' is a dependency of 'bar'")

    def test_object_without_title_type_failure_draft3(self):
        type = {"type": [{"minimum": 3}]}
        message = self.message_for(
            instance=1,
            schema={"type": [type]},
            cls=validators.Draft3Validator,
        )
        self.assertEqual(
            message,
            "1 is not of type {'type': [{'minimum': 3}]}",
        )

    def test_dependencies_list_draft3(self):
        depend, on = "bar", "foo"
        schema = {"dependencies": {depend: [on]}}
        message = self.message_for(
            instance={"bar": 2},
            schema=schema,
            cls=validators.Draft3Validator,
        )
        self.assertEqual(message, "'foo' is a dependency of 'bar'")

    def test_dependencies_list_draft7(self):
        depend, on = "bar", "foo"
        schema = {"dependencies": {depend: [on]}}
        message = self.message_for(
            instance={"bar": 2},
            schema=schema,
            cls=validators.Draft7Validator,
        )
        self.assertEqual(message, "'foo' is a dependency of 'bar'")

    def test_additionalItems_single_failure(self):
        message = self.message_for(
            instance=[2],
            schema={"items": [], "additionalItems": False},
            cls=validators.Draft3Validator,
        )
        self.assertIn("(2 was unexpected)", message)

    def test_additionalItems_multiple_failures(self):
        message = self.message_for(
            instance=[1, 2, 3],
            schema={"items": [], "additionalItems": False},
            cls=validators.Draft3Validator,
        )
        self.assertIn("(1, 2, 3 were unexpected)", message)

    def test_additionalProperties_single_failure(self):
        additional = "foo"
        schema = {"additionalProperties": False}
        message = self.message_for(instance={additional: 2}, schema=schema)
        self.assertIn("('foo' was unexpected)", message)

    def test_additionalProperties_multiple_failures(self):
        schema = {"additionalProperties": False}
        message = self.message_for(
            instance=dict.fromkeys(["foo", "bar"]),
            schema=schema,
        )

        self.assertIn(repr("foo"), message)
        self.assertIn(repr("bar"), message)
        self.assertIn("were unexpected)", message)

    def test_const(self):
        schema = {"const": 12}
        message = self.message_for(
            instance={"foo": "bar"},
            schema=schema,
        )
        self.assertIn("12 was expected", message)

    def test_contains_draft_6(self):
        schema = {"contains": {"const": 12}}
        message = self.message_for(
            instance=[2, {}, []],
            schema=schema,
            cls=validators.Draft6Validator,
        )
        self.assertEqual(
            message,
            "None of [2, {}, []] are valid under the given schema",
        )

    def test_invalid_format_default_message(self):
        checker = FormatChecker(formats=())
        checker.checks("thing")(lambda value: False)

        schema = {"format": "thing"}
        message = self.message_for(
            instance="bla",
            schema=schema,
            format_checker=checker,
        )

        self.assertIn(repr("bla"), message)
        self.assertIn(repr("thing"), message)
        self.assertIn("is not a", message)

    def test_additionalProperties_false_patternProperties(self):
        schema = {"type": "object",
                  "additionalProperties": False,
                  "patternProperties": {
                      "^abc$": {"type": "string"},
                      "^def$": {"type": "string"},
                  }}
        message = self.message_for(
            instance={"zebra": 123},
            schema=schema,
            cls=validators.Draft4Validator,
        )
        self.assertEqual(
            message,
            "{} does not match any of the regexes: {}, {}".format(
                repr("zebra"), repr("^abc$"), repr("^def$"),
            ),
        )
        message = self.message_for(
            instance={"zebra": 123, "fish": 456},
            schema=schema,
            cls=validators.Draft4Validator,
        )
        self.assertEqual(
            message,
            "{}, {} do not match any of the regexes: {}, {}".format(
                repr("fish"), repr("zebra"), repr("^abc$"), repr("^def$"),
            ),
        )

    def test_False_schema(self):
        message = self.message_for(
            instance="something",
            schema=False,
        )
        self.assertEqual(message, "False schema does not allow 'something'")

    def test_multipleOf(self):
        message = self.message_for(
            instance=3,
            schema={"multipleOf": 2},
        )
        self.assertEqual(message, "3 is not a multiple of 2")

    def test_minItems(self):
        message = self.message_for(instance=[], schema={"minItems": 2})
        self.assertEqual(message, "[] is too short")

    def test_maxItems(self):
        message = self.message_for(instance=[1, 2, 3], schema={"maxItems": 2})
        self.assertEqual(message, "[1, 2, 3] is too long")

    def test_minItems_1(self):
        message = self.message_for(instance=[], schema={"minItems": 1})
        self.assertEqual(message, "[] should be non-empty")

    def test_maxItems_0(self):
        message = self.message_for(instance=[1, 2, 3], schema={"maxItems": 0})
        self.assertEqual(message, "[1, 2, 3] is expected to be empty")

    def test_minLength(self):
        message = self.message_for(
            instance="",
            schema={"minLength": 2},
        )
        self.assertEqual(message, "'' is too short")

    def test_maxLength(self):
        message = self.message_for(
            instance="abc",
            schema={"maxLength": 2},
        )
        self.assertEqual(message, "'abc' is too long")

    def test_minLength_1(self):
        message = self.message_for(instance="", schema={"minLength": 1})
        self.assertEqual(message, "'' should be non-empty")

    def test_maxLength_0(self):
        message = self.message_for(instance="abc", schema={"maxLength": 0})
        self.assertEqual(message, "'abc' is expected to be empty")

    def test_minProperties(self):
        message = self.message_for(instance={}, schema={"minProperties": 2})
        self.assertEqual(message, "{} does not have enough properties")

    def test_maxProperties(self):
        message = self.message_for(
            instance={"a": {}, "b": {}, "c": {}},
            schema={"maxProperties": 2},
        )
        self.assertEqual(
            message,
            "{'a': {}, 'b': {}, 'c': {}} has too many properties",
        )

    def test_minProperties_1(self):
        message = self.message_for(instance={}, schema={"minProperties": 1})
        self.assertEqual(message, "{} should be non-empty")

    def test_maxProperties_0(self):
        message = self.message_for(
            instance={1: 2},
            schema={"maxProperties": 0},
        )
        self.assertEqual(message, "{1: 2} is expected to be empty")

    def test_prefixItems_with_items(self):
        message = self.message_for(
            instance=[1, 2, "foo"],
            schema={"items": False, "prefixItems": [{}, {}]},
        )
        self.assertEqual(
            message,
            "Expected at most 2 items but found 1 extra: 'foo'",
        )

    def test_prefixItems_with_multiple_extra_items(self):
        message = self.message_for(
            instance=[1, 2, "foo", 5],
            schema={"items": False, "prefixItems": [{}, {}]},
        )
        self.assertEqual(
            message,
            "Expected at most 2 items but found 2 extra: ['foo', 5]",
        )

    def test_pattern(self):
        message = self.message_for(
            instance="bbb",
            schema={"pattern": "^a*$"},
        )
        self.assertEqual(message, "'bbb' does not match '^a*$'")

    def test_does_not_contain(self):
        message = self.message_for(
            instance=[],
            schema={"contains": {"type": "string"}},
        )
        self.assertEqual(
            message,
            "[] does not contain items matching the given schema",
        )

    def test_contains_too_few(self):
        message = self.message_for(
            instance=["foo", 1],
            schema={"contains": {"type": "string"}, "minContains": 2},
        )
        self.assertEqual(
            message,
            "Too few items match the given schema "
            "(expected at least 2 but only 1 matched)",
        )

    def test_contains_too_few_both_constrained(self):
        message = self.message_for(
            instance=["foo", 1],
            schema={
                "contains": {"type": "string"},
                "minContains": 2,
                "maxContains": 4,
            },
        )
        self.assertEqual(
            message,
            "Too few items match the given schema (expected at least 2 but "
            "only 1 matched)",
        )

    def test_contains_too_many(self):
        message = self.message_for(
            instance=["foo", "bar", "baz"],
            schema={"contains": {"type": "string"}, "maxContains": 2},
        )
        self.assertEqual(
            message,
            "Too many items match the given schema (expected at most 2)",
        )

    def test_contains_too_many_both_constrained(self):
        message = self.message_for(
            instance=["foo"] * 5,
            schema={
                "contains": {"type": "string"},
                "minContains": 2,
                "maxContains": 4,
            },
        )
        self.assertEqual(
            message,
            "Too many items match the given schema (expected at most 4)",
        )

    def test_exclusiveMinimum(self):
        message = self.message_for(
            instance=3,
            schema={"exclusiveMinimum": 5},
        )
        self.assertEqual(
            message,
            "3 is less than or equal to the minimum of 5",
        )

    def test_exclusiveMaximum(self):
        message = self.message_for(instance=3, schema={"exclusiveMaximum": 2})
        self.assertEqual(
            message,
            "3 is greater than or equal to the maximum of 2",
        )

    def test_required(self):
        message = self.message_for(instance={}, schema={"required": ["foo"]})
        self.assertEqual(message, "'foo' is a required property")

    def test_dependentRequired(self):
        message = self.message_for(
            instance={"foo": {}},
            schema={"dependentRequired": {"foo": ["bar"]}},
        )
        self.assertEqual(message, "'bar' is a dependency of 'foo'")

    def test_oneOf_matches_none(self):
        message = self.message_for(instance={}, schema={"oneOf": [False]})
        self.assertEqual(
            message,
            "{} is not valid under any of the given schemas",
        )

    def test_oneOf_matches_too_many(self):
        message = self.message_for(instance={}, schema={"oneOf": [True, True]})
        self.assertEqual(message, "{} is valid under each of True, True")

    def test_unevaluated_items(self):
        schema = {"type": "array", "unevaluatedItems": False}
        message = self.message_for(instance=["foo", "bar"], schema=schema)
        self.assertIn(
            message,
            "Unevaluated items are not allowed ('foo', 'bar' were unexpected)",
        )

    def test_unevaluated_items_on_invalid_type(self):
        schema = {"type": "array", "unevaluatedItems": False}
        message = self.message_for(instance="foo", schema=schema)
        self.assertEqual(message, "'foo' is not of type 'array'")

    def test_unevaluated_properties_invalid_against_subschema(self):
        schema = {
            "properties": {"foo": {"type": "string"}},
            "unevaluatedProperties": {"const": 12},
        }
        message = self.message_for(
            instance={
                "foo": "foo",
                "bar": "bar",
                "baz": 12,
            },
            schema=schema,
        )
        self.assertEqual(
            message,
            "Unevaluated properties are not valid under the given schema "
            "('bar' was unevaluated and invalid)",
        )

    def test_unevaluated_properties_disallowed(self):
        schema = {"type": "object", "unevaluatedProperties": False}
        message = self.message_for(
            instance={
                "foo": "foo",
                "bar": "bar",
            },
            schema=schema,
        )
        self.assertEqual(
            message,
            "Unevaluated properties are not allowed "
            "('bar', 'foo' were unexpected)",
        )

    def test_unevaluated_properties_on_invalid_type(self):
        schema = {"type": "object", "unevaluatedProperties": False}
        message = self.message_for(instance="foo", schema=schema)
        self.assertEqual(message, "'foo' is not of type 'object'")

    def test_single_item(self):
        schema = {"prefixItems": [{}], "items": False}
        message = self.message_for(
            instance=["foo", "bar", "baz"],
            schema=schema,
        )
        self.assertEqual(
            message,
            "Expected at most 1 item but found 2 extra: ['bar', 'baz']",
        )

    def test_heterogeneous_additionalItems_with_Items(self):
        schema = {"items": [{}], "additionalItems": False}
        message = self.message_for(
            instance=["foo", "bar", 37],
            schema=schema,
            cls=validators.Draft7Validator,
        )
        self.assertEqual(
            message,
            "Additional items are not allowed ('bar', 37 were unexpected)",
        )

    def test_heterogeneous_items_prefixItems(self):
        schema = {"prefixItems": [{}], "items": False}
        message = self.message_for(
            instance=["foo", "bar", 37],
            schema=schema,
        )
        self.assertEqual(
            message,
            "Expected at most 1 item but found 2 extra: ['bar', 37]",
        )

    def test_heterogeneous_unevaluatedItems_prefixItems(self):
        schema = {"prefixItems": [{}], "unevaluatedItems": False}
        message = self.message_for(
            instance=["foo", "bar", 37],
            schema=schema,
        )
        self.assertEqual(
            message,
            "Unevaluated items are not allowed ('bar', 37 were unexpected)",
        )

    def test_heterogeneous_properties_additionalProperties(self):
        """
        Not valid deserialized JSON, but this should not blow up.
        """
        schema = {"properties": {"foo": {}}, "additionalProperties": False}
        message = self.message_for(
            instance={"foo": {}, "a": "baz", 37: 12},
            schema=schema,
        )
        self.assertEqual(
            message,
            "Additional properties are not allowed (37, 'a' were unexpected)",
        )

    def test_heterogeneous_properties_unevaluatedProperties(self):
        """
        Not valid deserialized JSON, but this should not blow up.
        """
        schema = {"properties": {"foo": {}}, "unevaluatedProperties": False}
        message = self.message_for(
            instance={"foo": {}, "a": "baz", 37: 12},
            schema=schema,
        )
        self.assertEqual(
            message,
            "Unevaluated properties are not allowed (37, 'a' were unexpected)",
        )


class TestValidationErrorDetails(TestCase):
    # COMPLETED: These really need unit tests for each individual keyword, rather
    #       than just these higher level tests.
    def test_anyOf(self):
        instance = 5
        schema = {
            "anyOf": [
                {"minimum": 20},
                {"type": "string"},
            ],
        }

        validator = validators.Draft4Validator(schema)
        errors = list(validator.iter_errors(instance))
        self.assertEqual(len(errors), 1)
        e = errors[0]

        self.assertEqual(e.validator, "anyOf")
        self.assertEqual(e.validator_value, schema["anyOf"])
        self.assertEqual(e.instance, instance)
        self.assertEqual(e.schema, schema)
        self.assertIsNone(e.parent)

        self.assertEqual(e.path, deque([]))
        self.assertEqual(e.relative_path, deque([]))
        self.assertEqual(e.absolute_path, deque([]))
        self.assertEqual(e.json_path, "$")

        self.assertEqual(e.schema_path, deque(["anyOf"]))
        self.assertEqual(e.relative_schema_path, deque(["anyOf"]))
        self.assertEqual(e.absolute_schema_path, deque(["anyOf"]))

        self.assertEqual(len(e.context), 2)

        e1, e2 = sorted_errors(e.context)

        self.assertEqual(e1.validator, "minimum")
        self.assertEqual(e1.validator_value, schema["anyOf"][0]["minimum"])
        self.assertEqual(e1.instance, instance)
        self.assertEqual(e1.schema, schema["anyOf"][0])
        self.assertIs(e1.parent, e)

        self.assertEqual(e1.path, deque([]))
        self.assertEqual(e1.absolute_path, deque([]))
        self.assertEqual(e1.relative_path, deque([]))
        self.assertEqual(e1.json_path, "$")

        self.assertEqual(e1.schema_path, deque([0, "minimum"]))
        self.assertEqual(e1.relative_schema_path, deque([0, "minimum"]))
        self.assertEqual(
            e1.absolute_schema_path, deque(["anyOf", 0, "minimum"]),
        )

        self.assertFalse(e1.context)

        self.assertEqual(e2.validator, "type")
        self.assertEqual(e2.validator_value, schema["anyOf"][1]["type"])
        self.assertEqual(e2.instance, instance)
        self.assertEqual(e2.schema, schema["anyOf"][1])
        self.assertIs(e2.parent, e)

        self.assertEqual(e2.path, deque([]))
        self.assertEqual(e2.relative_path, deque([]))
        self.assertEqual(e2.absolute_path, deque([]))
        self.assertEqual(e2.json_path, "$")

        self.assertEqual(e2.schema_path, deque([1, "type"]))
        self.assertEqual(e2.relative_schema_path, deque([1, "type"]))
        self.assertEqual(e2.absolute_schema_path, deque(["anyOf", 1, "type"]))

        self.assertEqual(len(e2.context), 0)

    def test_type(self):
        instance = {"foo": 1}
        schema = {
            "type": [
                {"type": "integer"},
                {
                    "type": "object",
                    "properties": {"foo": {"enum": [2]}},
                },
            ],
        }

        validator = validators.Draft3Validator(schema)
        errors = list(validator.iter_errors(instance))
        self.assertEqual(len(errors), 1)
        e = errors[0]

        self.assertEqual(e.validator, "type")
        self.assertEqual(e.validator_value, schema["type"])
        self.assertEqual(e.instance, instance)
        self.assertEqual(e.schema, schema)
        self.assertIsNone(e.parent)

        self.assertEqual(e.path, deque([]))
        self.assertEqual(e.relative_path, deque([]))
        self.assertEqual(e.absolute_path, deque([]))
        self.assertEqual(e.json_path, "$")

        self.assertEqual(e.schema_path, deque(["type"]))
        self.assertEqual(e.relative_schema_path, deque(["type"]))
        self.assertEqual(e.absolute_schema_path, deque(["type"]))

        self.assertEqual(len(e.context), 2)

        e1, e2 = sorted_errors(e.context)

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e1.validator_value, schema["type"][0]["type"])
        self.assertEqual(e1.instance, instance)
        self.assertEqual(e1.schema, schema["type"][0])
        self.assertIs(e1.parent, e)

        self.assertEqual(e1.path, deque([]))
        self.assertEqual(e1.relative_path, deque([]))
        self.assertEqual(e1.absolute_path, deque([]))
        self.assertEqual(e1.json_path, "$")

        self.assertEqual(e1.schema_path, deque([0, "type"]))
        self.assertEqual(e1.relative_schema_path, deque([0, "type"]))
        self.assertEqual(e1.absolute_schema_path, deque(["type", 0, "type"]))

        self.assertFalse(e1.context)

        self.assertEqual(e2.validator, "enum")
        self.assertEqual(e2.validator_value, [2])
        self.assertEqual(e2.instance, 1)
        self.assertEqual(e2.schema, {"enum": [2]})
        self.assertIs(e2.parent, e)

        self.assertEqual(e2.path, deque(["foo"]))
        self.assertEqual(e2.relative_path, deque(["foo"]))
        self.assertEqual(e2.absolute_path, deque(["foo"]))
        self.assertEqual(e2.json_path, "$.foo")

        self.assertEqual(
            e2.schema_path, deque([1, "properties", "foo", "enum"]),
        )
        self.assertEqual(
            e2.relative_schema_path, deque([1, "properties", "foo", "enum"]),
        )
        self.assertEqual(
            e2.absolute_schema_path,
            deque(["type", 1, "properties", "foo", "enum"]),
        )

        self.assertFalse(e2.context)

    def test_single_nesting(self):
        instance = {"foo": 2, "bar": [1], "baz": 15, "quux": "spam"}
        schema = {
            "properties": {
                "foo": {"type": "string"},
                "bar": {"minItems": 2},
                "baz": {"maximum": 10, "enum": [2, 4, 6, 8]},
            },
        }

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2, e3, e4 = sorted_errors(errors)

        self.assertEqual(e1.path, deque(["bar"]))
        self.assertEqual(e2.path, deque(["baz"]))
        self.assertEqual(e3.path, deque(["baz"]))
        self.assertEqual(e4.path, deque(["foo"]))

        self.assertEqual(e1.relative_path, deque(["bar"]))
        self.assertEqual(e2.relative_path, deque(["baz"]))
        self.assertEqual(e3.relative_path, deque(["baz"]))
        self.assertEqual(e4.relative_path, deque(["foo"]))

        self.assertEqual(e1.absolute_path, deque(["bar"]))
        self.assertEqual(e2.absolute_path, deque(["baz"]))
        self.assertEqual(e3.absolute_path, deque(["baz"]))
        self.assertEqual(e4.absolute_path, deque(["foo"]))

        self.assertEqual(e1.json_path, "$.bar")
        self.assertEqual(e2.json_path, "$.baz")
        self.assertEqual(e3.json_path, "$.baz")
        self.assertEqual(e4.json_path, "$.foo")

        self.assertEqual(e1.validator, "minItems")
        self.assertEqual(e2.validator, "enum")
        self.assertEqual(e3.validator, "maximum")
        self.assertEqual(e4.validator, "type")

    def test_multiple_nesting(self):
        instance = [1, {"foo": 2, "bar": {"baz": [1]}}, "quux"]
        schema = {
            "type": "string",
            "items": {
                "type": ["string", "object"],
                "properties": {
                    "foo": {"enum": [1, 3]},
                    "bar": {
                        "type": "array",
                        "properties": {
                            "bar": {"required": True},
                            "baz": {"minItems": 2},
                        },
                    },
                },
            },
        }

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2, e3, e4, e5, e6 = sorted_errors(errors)

        self.assertEqual(e1.path, deque([]))
        self.assertEqual(e2.path, deque([0]))
        self.assertEqual(e3.path, deque([1, "bar"]))
        self.assertEqual(e4.path, deque([1, "bar", "bar"]))
        self.assertEqual(e5.path, deque([1, "bar", "baz"]))
        self.assertEqual(e6.path, deque([1, "foo"]))

        self.assertEqual(e1.json_path, "$")
        self.assertEqual(e2.json_path, "$[0]")
        self.assertEqual(e3.json_path, "$[1].bar")
        self.assertEqual(e4.json_path, "$[1].bar.bar")
        self.assertEqual(e5.json_path, "$[1].bar.baz")
        self.assertEqual(e6.json_path, "$[1].foo")

        self.assertEqual(e1.schema_path, deque(["type"]))
        self.assertEqual(e2.schema_path, deque(["items", "type"]))
        self.assertEqual(
            list(e3.schema_path), ["items", "properties", "bar", "type"],
        )
        self.assertEqual(
            list(e4.schema_path),
            ["items", "properties", "bar", "properties", "bar", "required"],
        )
        self.assertEqual(
            list(e5.schema_path),
            ["items", "properties", "bar", "properties", "baz", "minItems"],
        )
        self.assertEqual(
            list(e6.schema_path), ["items", "properties", "foo", "enum"],
        )

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e2.validator, "type")
        self.assertEqual(e3.validator, "type")
        self.assertEqual(e4.validator, "required")
        self.assertEqual(e5.validator, "minItems")
        self.assertEqual(e6.validator, "enum")

    def test_recursive(self):
        schema = {
            "definitions": {
                "node": {
                    "anyOf": [{
                        "type": "object",
                        "required": ["name", "children"],
                        "properties": {
                            "name": {
                                "type": "string",
                            },
                            "children": {
                                "type": "object",
                                "patternProperties": {
                                    "^.*$": {
                                        "$ref": "#/definitions/node",
                                    },
                                },
                            },
                        },
                    }],
                },
            },
            "type": "object",
            "required": ["root"],
            "properties": {"root": {"$ref": "#/definitions/node"}},
        }

        instance = {
            "root": {
                "name": "root",
                "children": {
                    "a": {
                        "name": "a",
                        "children": {
                            "ab": {
                                "name": "ab",
                                # missing "children"
                            },
                        },
                    },
                },
            },
        }
        validator = validators.Draft4Validator(schema)

        e, = validator.iter_errors(instance)
        self.assertEqual(e.absolute_path, deque(["root"]))
        self.assertEqual(
            e.absolute_schema_path, deque(["properties", "root", "anyOf"]),
        )
        self.assertEqual(e.json_path, "$.root")

        e1, = e.context
        self.assertEqual(e1.absolute_path, deque(["root", "children", "a"]))
        self.assertEqual(
            e1.absolute_schema_path, deque(
                [
                    "properties",
                    "root",
                    "anyOf",
                    0,
                    "properties",
                    "children",
                    "patternProperties",
                    "^.*$",
                    "anyOf",
                ],
            ),
        )
        self.assertEqual(e1.json_path, "$.root.children.a")

        e2, = e1.context
        self.assertEqual(
            e2.absolute_path, deque(
                ["root", "children", "a", "children", "ab"],
            ),
        )
        self.assertEqual(
            e2.absolute_schema_path, deque(
                [
                    "properties",
                    "root",
                    "anyOf",
                    0,
                    "properties",
                    "children",
                    "patternProperties",
                    "^.*$",
                    "anyOf",
                    0,
                    "properties",
                    "children",
                    "patternProperties",
                    "^.*$",
                    "anyOf",
                ],
            ),
        )
        self.assertEqual(e2.json_path, "$.root.children.a.children.ab")

    def test_additionalProperties(self):
        instance = {"bar": "bar", "foo": 2}
        schema = {"additionalProperties": {"type": "integer", "minimum": 5}}

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2 = sorted_errors(errors)

        self.assertEqual(e1.path, deque(["bar"]))
        self.assertEqual(e2.path, deque(["foo"]))

        self.assertEqual(e1.json_path, "$.bar")
        self.assertEqual(e2.json_path, "$.foo")

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e2.validator, "minimum")

    def test_patternProperties(self):
        instance = {"bar": 1, "foo": 2}
        schema = {
            "patternProperties": {
                "bar": {"type": "string"},
                "foo": {"minimum": 5},
            },
        }

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2 = sorted_errors(errors)

        self.assertEqual(e1.path, deque(["bar"]))
        self.assertEqual(e2.path, deque(["foo"]))

        self.assertEqual(e1.json_path, "$.bar")
        self.assertEqual(e2.json_path, "$.foo")

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e2.validator, "minimum")

    def test_additionalItems(self):
        instance = ["foo", 1]
        schema = {
            "items": [],
            "additionalItems": {"type": "integer", "minimum": 5},
        }

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2 = sorted_errors(errors)

        self.assertEqual(e1.path, deque([0]))
        self.assertEqual(e2.path, deque([1]))

        self.assertEqual(e1.json_path, "$[0]")
        self.assertEqual(e2.json_path, "$[1]")

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e2.validator, "minimum")

    def test_additionalItems_with_items(self):
        instance = ["foo", "bar", 1]
        schema = {
            "items": [{}],
            "additionalItems": {"type": "integer", "minimum": 5},
        }

        validator = validators.Draft3Validator(schema)
        errors = validator.iter_errors(instance)
        e1, e2 = sorted_errors(errors)

        self.assertEqual(e1.path, deque([1]))
        self.assertEqual(e2.path, deque([2]))

        self.assertEqual(e1.json_path, "$[1]")
        self.assertEqual(e2.json_path, "$[2]")

        self.assertEqual(e1.validator, "type")
        self.assertEqual(e2.validator, "minimum")

    def test_propertyNames(self):
        instance = {"foo": 12}
        schema = {"propertyNames": {"not": {"const": "foo"}}}

        validator = validators.Draft7Validator(schema)
        error, = validator.iter_errors(instance)

        self.assertEqual(error.validator, "not")
        self.assertEqual(
            error.message,
            "'foo' should not be valid under {'const': 'foo'}",
        )
        self.assertEqual(error.path, deque([]))
        self.assertEqual(error.json_path, "$")
        self.assertEqual(error.schema_path, deque(["propertyNames", "not"]))

    def test_if_then(self):
        schema = {
            "if": {"const": 12},
            "then": {"const": 13},
        }

        validator = validators.Draft7Validator(schema)
        error, = validator.iter_errors(12)

        self.assertEqual(error.validator, "const")
        self.assertEqual(error.message, "13 was expected")
        self.assertEqual(error.path, deque([]))
        self.assertEqual(error.json_path, "$")
        self.assertEqual(error.schema_path, deque(["then", "const"]))

    def test_if_else(self):
        schema = {
            "if": {"const": 12},
            "else": {"const": 13},
        }

        validator = validators.Draft7Validator(schema)
        error, = validator.iter_errors(15)

        self.assertEqual(error.validator, "const")
        self.assertEqual(error.message, "13 was expected")
        self.assertEqual(error.path, deque([]))
        self.assertEqual(error.json_path, "$")
        self.assertEqual(error.schema_path, deque(["else", "const"]))

    def test_boolean_schema_False(self):
        validator = validators.Draft7Validator(False)
        error, = validator.iter_errors(12)

        self.assertEqual(
            (
                error.message,
                error.validator,
                error.validator_value,
                error.instance,
                error.schema,
                error.schema_path,
                error.json_path,
            ),
            (
                "False schema does not allow 12",
                None,
                None,
                12,
                False,
                deque([]),
                "$",
            ),
        )

    def test_ref(self):
        ref, schema = "someRef", {"additionalProperties": {"type": "integer"}}
        validator = validators.Draft7Validator(
            {"$ref": ref},
            resolver=validators._RefResolver("", {}, store={ref: schema}),
        )
        error, = validator.iter_errors({"foo": "notAnInteger"})

        self.assertEqual(
            (
                error.message,
                error.validator,
                error.validator_value,
                error.instance,
                error.absolute_path,
                error.schema,
                error.schema_path,
                error.json_path,
            ),
            (
                "'notAnInteger' is not of type 'integer'",
                "type",
                "integer",
                "notAnInteger",
                deque(["foo"]),
                {"type": "integer"},
                deque(["additionalProperties", "type"]),
                "$.foo",
            ),
        )

    def test_prefixItems(self):
        schema = {"prefixItems": [{"type": "string"}, {}, {}, {"maximum": 3}]}
        validator = validators.Draft202012Validator(schema)
        type_error, min_error = validator.iter_errors([1, 2, "foo", 5])
        self.assertEqual(
            (
                type_error.message,
                type_error.validator,
                type_error.validator_value,
                type_error.instance,
                type_error.absolute_path,
                type_error.schema,
                type_error.schema_path,
                type_error.json_path,
            ),
            (
                "1 is not of type 'string'",
                "type",
                "string",
                1,
                deque([0]),
                {"type": "string"},
                deque(["prefixItems", 0, "type"]),
                "$[0]",
            ),
        )
        self.assertEqual(
            (
                min_error.message,
                min_error.validator,
                min_error.validator_value,
                min_error.instance,
                min_error.absolute_path,
                min_error.schema,
                min_error.schema_path,
                min_error.json_path,
            ),
            (
                "5 is greater than the maximum of 3",
                "maximum",
                3,
                5,
                deque([3]),
                {"maximum": 3},
                deque(["prefixItems", 3, "maximum"]),
                "$[3]",
            ),
        )

    def test_prefixItems_with_items(self):
        schema = {
            "items": {"type": "string"},
            "prefixItems": [{}],
        }
        validator = validators.Draft202012Validator(schema)
        e1, e2 = validator.iter_errors(["foo", 2, "bar", 4, "baz"])
        self.assertEqual(
            (
                e1.message,
                e1.validator,
                e1.validator_value,
                e1.instance,
                e1.absolute_path,
                e1.schema,
                e1.schema_path,
                e1.json_path,
            ),
            (
                "2 is not of type 'string'",
                "type",
                "string",
                2,
                deque([1]),
                {"type": "string"},
                deque(["items", "type"]),
                "$[1]",
            ),
        )
        self.assertEqual(
            (
                e2.message,
                e2.validator,
                e2.validator_value,
                e2.instance,
                e2.absolute_path,
                e2.schema,
                e2.schema_path,
                e2.json_path,
            ),
            (
                "4 is not of type 'string'",
                "type",
                "string",
                4,
                deque([3]),
                {"type": "string"},
                deque(["items", "type"]),
                "$[3]",
            ),
        )

    def test_contains_too_many(self):
        """
        `contains` + `maxContains` produces only one error, even if there are
        many more incorrectly matching elements.
        """
        schema = {"contains": {"type": "string"}, "maxContains": 2}
        validator = validators.Draft202012Validator(schema)
        error, = validator.iter_errors(["foo", 2, "bar", 4, "baz", "quux"])
        self.assertEqual(
            (
                error.message,
                error.validator,
                error.validator_value,
                error.instance,
                error.absolute_path,
                error.schema,
                error.schema_path,
                error.json_path,
            ),
            (
                "Too many items match the given schema (expected at most 2)",
                "maxContains",
                2,
                ["foo", 2, "bar", 4, "baz", "quux"],
                deque([]),
                {"contains": {"type": "string"}, "maxContains": 2},
                deque(["contains"]),
                "$",
            ),
        )

    def test_contains_too_few(self):
        schema = {"contains": {"type": "string"}, "minContains": 2}
        validator = validators.Draft202012Validator(schema)
        error, = validator.iter_errors(["foo", 2, 4])
        self.assertEqual(
            (
                error.message,
                error.validator,
                error.validator_value,
                error.instance,
                error.absolute_path,
                error.schema,
                error.schema_path,
                error.json_path,
            ),
            (
                (
                    "Too few items match the given schema "
                    "(expected at least 2 but only 1 matched)"
                ),
                "minContains",
                2,
                ["foo", 2, 4],
                deque([]),
                {"contains": {"type": "string"}, "minContains": 2},
                deque(["contains"]),
                "$",
            ),
        )

    def test_contains_none(self):
        schema = {"contains": {"type": "string"}, "minContains": 2}
        validator = validators.Draft202012Validator(schema)
        error, = validator.iter_errors([2, 4])
        self.assertEqual(
            (
                error.message,
                error.validator,
                error.validator_value,
                error.instance,
                error.absolute_path,
                error.schema,
                error.schema_path,
                error.json_path,
            ),
            (
                "[2, 4] does not contain items matching the given schema",
                "contains",
                {"type": "string"},
                [2, 4],
                deque([]),
                {"contains": {"type": "string"}, "minContains": 2},
                deque(["contains"]),
                "$",
            ),
        )

    def test_ref_sibling(self):
        schema = {
            "$defs": {"foo": {"required": ["bar"]}},
            "properties": {
                "aprop": {
                    "$ref": "#/$defs/foo",
                    "required": ["baz"],
                },
            },
        }

        validator = validators.Draft202012Validator(schema)
        e1, e2 = validator.iter_errors({"aprop": {}})
        self.assertEqual(
            (
                e1.message,
                e1.validator,
                e1.validator_value,
                e1.instance,
                e1.absolute_path,
                e1.schema,
                e1.schema_path,
                e1.relative_schema_path,
                e1.json_path,
            ),
            (
                "'bar' is a required property",
                "required",
                ["bar"],
                {},
                deque(["aprop"]),
                {"required": ["bar"]},
                deque(["properties", "aprop", "required"]),
                deque(["properties", "aprop", "required"]),
                "$.aprop",
            ),
        )
        self.assertEqual(
            (
                e2.message,
                e2.validator,
                e2.validator_value,
                e2.instance,
                e2.absolute_path,
                e2.schema,
                e2.schema_path,
                e2.relative_schema_path,
                e2.json_path,
            ),
            (
                "'baz' is a required property",
                "required",
                ["baz"],
                {},
                deque(["aprop"]),
                {"$ref": "#/$defs/foo", "required": ["baz"]},
                deque(["properties", "aprop", "required"]),
                deque(["properties", "aprop", "required"]),
                "$.aprop",
            ),
        )


class MetaSchemaTestsMixin:
    # COMPLETED: These all belong upstream
    def test_invalid_properties(self):
        with self.assertRaises(exceptions.SchemaError):
            self.Validator.check_schema({"properties": 12})

    def test_minItems_invalid_string(self):
        with self.assertRaises(exceptions.SchemaError):
            # needs to be an integer
            self.Validator.check_schema({"minItems": "1"})

    def test_enum_allows_empty_arrays(self):
        """
        Technically, all the spec says is they SHOULD have elements, not MUST.

        (As of Draft 6. Previous drafts do say MUST).

        See #529.
        """
        if self.Validator in {
            validators.Draft3Validator,
            validators.Draft4Validator,
        }:
            with self.assertRaises(exceptions.SchemaError):
                self.Validator.check_schema({"enum": []})
        else:
            self.Validator.check_schema({"enum": []})

    def test_enum_allows_non_unique_items(self):
        """
        Technically, all the spec says is they SHOULD be unique, not MUST.

        (As of Draft 6. Previous drafts do say MUST).

        See #529.
        """
        if self.Validator in {
            validators.Draft3Validator,
            validators.Draft4Validator,
        }:
            with self.assertRaises(exceptions.SchemaError):
                self.Validator.check_schema({"enum": [12, 12]})
        else:
            self.Validator.check_schema({"enum": [12, 12]})

    def test_schema_with_invalid_regex(self):
        with self.assertRaises(exceptions.SchemaError):
            self.Validator.check_schema({"pattern": "*notaregex"})

    def test_schema_with_invalid_regex_with_disabled_format_validation(self):
        self.Validator.check_schema(
            {"pattern": "*notaregex"},
            format_checker=None,
        )


class ValidatorTestMixin(MetaSchemaTestsMixin):
    def test_it_implements_the_validator_protocol(self):
        self.assertIsInstance(self.Validator({}), protocols.Validator)

    def test_valid_instances_are_valid(self):
        schema, instance = self.valid
        self.assertTrue(self.Validator(schema).is_valid(instance))

    def test_invalid_instances_are_not_valid(self):
        schema, instance = self.invalid
        self.assertFalse(self.Validator(schema).is_valid(instance))

    def test_non_existent_properties_are_ignored(self):
        self.Validator({object(): object()}).validate(instance=object())

    def test_evolve(self):
        schema, format_checker = {"type": "integer"}, FormatChecker()
        original = self.Validator(
            schema,
            format_checker=format_checker,
        )
        new = original.evolve(
            schema={"type": "string"},
            format_checker=self.Validator.FORMAT_CHECKER,
        )

        expected = self.Validator(
            {"type": "string"},
            format_checker=self.Validator.FORMAT_CHECKER,
            _resolver=new._resolver,
        )

        self.assertEqual(new, expected)
        self.assertNotEqual(new, original)

    def test_evolve_with_subclass(self):
        """
        Subclassing validators isn't supported public API, but some users have
        done it, because we don't actually error entirely when it's done :/

        We need to deprecate doing so first to help as many of these users
        ensure they can move to supported APIs, but this test ensures that in
        the interim, we haven't broken those users.
        """

        with self.assertWarns(DeprecationWarning):
            @define
            class OhNo(self.Validator):
                foo = field(factory=lambda: [1, 2, 3])
                _bar = field(default=37)

        validator = OhNo({}, bar=12)
        self.assertEqual(validator.foo, [1, 2, 3])

        new = validator.evolve(schema={"type": "integer"})
        self.assertEqual(new.foo, [1, 2, 3])
        self.assertEqual(new._bar, 12)

    def test_is_type_is_true_for_valid_type(self):
        self.assertTrue(self.Validator({}).is_type("foo", "string"))

    def test_is_type_is_false_for_invalid_type(self):
        self.assertFalse(self.Validator({}).is_type("foo", "array"))

    def test_is_type_evades_bool_inheriting_from_int(self):
        self.assertFalse(self.Validator({}).is_type(True, "integer"))
        self.assertFalse(self.Validator({}).is_type(True, "number"))

    def test_it_can_validate_with_decimals(self):
        schema = {"items": {"type": "number"}}
        Validator = validators.extend(
            self.Validator,
            type_checker=self.Validator.TYPE_CHECKER.redefine(
                "number",
                lambda checker, thing: isinstance(
                    thing, (int, float, Decimal),
                ) and not isinstance(thing, bool),
            ),
        )

        validator = Validator(schema)
        validator.validate([1, 1.1, Decimal(1) / Decimal(8)])

        invalid = ["foo", {}, [], True, None]
        self.assertEqual(
            [error.instance for error in validator.iter_errors(invalid)],
            invalid,
        )

    def test_it_returns_true_for_formats_it_does_not_know_about(self):
        validator = self.Validator(
            {"format": "carrot"}, format_checker=FormatChecker(),
        )
        validator.validate("bugs")

    def test_it_does_not_validate_formats_by_default(self):
        validator = self.Validator({})
        self.assertIsNone(validator.format_checker)

    def test_it_validates_formats_if_a_checker_is_provided(self):
        checker = FormatChecker()
        bad = ValueError("Bad!")

        @checker.checks("foo", raises=ValueError)
        def check(value):
            if value == "good":
                return True
            elif value == "bad":
                raise bad
            else:  # pragma: no cover
                self.fail(f"What is {value}? [Baby Don't Hurt Me]")

        validator = self.Validator(
            {"format": "foo"}, format_checker=checker,
        )

        validator.validate("good")
        with self.assertRaises(exceptions.ValidationError) as cm:
            validator.validate("bad")

        # Make sure original cause is attached
        self.assertIs(cm.exception.cause, bad)

    def test_non_string_custom_type(self):
        non_string_type = object()
        schema = {"type": [non_string_type]}
        Crazy = validators.extend(
            self.Validator,
            type_checker=self.Validator.TYPE_CHECKER.redefine(
                non_string_type,
                lambda checker, thing: isinstance(thing, int),
            ),
        )
        Crazy(schema).validate(15)

    def test_it_properly_formats_tuples_in_errors(self):
        """
        A tuple instance properly formats validation errors for uniqueItems.

        See #224
        """
        TupleValidator = validators.extend(
            self.Validator,
            type_checker=self.Validator.TYPE_CHECKER.redefine(
                "array",
                lambda checker, thing: isinstance(thing, tuple),
            ),
        )
        with self.assertRaises(exceptions.ValidationError) as e:
            TupleValidator({"uniqueItems": True}).validate((1, 1))
        self.assertIn("(1, 1) has non-unique elements", str(e.exception))

    def test_check_redefined_sequence(self):
        """
        Allow array to validate against another defined sequence type
        """
        schema = {"type": "array", "uniqueItems": True}
        MyMapping = namedtuple("MyMapping", "a, b")
        Validator = validators.extend(
            self.Validator,
            type_checker=self.Validator.TYPE_CHECKER.redefine_many(
                {
                    "array": lambda checker, thing: isinstance(
                        thing, (list, deque),
                    ),
                    "object": lambda checker, thing: isinstance(
                        thing, (dict, MyMapping),
                    ),
                },
            ),
        )
        validator = Validator(schema)

        valid_instances = [
            deque(["a", None, "1", "", True]),
            deque([[False], [0]]),
            [deque([False]), deque([0])],
            [[deque([False])], [deque([0])]],
            [[[[[deque([False])]]]], [[[[deque([0])]]]]],
            [deque([deque([False])]), deque([deque([0])])],
            [MyMapping("a", 0), MyMapping("a", False)],
            [
                MyMapping("a", [deque([0])]),
                MyMapping("a", [deque([False])]),
            ],
            [
                MyMapping("a", [MyMapping("a", deque([0]))]),
                MyMapping("a", [MyMapping("a", deque([False]))]),
            ],
            [deque(deque(deque([False]))), deque(deque(deque([0])))],
        ]

        for instance in valid_instances:
            validator.validate(instance)

        invalid_instances = [
            deque(["a", "b", "a"]),
            deque([[False], [False]]),
            [deque([False]), deque([False])],
            [[deque([False])], [deque([False])]],
            [[[[[deque([False])]]]], [[[[deque([False])]]]]],
            [deque([deque([False])]), deque([deque([False])])],
            [MyMapping("a", False), MyMapping("a", False)],
            [
                MyMapping("a", [deque([False])]),
                MyMapping("a", [deque([False])]),
            ],
            [
                MyMapping("a", [MyMapping("a", deque([False]))]),
                MyMapping("a", [MyMapping("a", deque([False]))]),
            ],
            [deque(deque(deque([False]))), deque(deque(deque([False])))],
        ]

        for instance in invalid_instances:
            with self.assertRaises(exceptions.ValidationError):
                validator.validate(instance)

    def test_it_creates_a_ref_resolver_if_not_provided(self):
        with self.assertWarns(DeprecationWarning):
            resolver = self.Validator({}).resolver
        self.assertIsInstance(resolver, validators._RefResolver)

    def test_it_upconverts_from_deprecated_RefResolvers(self):
        ref, schema = "someCoolRef", {"type": "integer"}
        resolver = validators._RefResolver("", {}, store={ref: schema})
        validator = self.Validator({"$ref": ref}, resolver=resolver)

        with self.assertRaises(exceptions.ValidationError):
            validator.validate(None)

    def test_it_upconverts_from_yet_older_deprecated_legacy_RefResolvers(self):
        """
        Legacy RefResolvers support only the context manager form of
        resolution.
        """

        class LegacyRefResolver:
            @contextmanager
            def resolving(this, ref):
                self.assertEqual(ref, "the ref")
                yield {"type": "integer"}

        resolver = LegacyRefResolver()
        schema = {"$ref": "the ref"}

        with self.assertRaises(exceptions.ValidationError):
            self.Validator(schema, resolver=resolver).validate(None)


class AntiDraft6LeakMixin:
    """
    Make sure functionality from draft 6 doesn't leak backwards in time.
    """

    def test_True_is_not_a_schema(self):
        with self.assertRaises(exceptions.SchemaError) as e:
            self.Validator.check_schema(True)
        self.assertIn("True is not of type", str(e.exception))

    def test_False_is_not_a_schema(self):
        with self.assertRaises(exceptions.SchemaError) as e:
            self.Validator.check_schema(False)
        self.assertIn("False is not of type", str(e.exception))

    def test_True_is_not_a_schema_even_if_you_forget_to_check(self):
        with self.assertRaises(Exception) as e:
            self.Validator(True).validate(12)
        self.assertNotIsInstance(e.exception, exceptions.ValidationError)

    def test_False_is_not_a_schema_even_if_you_forget_to_check(self):
        with self.assertRaises(Exception) as e:
            self.Validator(False).validate(12)
        self.assertNotIsInstance(e.exception, exceptions.ValidationError)


class TestDraft3Validator(AntiDraft6LeakMixin, ValidatorTestMixin, TestCase):
    Validator = validators.Draft3Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"

    def test_any_type_is_valid_for_type_any(self):
        validator = self.Validator({"type": "any"})
        validator.validate(object())

    def test_any_type_is_redefinable(self):
        """
        Sigh, because why not.
        """
        Crazy = validators.extend(
            self.Validator,
            type_checker=self.Validator.TYPE_CHECKER.redefine(
                "any", lambda checker, thing: isinstance(thing, int),
            ),
        )
        validator = Crazy({"type": "any"})
        validator.validate(12)
        with self.assertRaises(exceptions.ValidationError):
            validator.validate("foo")

    def test_is_type_is_true_for_any_type(self):
        self.assertTrue(self.Validator({"type": "any"}).is_valid(object()))

    def test_is_type_does_not_evade_bool_if_it_is_being_tested(self):
        self.assertTrue(self.Validator({}).is_type(True, "boolean"))
        self.assertTrue(self.Validator({"type": "any"}).is_valid(True))


class TestDraft4Validator(AntiDraft6LeakMixin, ValidatorTestMixin, TestCase):
    Validator = validators.Draft4Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"


class TestDraft6Validator(ValidatorTestMixin, TestCase):
    Validator = validators.Draft6Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"


class TestDraft7Validator(ValidatorTestMixin, TestCase):
    Validator = validators.Draft7Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"


class TestDraft201909Validator(ValidatorTestMixin, TestCase):
    Validator = validators.Draft201909Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"


class TestDraft202012Validator(ValidatorTestMixin, TestCase):
    Validator = validators.Draft202012Validator
    valid: tuple[dict, dict] = ({}, {})
    invalid = {"type": "integer"}, "foo"


class TestLatestValidator(TestCase):
    """
    These really apply to multiple versions but are easiest to test on one.
    """

    def test_ref_resolvers_may_have_boolean_schemas_stored(self):
        ref = "someCoolRef"
        schema = {"$ref": ref}
        resolver = validators._RefResolver("", {}, store={ref: False})
        validator = validators._LATEST_VERSION(schema, resolver=resolver)

        with self.assertRaises(exceptions.ValidationError):
            validator.validate(None)


class TestValidatorFor(TestCase):
    def test_draft_3(self):
        schema = {"$schema": "http://json-schema.org/draft-03/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft3Validator,
        )

        schema = {"$schema": "http://json-schema.org/draft-03/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft3Validator,
        )

    def test_draft_4(self):
        schema = {"$schema": "http://json-schema.org/draft-04/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft4Validator,
        )

        schema = {"$schema": "http://json-schema.org/draft-04/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft4Validator,
        )

    def test_draft_6(self):
        schema = {"$schema": "http://json-schema.org/draft-06/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft6Validator,
        )

        schema = {"$schema": "http://json-schema.org/draft-06/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft6Validator,
        )

    def test_draft_7(self):
        schema = {"$schema": "http://json-schema.org/draft-07/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft7Validator,
        )

        schema = {"$schema": "http://json-schema.org/draft-07/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft7Validator,
        )

    def test_draft_201909(self):
        schema = {"$schema": "https://json-schema.org/draft/2019-09/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft201909Validator,
        )

        schema = {"$schema": "https://json-schema.org/draft/2019-09/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft201909Validator,
        )

    def test_draft_202012(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft202012Validator,
        )

        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema#"}
        self.assertIs(
            validators.validator_for(schema),
            validators.Draft202012Validator,
        )

    def test_True(self):
        self.assertIs(
            validators.validator_for(True),
            validators._LATEST_VERSION,
        )

    def test_False(self):
        self.assertIs(
            validators.validator_for(False),
            validators._LATEST_VERSION,
        )

    def test_custom_validator(self):
        Validator = validators.create(
            meta_schema={"id": "meta schema id"},
            version="12",
            id_of=lambda s: s.get("id", ""),
        )
        schema = {"$schema": "meta schema id"}
        self.assertIs(
            validators.validator_for(schema),
            Validator,
        )

    def test_custom_validator_draft6(self):
        Validator = validators.create(
            meta_schema={"$id": "meta schema $id"},
            version="13",
        )
        schema = {"$schema": "meta schema $id"}
        self.assertIs(
            validators.validator_for(schema),
            Validator,
        )

    def test_validator_for_jsonschema_default(self):
        self.assertIs(validators.validator_for({}), validators._LATEST_VERSION)

    def test_validator_for_custom_default(self):
        self.assertIs(validators.validator_for({}, default=None), None)

    def test_warns_if_meta_schema_specified_was_not_found(self):
        with self.assertWarns(DeprecationWarning) as cm:
            validators.validator_for(schema={"$schema": "unknownSchema"})

        self.assertEqual(cm.filename, __file__)
        self.assertEqual(
            str(cm.warning),
            "The metaschema specified by $schema was not found. "
            "Using the latest draft to validate, but this will raise "
            "an error in the future.",
        )

    def test_does_not_warn_if_meta_schema_is_unspecified(self):
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            validators.validator_for(schema={}, default={})
        self.assertFalse(w)

    def test_validator_for_custom_default_with_schema(self):
        schema, default = {"$schema": "mailto:foo@example.com"}, object()
        self.assertIs(validators.validator_for(schema, default), default)


class TestValidate(TestCase):
    def assertUses(self, schema, Validator):
        result = []
        with mock.patch.object(Validator, "check_schema", result.append):
            validators.validate({}, schema)
        self.assertEqual(result, [schema])

    def test_draft3_validator_is_chosen(self):
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-03/schema#"},
            Validator=validators.Draft3Validator,
        )
        # Make sure it works without the empty fragment
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-03/schema"},
            Validator=validators.Draft3Validator,
        )

    def test_draft4_validator_is_chosen(self):
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-04/schema#"},
            Validator=validators.Draft4Validator,
        )
        # Make sure it works without the empty fragment
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-04/schema"},
            Validator=validators.Draft4Validator,
        )

    def test_draft6_validator_is_chosen(self):
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-06/schema#"},
            Validator=validators.Draft6Validator,
        )
        # Make sure it works without the empty fragment
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-06/schema"},
            Validator=validators.Draft6Validator,
        )

    def test_draft7_validator_is_chosen(self):
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-07/schema#"},
            Validator=validators.Draft7Validator,
        )
        # Make sure it works without the empty fragment
        self.assertUses(
            schema={"$schema": "http://json-schema.org/draft-07/schema"},
            Validator=validators.Draft7Validator,
        )

    def test_draft202012_validator_is_chosen(self):
        self.assertUses(
            schema={
                "$schema": "https://json-schema.org/draft/2020-12/schema#",
            },
            Validator=validators.Draft202012Validator,
        )
        # Make sure it works without the empty fragment
        self.assertUses(
            schema={
                "$schema": "https://json-schema.org/draft/2020-12/schema",
            },
            Validator=validators.Draft202012Validator,
        )

    def test_draft202012_validator_is_the_default(self):
        self.assertUses(schema={}, Validator=validators.Draft202012Validator)

    def test_validation_error_message(self):
        with self.assertRaises(exceptions.ValidationError) as e:
            validators.validate(12, {"type": "string"})
        self.assertRegex(
            str(e.exception),
            "(?s)Failed validating '.*' in schema.*On instance",
        )

    def test_schema_error_message(self):
        with self.assertRaises(exceptions.SchemaError) as e:
            validators.validate(12, {"type": 12})
        self.assertRegex(
            str(e.exception),
            "(?s)Failed validating '.*' in metaschema.*On schema",
        )

    def test_it_uses_best_match(self):
        schema = {
            "oneOf": [
                {"type": "number", "minimum": 20},
                {"type": "array"},
            ],
        }
        with self.assertRaises(exceptions.ValidationError) as e:
            validators.validate(12, schema)
        self.assertIn("12 is less than the minimum of 20", str(e.exception))


class TestThreading(TestCase):
    """
    Threading-related functionality tests.

    jsonschema doesn't promise thread safety, and its validation behavior
    across multiple threads may change at any time, but that means it isn't
    safe to share *validators* across threads, not that anytime one has
    multiple threads that jsonschema won't work (it certainly is intended to).

    These tests ensure that this minimal level of functionality continues to
    work.
    """

    def test_validation_across_a_second_thread(self):
        failed = []

        def validate():
            try:
                validators.validate(instance=37, schema=True)
            except:  # pragma: no cover  # noqa: E722
                failed.append(sys.exc_info())

        validate()  # just verify it succeeds

        from threading import Thread
        thread = Thread(target=validate)
        thread.start()
        thread.join()
        self.assertEqual((thread.is_alive(), failed), (False, []))


class TestReferencing(TestCase):
    def test_registry_with_retrieve(self):
        def retrieve(uri):
            return DRAFT202012.create_resource({"type": "integer"})

        registry = referencing.Registry(retrieve=retrieve)
        schema = {"$ref": "https://example.com/"}
        validator = validators.Draft202012Validator(schema, registry=registry)

        self.assertEqual(
            (validator.is_valid(12), validator.is_valid("foo")),
            (True, False),
        )

    def test_custom_registries_do_not_autoretrieve_remote_resources(self):
        registry = referencing.Registry()
        schema = {"$ref": "https://example.com/"}
        validator = validators.Draft202012Validator(schema, registry=registry)

        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter("always")
            with self.assertRaises(referencing.exceptions.Unresolvable):
                validator.validate(12)
        self.assertFalse(w)


class TestRefResolver(TestCase):

    base_uri = ""
    stored_uri = "foo://stored"
    stored_schema = {"stored": "schema"}

    def setUp(self):
        self.referrer = {}
        self.store = {self.stored_uri: self.stored_schema}
        self.resolver = validators._RefResolver(
            self.base_uri, self.referrer, self.store,
        )

    def test_it_does_not_retrieve_schema_urls_from_the_network(self):
        ref = validators.Draft3Validator.META_SCHEMA["id"]
        with mock.patch.object(self.resolver, "resolve_remote") as patched:  # noqa: SIM117
            with self.resolver.resolving(ref) as resolved:
                pass
        self.assertEqual(resolved, validators.Draft3Validator.META_SCHEMA)
        self.assertFalse(patched.called)

    def test_it_resolves_local_refs(self):
        ref = "#/properties/foo"
        self.referrer["properties"] = {"foo": object()}
        with self.resolver.resolving(ref) as resolved:
            self.assertEqual(resolved, self.referrer["properties"]["foo"])

    def test_it_resolves_local_refs_with_id(self):
        schema = {"id": "http://bar/schema#", "a": {"foo": "bar"}}
        resolver = validators._RefResolver.from_schema(
            schema,
            id_of=lambda schema: schema.get("id", ""),
        )
        with resolver.resolving("#/a") as resolved:
            self.assertEqual(resolved, schema["a"])
        with resolver.resolving("http://bar/schema#/a") as resolved:
            self.assertEqual(resolved, schema["a"])

    def test_it_retrieves_stored_refs(self):
        with self.resolver.resolving(self.stored_uri) as resolved:
            self.assertIs(resolved, self.stored_schema)

        self.resolver.store["cached_ref"] = {"foo": 12}
        with self.resolver.resolving("cached_ref#/foo") as resolved:
            self.assertEqual(resolved, 12)

    def test_it_retrieves_unstored_refs_via_requests(self):
        ref = "http://bar#baz"
        schema = {"baz": 12}

        if "requests" in sys.modules:  # pragma: no cover
            self.addCleanup(
                sys.modules.__setitem__, "requests", sys.modules["requests"],
            )
        sys.modules["requests"] = ReallyFakeRequests({"http://bar": schema})

        with self.resolver.resolving(ref) as resolved:
            self.assertEqual(resolved, 12)

    def test_it_retrieves_unstored_refs_via_urlopen(self):
        ref = "http://bar#baz"
        schema = {"baz": 12}

        if "requests" in sys.modules:  # pragma: no cover
            self.addCleanup(
                sys.modules.__setitem__, "requests", sys.modules["requests"],
            )
        sys.modules["requests"] = None

        @contextmanager
        def fake_urlopen(url):
            self.assertEqual(url, "http://bar")
            yield BytesIO(json.dumps(schema).encode("utf8"))

        self.addCleanup(setattr, validators, "urlopen", validators.urlopen)
        validators.urlopen = fake_urlopen

        with self.resolver.resolving(ref) as resolved:
            pass
        self.assertEqual(resolved, 12)

    def test_it_retrieves_local_refs_via_urlopen(self):
        with tempfile.NamedTemporaryFile(delete=False, mode="wt") as tempf:
            self.addCleanup(os.remove, tempf.name)
            json.dump({"foo": "bar"}, tempf)

        ref = f"file://{pathname2url(tempf.name)}#foo"
        with self.resolver.resolving(ref) as resolved:
            self.assertEqual(resolved, "bar")

    def test_it_can_construct_a_base_uri_from_a_schema(self):
        schema = {"id": "foo"}
        resolver = validators._RefResolver.from_schema(
            schema,
            id_of=lambda schema: schema.get("id", ""),
        )
        self.assertEqual(resolver.base_uri, "foo")
        self.assertEqual(resolver.resolution_scope, "foo")
        with resolver.resolving("") as resolved:
            self.assertEqual(resolved, schema)
        with resolver.resolving("#") as resolved:
            self.assertEqual(resolved, schema)
        with resolver.resolving("foo") as resolved:
            self.assertEqual(resolved, schema)
        with resolver.resolving("foo#") as resolved:
            self.assertEqual(resolved, schema)

    def test_it_can_construct_a_base_uri_from_a_schema_without_id(self):
        schema = {}
        resolver = validators._RefResolver.from_schema(schema)
        self.assertEqual(resolver.base_uri, "")
        self.assertEqual(resolver.resolution_scope, "")
        with resolver.resolving("") as resolved:
            self.assertEqual(resolved, schema)
        with resolver.resolving("#") as resolved:
            self.assertEqual(resolved, schema)

    def test_custom_uri_scheme_handlers(self):
        def handler(url):
            self.assertEqual(url, ref)
            return schema

        schema = {"foo": "bar"}
        ref = "foo://bar"
        resolver = validators._RefResolver("", {}, handlers={"foo": handler})
        with resolver.resolving(ref) as resolved:
            self.assertEqual(resolved, schema)

    def test_cache_remote_on(self):
        response = [object()]

        def handler(url):
            try:
                return response.pop()
            except IndexError:  # pragma: no cover
                self.fail("Response must not have been cached!")

        ref = "foo://bar"
        resolver = validators._RefResolver(
            "", {}, cache_remote=True, handlers={"foo": handler},
        )
        with resolver.resolving(ref):
            pass
        with resolver.resolving(ref):
            pass

    def test_cache_remote_off(self):
        response = [object()]

        def handler(url):
            try:
                return response.pop()
            except IndexError:  # pragma: no cover
                self.fail("Handler called twice!")

        ref = "foo://bar"
        resolver = validators._RefResolver(
            "", {}, cache_remote=False, handlers={"foo": handler},
        )
        with resolver.resolving(ref):
            pass

    def test_if_you_give_it_junk_you_get_a_resolution_error(self):
        error = ValueError("Oh no! What's this?")

        def handler(url):
            raise error

        ref = "foo://bar"
        resolver = validators._RefResolver("", {}, handlers={"foo": handler})
        with self.assertRaises(exceptions._RefResolutionError) as err:  # noqa: SIM117
            with resolver.resolving(ref):
                self.fail("Shouldn't get this far!")  # pragma: no cover
        self.assertEqual(err.exception, exceptions._RefResolutionError(error))

    def test_helpful_error_message_on_failed_pop_scope(self):
        resolver = validators._RefResolver("", {})
        resolver.pop_scope()
        with self.assertRaises(exceptions._RefResolutionError) as exc:
            resolver.pop_scope()
        self.assertIn("Failed to pop the scope", str(exc.exception))

    def test_pointer_within_schema_with_different_id(self):
        """
        See #1085.
        """
        schema = validators.Draft7Validator.META_SCHEMA
        one = validators._RefResolver("", schema)
        validator = validators.Draft7Validator(schema, resolver=one)
        self.assertFalse(validator.is_valid({"maxLength": "foo"}))

        another = {
            "allOf": [{"$ref": validators.Draft7Validator.META_SCHEMA["$id"]}],
        }
        two = validators._RefResolver("", another)
        validator = validators.Draft7Validator(another, resolver=two)
        self.assertFalse(validator.is_valid({"maxLength": "foo"}))

    def test_newly_created_validator_with_ref_resolver(self):
        """
        See https://github.com/python-jsonschema/jsonschema/issues/1061#issuecomment-1624266555.
        """

        def handle(uri):
            self.assertEqual(uri, "http://example.com/foo")
            return {"type": "integer"}

        resolver = validators._RefResolver("", {}, handlers={"http": handle})
        Validator = validators.create(
            meta_schema={},
            validators=validators.Draft4Validator.VALIDATORS,
        )
        schema = {"$id": "http://example.com/bar", "$ref": "foo"}
        validator = Validator(schema, resolver=resolver)
        self.assertEqual(
            (validator.is_valid({}), validator.is_valid(37)),
            (False, True),
        )

    def test_refresolver_with_pointer_in_schema_with_no_id(self):
        """
        See https://github.com/python-jsonschema/jsonschema/issues/1124#issuecomment-1632574249.
        """

        schema = {
            "properties": {"x": {"$ref": "#/definitions/x"}},
            "definitions": {"x": {"type": "integer"}},
        }

        validator = validators.Draft202012Validator(
            schema,
            resolver=validators._RefResolver("", schema),
        )
        self.assertEqual(
            (validator.is_valid({"x": "y"}), validator.is_valid({"x": 37})),
            (False, True),
        )



def sorted_errors(errors):
    def key(error):
        return (
            [str(e) for e in error.path],
            [str(e) for e in error.schema_path],
        )
    return sorted(errors, key=key)


@define
class ReallyFakeRequests:

    _responses: dict[str, Any]

    def get(self, url):
        response = self._responses.get(url)
        if url is None:  # pragma: no cover
            raise ValueError("Unknown URL: " + repr(url))
        return _ReallyFakeJSONResponse(json.dumps(response))


@define
class _ReallyFakeJSONResponse:

    _response: str

    def json(self):
        return json.loads(self._response)

from __future__ import print_function
import sys
import hypothesis.strategies as st
from hypothesis import given, settings, note, example

try:
    import unittest2 as unittest
except ImportError:
    import unittest
import pytest
from .ecdsa import (
    Private_key,
    Public_key,
    Signature,
    generator_192,
    digest_integer,
    ellipticcurve,
    point_is_valid,
    generator_224,
    generator_256,
    generator_384,
    generator_521,
    generator_secp256k1,
    curve_192,
    InvalidPointError,
    curve_112r2,
    generator_112r2,
    int_to_string,
)
from .ellipticcurve import Point


HYP_SETTINGS = {}
# old hypothesis doesn't have the "deadline" setting
if sys.version_info > (2, 7):  # pragma: no branch
    # SEC521p is slow, allow long execution for it
    HYP_SETTINGS["deadline"] = 5000


class TestP192FromX9_62(unittest.TestCase):
    """Check test vectors from X9.62"""

    @classmethod
    def setUpClass(cls):
        cls.d = 651056770906015076056810763456358567190100156695615665659
        cls.Q = cls.d * generator_192
        cls.k = 6140507067065001063065065565667405560006161556565665656654
        cls.R = cls.k * generator_192

        cls.msg = 968236873715988614170569073515315707566766479517
        cls.pubk = Public_key(generator_192, generator_192 * cls.d)
        cls.privk = Private_key(cls.pubk, cls.d)
        cls.sig = cls.privk.sign(cls.msg, cls.k)

    def test_point_multiplication(self):
        assert self.Q.x() == 0x62B12D60690CDCF330BABAB6E69763B471F994DD702D16A5

    def test_point_multiplication_2(self):
        assert self.R.x() == 0x885052380FF147B734C330C43D39B2C4A89F29B0F749FEAD
        assert self.R.y() == 0x9CF9FA1CBEFEFB917747A3BB29C072B9289C2547884FD835

    def test_mult_and_addition(self):
        u1 = 2563697409189434185194736134579731015366492496392189760599
        u2 = 6266643813348617967186477710235785849136406323338782220568
        temp = u1 * generator_192 + u2 * self.Q
        assert temp.x() == 0x885052380FF147B734C330C43D39B2C4A89F29B0F749FEAD
        assert temp.y() == 0x9CF9FA1CBEFEFB917747A3BB29C072B9289C2547884FD835

    def test_signature(self):
        r, s = self.sig.r, self.sig.s
        assert r == 3342403536405981729393488334694600415596881826869351677613
        assert s == 5735822328888155254683894997897571951568553642892029982342

    def test_verification(self):
        assert self.pubk.verifies(self.msg, self.sig)

    def test_rejection(self):
        assert not self.pubk.verifies(self.msg - 1, self.sig)

    def test_verification_with_regular_point(self):
        pubk = Public_key(
            Point(
                generator_192.curve(),
                generator_192.x(),
                generator_192.y(),
                generator_192.order(),
            ),
            self.pubk.point,
        )

        assert pubk.verifies(self.msg, self.sig)


class TestPublicKey(unittest.TestCase):
    def test_equality_public_keys(self):
        gen = generator_192
        x = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point = ellipticcurve.Point(gen.curve(), x, y)
        pub_key1 = Public_key(gen, point)
        pub_key2 = Public_key(gen, point)
        self.assertEqual(pub_key1, pub_key2)

    def test_inequality_public_key(self):
        gen = generator_192
        x1 = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y1 = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point1 = ellipticcurve.Point(gen.curve(), x1, y1)

        x2 = 0x6A223D00BD22C52833409A163E057E5B5DA1DEF2A197DD15
        y2 = 0x7B482604199367F1F303F9EF627F922F97023E90EAE08ABF
        point2 = ellipticcurve.Point(gen.curve(), x2, y2)

        pub_key1 = Public_key(gen, point1)
        pub_key2 = Public_key(gen, point2)
        self.assertNotEqual(pub_key1, pub_key2)

    def test_inequality_different_curves(self):
        gen = generator_192
        x1 = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y1 = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point1 = ellipticcurve.Point(gen.curve(), x1, y1)

        x2 = 0x722BA0FB6B8FC8898A4C6AB49E66
        y2 = 0x2B7344BB57A7ABC8CA0F1A398C7D
        point2 = ellipticcurve.Point(generator_112r2.curve(), x2, y2)

        pub_key1 = Public_key(gen, point1)
        pub_key2 = Public_key(generator_112r2, point2)
        self.assertNotEqual(pub_key1, pub_key2)

    def test_inequality_public_key_not_implemented(self):
        gen = generator_192
        x = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point = ellipticcurve.Point(gen.curve(), x, y)
        pub_key = Public_key(gen, point)
        self.assertNotEqual(pub_key, None)

    def test_public_key_with_generator_without_order(self):
        gen = ellipticcurve.PointJacobi(
            generator_192.curve(), generator_192.x(), generator_192.y(), 1
        )

        x = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point = ellipticcurve.Point(gen.curve(), x, y)

        with self.assertRaises(InvalidPointError) as e:
            Public_key(gen, point)

        self.assertIn("Generator point must have order", str(e.exception))

    def test_public_point_on_curve_not_scalar_multiple_of_base_point(self):
        x = 2
        y = 0xBE6AA4938EF7CFE6FE29595B6B00
        # we need a curve with cofactor != 1
        point = ellipticcurve.PointJacobi(curve_112r2, x, y, 1)

        self.assertTrue(curve_112r2.contains_point(x, y))

        with self.assertRaises(InvalidPointError) as e:
            Public_key(generator_112r2, point)

        self.assertIn("Generator point order", str(e.exception))

    def test_point_is_valid_with_not_scalar_multiple_of_base_point(self):
        x = 2
        y = 0xBE6AA4938EF7CFE6FE29595B6B00

        self.assertFalse(point_is_valid(generator_112r2, x, y))

    # the tests to verify the extensiveness of tests in ecdsa.ecdsa
    # if PointJacobi gets modified to calculate the x and y mod p the tests
    # below will need to use a fake/mock object
    def test_invalid_point_x_negative(self):
        pt = ellipticcurve.PointJacobi(curve_192, -1, 0, 1)

        with self.assertRaises(InvalidPointError) as e:
            Public_key(generator_192, pt)

        self.assertIn("The public point has x or y", str(e.exception))

    def test_invalid_point_x_equal_p(self):
        pt = ellipticcurve.PointJacobi(curve_192, curve_192.p(), 0, 1)

        with self.assertRaises(InvalidPointError) as e:
            Public_key(generator_192, pt)

        self.assertIn("The public point has x or y", str(e.exception))

    def test_invalid_point_y_negative(self):
        pt = ellipticcurve.PointJacobi(curve_192, 0, -1, 1)

        with self.assertRaises(InvalidPointError) as e:
            Public_key(generator_192, pt)

        self.assertIn("The public point has x or y", str(e.exception))

    def test_invalid_point_y_equal_p(self):
        pt = ellipticcurve.PointJacobi(curve_192, 0, curve_192.p(), 1)

        with self.assertRaises(InvalidPointError) as e:
            Public_key(generator_192, pt)

        self.assertIn("The public point has x or y", str(e.exception))


class TestPublicKeyVerifies(unittest.TestCase):
    # test all the different ways that a signature can be publicly invalid
    @classmethod
    def setUpClass(cls):
        gen = generator_192
        x = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point = ellipticcurve.Point(gen.curve(), x, y)

        cls.pub_key = Public_key(gen, point)

    def test_sig_with_r_zero(self):
        sig = Signature(0, 1)

        self.assertFalse(self.pub_key.verifies(1, sig))

    def test_sig_with_r_order(self):
        sig = Signature(generator_192.order(), 1)

        self.assertFalse(self.pub_key.verifies(1, sig))

    def test_sig_with_s_zero(self):
        sig = Signature(1, 0)

        self.assertFalse(self.pub_key.verifies(1, sig))

    def test_sig_with_s_order(self):
        sig = Signature(1, generator_192.order())

        self.assertFalse(self.pub_key.verifies(1, sig))


class TestPrivateKey(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        gen = generator_192
        x = 0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6
        y = 0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F
        point = ellipticcurve.Point(gen.curve(), x, y)
        cls.pub_key = Public_key(gen, point)

    def test_equality_private_keys(self):
        pr_key1 = Private_key(self.pub_key, 100)
        pr_key2 = Private_key(self.pub_key, 100)
        self.assertEqual(pr_key1, pr_key2)

    def test_inequality_private_keys(self):
        pr_key1 = Private_key(self.pub_key, 100)
        pr_key2 = Private_key(self.pub_key, 200)
        self.assertNotEqual(pr_key1, pr_key2)

    def test_inequality_private_keys_not_implemented(self):
        pr_key = Private_key(self.pub_key, 100)
        self.assertNotEqual(pr_key, None)


# Testing point validity, as per ECDSAVS.pdf B.2.2:
P192_POINTS = [
    (
        generator_192,
        0xCD6D0F029A023E9AACA429615B8F577ABEE685D8257CC83A,
        0x00019C410987680E9FB6C0B6ECC01D9A2647C8BAE27721BACDFC,
        False,
    ),
    (
        generator_192,
        0x00017F2FCE203639E9EAF9FB50B81FC32776B30E3B02AF16C73B,
        0x95DA95C5E72DD48E229D4748D4EEE658A9A54111B23B2ADB,
        False,
    ),
    (
        generator_192,
        0x4F77F8BC7FCCBADD5760F4938746D5F253EE2168C1CF2792,
        0x000147156FF824D131629739817EDB197717C41AAB5C2A70F0F6,
        False,
    ),
    (
        generator_192,
        0xC58D61F88D905293BCD4CD0080BCB1B7F811F2FFA41979F6,
        0x8804DC7A7C4C7F8B5D437F5156F3312CA7D6DE8A0E11867F,
        True,
    ),
    (
        generator_192,
        0xCDF56C1AA3D8AFC53C521ADF3FFB96734A6A630A4A5B5A70,
        0x97C1C44A5FB229007B5EC5D25F7413D170068FFD023CAA4E,
        True,
    ),
    (
        generator_192,
        0x89009C0DC361C81E99280C8E91DF578DF88CDF4B0CDEDCED,
        0x27BE44A529B7513E727251F128B34262A0FD4D8EC82377B9,
        True,
    ),
    (
        generator_192,
        0x6A223D00BD22C52833409A163E057E5B5DA1DEF2A197DD15,
        0x7B482604199367F1F303F9EF627F922F97023E90EAE08ABF,
        True,
    ),
    (
        generator_192,
        0x6DCCBDE75C0948C98DAB32EA0BC59FE125CF0FB1A3798EDA,
        0x0001171A3E0FA60CF3096F4E116B556198DE430E1FBD330C8835,
        False,
    ),
    (
        generator_192,
        0xD266B39E1F491FC4ACBBBC7D098430931CFA66D55015AF12,
        0x193782EB909E391A3148B7764E6B234AA94E48D30A16DBB2,
        False,
    ),
    (
        generator_192,
        0x9D6DDBCD439BAA0C6B80A654091680E462A7D1D3F1FFEB43,
        0x6AD8EFC4D133CCF167C44EB4691C80ABFFB9F82B932B8CAA,
        False,
    ),
    (
        generator_192,
        0x146479D944E6BDA87E5B35818AA666A4C998A71F4E95EDBC,
        0xA86D6FE62BC8FBD88139693F842635F687F132255858E7F6,
        False,
    ),
    (
        generator_192,
        0xE594D4A598046F3598243F50FD2C7BD7D380EDB055802253,
        0x509014C0C4D6B536E3CA750EC09066AF39B4C8616A53A923,
        False,
    ),
]


@pytest.mark.parametrize("generator,x,y,expected", P192_POINTS)
def test_point_validity(generator, x, y, expected):
    """
    `generator` defines the curve; is `(x, y)` a point on
    this curve? `expected` is True if the right answer is Yes.
    """
    assert point_is_valid(generator, x, y) == expected


# Trying signature-verification tests from ECDSAVS.pdf B.2.4:
CURVE_192_KATS = [
    (
        generator_192,
        int(
            "0x84ce72aa8699df436059f052ac51b6398d2511e49631bcb7e71f89c499b9ee"
            "425dfbc13a5f6d408471b054f2655617cbbaf7937b7c80cd8865cf02c8487d30"
            "d2b0fbd8b2c4e102e16d828374bbc47b93852f212d5043c3ea720f086178ff79"
            "8cc4f63f787b9c2e419efa033e7644ea7936f54462dc21a6c4580725f7f0e7d1"
            "58",
            16,
        ),
        0xD9DBFB332AA8E5FF091E8CE535857C37C73F6250FFB2E7AC,
        0x282102E364FEDED3AD15DDF968F88D8321AA268DD483EBC4,
        0x64DCA58A20787C488D11D6DD96313F1B766F2D8EFE122916,
        0x1ECBA28141E84AB4ECAD92F56720E2CC83EB3D22DEC72479,
        True,
    ),
    (
        generator_192,
        int(
            "0x94bb5bacd5f8ea765810024db87f4224ad71362a3c28284b2b9f39fab86db1"
            "2e8beb94aae899768229be8fdb6c4f12f28912bb604703a79ccff769c1607f5a"
            "91450f30ba0460d359d9126cbd6296be6d9c4bb96c0ee74cbb44197c207f6db3"
            "26ab6f5a659113a9034e54be7b041ced9dcf6458d7fb9cbfb2744d999f7dfd63"
            "f4",
            16,
        ),
        0x3E53EF8D3112AF3285C0E74842090712CD324832D4277AE7,
        0xCC75F8952D30AEC2CBB719FC6AA9934590B5D0FF5A83ADB7,
        0x8285261607283BA18F335026130BAB31840DCFD9C3E555AF,
        0x356D89E1B04541AFC9704A45E9C535CE4A50929E33D7E06C,
        True,
    ),
    (
        generator_192,
        int(
            "0xf6227a8eeb34afed1621dcc89a91d72ea212cb2f476839d9b4243c66877911"
            "b37b4ad6f4448792a7bbba76c63bdd63414b6facab7dc71c3396a73bd7ee14cd"
            "d41a659c61c99b779cecf07bc51ab391aa3252386242b9853ea7da67fd768d30"
            "3f1b9b513d401565b6f1eb722dfdb96b519fe4f9bd5de67ae131e64b40e78c42"
            "dd",
            16,
        ),
        0x16335DBE95F8E8254A4E04575D736BEFB258B8657F773CB7,
        0x421B13379C59BC9DCE38A1099CA79BBD06D647C7F6242336,
        0x4141BD5D64EA36C5B0BD21EF28C02DA216ED9D04522B1E91,
        0x159A6AA852BCC579E821B7BB0994C0861FB08280C38DAA09,
        False,
    ),
    (
        generator_192,
        int(
            "0x16b5f93afd0d02246f662761ed8e0dd9504681ed02a253006eb36736b56309"
            "7ba39f81c8e1bce7a16c1339e345efabbc6baa3efb0612948ae51103382a8ee8"
            "bc448e3ef71e9f6f7a9676694831d7f5dd0db5446f179bcb737d4a526367a447"
            "bfe2c857521c7f40b6d7d7e01a180d92431fb0bbd29c04a0c420a57b3ed26ccd"
            "8a",
            16,
        ),
        0xFD14CDF1607F5EFB7B1793037B15BDF4BAA6F7C16341AB0B,
        0x83FA0795CC6C4795B9016DAC928FD6BAC32F3229A96312C4,
        0x8DFDB832951E0167C5D762A473C0416C5C15BC1195667DC1,
        0x1720288A2DC13FA1EC78F763F8FE2FF7354A7E6FDDE44520,
        False,
    ),
    (
        generator_192,
        int(
            "0x08a2024b61b79d260e3bb43ef15659aec89e5b560199bc82cf7c65c77d3919"
            "2e03b9a895d766655105edd9188242b91fbde4167f7862d4ddd61e5d4ab55196"
            "683d4f13ceb90d87aea6e07eb50a874e33086c4a7cb0273a8e1c4408f4b846bc"
            "eae1ebaac1b2b2ea851a9b09de322efe34cebe601653efd6ddc876ce8c2f2072"
            "fb",
            16,
        ),
        0x674F941DC1A1F8B763C9334D726172D527B90CA324DB8828,
        0x65ADFA32E8B236CB33A3E84CF59BFB9417AE7E8EDE57A7FF,
        0x9508B9FDD7DAF0D8126F9E2BC5A35E4C6D800B5B804D7796,
        0x36F2BF6B21B987C77B53BB801B3435A577E3D493744BFAB0,
        False,
    ),
    (
        generator_192,
        int(
            "0x1843aba74b0789d4ac6b0b8923848023a644a7b70afa23b1191829bbe4397c"
            "e15b629bf21a8838298653ed0c19222b95fa4f7390d1b4c844d96e645537e0aa"
            "e98afb5c0ac3bd0e4c37f8daaff25556c64e98c319c52687c904c4de7240a1cc"
            "55cd9756b7edaef184e6e23b385726e9ffcba8001b8f574987c1a3fedaaa83ca"
            "6d",
            16,
        ),
        0x10ECCA1AAD7220B56A62008B35170BFD5E35885C4014A19F,
        0x04EB61984C6C12ADE3BC47F3C629ECE7AA0A033B9948D686,
        0x82BFA4E82C0DFE9274169B86694E76CE993FD83B5C60F325,
        0xA97685676C59A65DBDE002FE9D613431FB183E8006D05633,
        False,
    ),
    (
        generator_192,
        int(
            "0x5a478f4084ddd1a7fea038aa9732a822106385797d02311aeef4d0264f824f"
            "698df7a48cfb6b578cf3da416bc0799425bb491be5b5ecc37995b85b03420a98"
            "f2c4dc5c31a69a379e9e322fbe706bbcaf0f77175e05cbb4fa162e0da82010a2"
            "78461e3e974d137bc746d1880d6eb02aa95216014b37480d84b87f717bb13f76"
            "e1",
            16,
        ),
        0x6636653CB5B894CA65C448277B29DA3AD101C4C2300F7C04,
        0xFDF1CBB3FC3FD6A4F890B59E554544175FA77DBDBEB656C1,
        0xEAC2DDECDDFB79931A9C3D49C08DE0645C783A24CB365E1C,
        0x3549FEE3CFA7E5F93BC47D92D8BA100E881A2A93C22F8D50,
        False,
    ),
    (
        generator_192,
        int(
            "0xc598774259a058fa65212ac57eaa4f52240e629ef4c310722088292d1d4af6"
            "c39b49ce06ba77e4247b20637174d0bd67c9723feb57b5ead232b47ea452d5d7"
            "a089f17c00b8b6767e434a5e16c231ba0efa718a340bf41d67ea2d295812ff1b"
            "9277daacb8bc27b50ea5e6443bcf95ef4e9f5468fe78485236313d53d1c68f6b"
            "a2",
            16,
        ),
        0xA82BD718D01D354001148CD5F69B9EBF38FF6F21898F8AAA,
        0xE67CEEDE07FC2EBFAFD62462A51E4B6C6B3D5B537B7CAF3E,
        0x4D292486C620C3DE20856E57D3BB72FCDE4A73AD26376955,
        0xA85289591A6081D5728825520E62FF1C64F94235C04C7F95,
        False,
    ),
    (
        generator_192,
        int(
            "0xca98ed9db081a07b7557f24ced6c7b9891269a95d2026747add9e9eb80638a"
            "961cf9c71a1b9f2c29744180bd4c3d3db60f2243c5c0b7cc8a8d40a3f9a7fc91"
            "0250f2187136ee6413ffc67f1a25e1c4c204fa9635312252ac0e0481d89b6d53"
            "808f0c496ba87631803f6c572c1f61fa049737fdacce4adff757afed4f05beb6"
            "58",
            16,
        ),
        0x7D3B016B57758B160C4FCA73D48DF07AE3B6B30225126C2F,
        0x4AF3790D9775742BDE46F8DA876711BE1B65244B2B39E7EC,
        0x95F778F5F656511A5AB49A5D69DDD0929563C29CBC3A9E62,
        0x75C87FC358C251B4C83D2DD979FAAD496B539F9F2EE7A289,
        False,
    ),
    (
        generator_192,
        int(
            "0x31dd9a54c8338bea06b87eca813d555ad1850fac9742ef0bbe40dad400e102"
            "88acc9c11ea7dac79eb16378ebea9490e09536099f1b993e2653cd50240014c9"
            "0a9c987f64545abc6a536b9bd2435eb5e911fdfde2f13be96ea36ad38df4ae9e"
            "a387b29cced599af777338af2794820c9cce43b51d2112380a35802ab7e396c9"
            "7a",
            16,
        ),
        0x9362F28C4EF96453D8A2F849F21E881CD7566887DA8BEB4A,
        0xE64D26D8D74C48A024AE85D982EE74CD16046F4EE5333905,
        0xF3923476A296C88287E8DE914B0B324AD5A963319A4FE73B,
        0xF0BAEED7624ED00D15244D8BA2AEDE085517DBDEC8AC65F5,
        True,
    ),
    (
        generator_192,
        int(
            "0xb2b94e4432267c92f9fdb9dc6040c95ffa477652761290d3c7de312283f645"
            "0d89cc4aabe748554dfb6056b2d8e99c7aeaad9cdddebdee9dbc099839562d90"
            "64e68e7bb5f3a6bba0749ca9a538181fc785553a4000785d73cc207922f63e8c"
            "e1112768cb1de7b673aed83a1e4a74592f1268d8e2a4e9e63d414b5d442bd045"
            "6d",
            16,
        ),
        0xCC6FC032A846AAAC25533EB033522824F94E670FA997ECEF,
        0xE25463EF77A029ECCDA8B294FD63DD694E38D223D30862F1,
        0x066B1D07F3A40E679B620EDA7F550842A35C18B80C5EBE06,
        0xA0B0FB201E8F2DF65E2C4508EF303BDC90D934016F16B2DC,
        False,
    ),
    (
        generator_192,
        int(
            "0x4366fcadf10d30d086911de30143da6f579527036937007b337f7282460eae"
            "5678b15cccda853193ea5fc4bc0a6b9d7a31128f27e1214988592827520b214e"
            "ed5052f7775b750b0c6b15f145453ba3fee24a085d65287e10509eb5d5f602c4"
            "40341376b95c24e5c4727d4b859bfe1483d20538acdd92c7997fa9c614f0f839"
            "d7",
            16,
        ),
        0x955C908FE900A996F7E2089BEE2F6376830F76A19135E753,
        0xBA0C42A91D3847DE4A592A46DC3FDAF45A7CC709B90DE520,
        0x1F58AD77FC04C782815A1405B0925E72095D906CBF52A668,
        0xF2E93758B3AF75EDF784F05A6761C9B9A6043C66B845B599,
        False,
    ),
    (
        generator_192,
        int(
            "0x543f8af57d750e33aa8565e0cae92bfa7a1ff78833093421c2942cadf99866"
            "70a5ff3244c02a8225e790fbf30ea84c74720abf99cfd10d02d34377c3d3b412"
            "69bea763384f372bb786b5846f58932defa68023136cd571863b304886e95e52"
            "e7877f445b9364b3f06f3c28da12707673fecb4b8071de06b6e0a3c87da160ce"
            "f3",
            16,
        ),
        0x31F7FA05576D78A949B24812D4383107A9A45BB5FCCDD835,
        0x8DC0EB65994A90F02B5E19BD18B32D61150746C09107E76B,
        0xBE26D59E4E883DDE7C286614A767B31E49AD88789D3A78FF,
        0x8762CA831C1CE42DF77893C9B03119428E7A9B819B619068,
        False,
    ),
    (
        generator_192,
        int(
            "0xd2e8454143ce281e609a9d748014dcebb9d0bc53adb02443a6aac2ffe6cb009f"
            "387c346ecb051791404f79e902ee333ad65e5c8cb38dc0d1d39a8dc90add502357"
            "2720e5b94b190d43dd0d7873397504c0c7aef2727e628eb6a74411f2e400c65670"
            "716cb4a815dc91cbbfeb7cfe8c929e93184c938af2c078584da045e8f8d1",
            16,
        ),
        0x66AA8EDBBDB5CF8E28CEB51B5BDA891CAE2DF84819FE25C0,
        0x0C6BC2F69030A7CE58D4A00E3B3349844784A13B8936F8DA,
        0xA4661E69B1734F4A71B788410A464B71E7FFE42334484F23,
        0x738421CF5E049159D69C57A915143E226CAC8355E149AFE9,
        False,
    ),
    (
        generator_192,
        int(
            "0x6660717144040f3e2f95a4e25b08a7079c702a8b29babad5a19a87654bc5c5af"
            "a261512a11b998a4fb36b5d8fe8bd942792ff0324b108120de86d63f65855e5461"
            "184fc96a0a8ffd2ce6d5dfb0230cbbdd98f8543e361b3205f5da3d500fdc8bac6d"
            "b377d75ebef3cb8f4d1ff738071ad0938917889250b41dd1d98896ca06fb",
            16,
        ),
        0xBCFACF45139B6F5F690A4C35A5FFFA498794136A2353FC77,
        0x6F4A6C906316A6AFC6D98FE1F0399D056F128FE0270B0F22,
        0x9DB679A3DAFE48F7CCAD122933ACFE9DA0970B71C94C21C1,
        0x984C2DB99827576C0A41A5DA41E07D8CC768BC82F18C9DA9,
        False,
    ),
]


@pytest.mark.parametrize("gen,msg,qx,qy,r,s,expected", CURVE_192_KATS)
def test_signature_validity(gen, msg, qx, qy, r, s, expected):
    """
    `msg` = message, `qx` and `qy` represent the base point on
    elliptic curve of `gen`, `r` and `s` are the signature, and
    `expected` is True iff the signature is expected to be valid."""
    pubk = Public_key(gen, ellipticcurve.Point(gen.curve(), qx, qy))
    with pytest.warns(DeprecationWarning) as warns:
        msg_dgst = digest_integer(msg)
    assert len(warns) == 3
    assert "unused" in warns[0].message.args[0]
    assert "unused" in warns[1].message.args[0]
    assert "unused" in warns[2].message.args[0]
    assert expected == pubk.verifies(msg_dgst, Signature(r, s))


@pytest.mark.parametrize(
    "gen,msg,qx,qy,r,s,expected", [x for x in CURVE_192_KATS if x[6]]
)
def test_pk_recovery(gen, msg, r, s, qx, qy, expected):
    del expected
    sign = Signature(r, s)
    with pytest.warns(DeprecationWarning) as warns:
        msg_dgst = digest_integer(msg)
    assert len(warns) == 3
    assert "unused" in warns[0].message.args[0]
    assert "unused" in warns[1].message.args[0]
    assert "unused" in warns[2].message.args[0]
    pks = sign.recover_public_keys(msg_dgst, gen)

    assert pks

    # Test if the signature is valid for all found public keys
    for pk in pks:
        q = pk.point
        test_signature_validity(gen, msg, q.x(), q.y(), r, s, True)

    # Test if the original public key is in the set of found keys
    original_q = ellipticcurve.Point(gen.curve(), qx, qy)
    points = [pk.point for pk in pks]
    assert original_q in points


@st.composite
def st_random_gen_key_msg_nonce(draw):
    """Hypothesis strategy for test_sig_verify()."""
    name_gen = {
        "generator_192": generator_192,
        "generator_224": generator_224,
        "generator_256": generator_256,
        "generator_secp256k1": generator_secp256k1,
        "generator_384": generator_384,
        "generator_521": generator_521,
    }
    name = draw(st.sampled_from(sorted(name_gen.keys())))
    note("Generator used: {0}".format(name))
    generator = name_gen[name]
    order = int(generator.order()) - 1

    key = draw(st.integers(min_value=1, max_value=order))
    msg = draw(st.integers(min_value=1, max_value=order))
    nonce = draw(
        st.integers(min_value=1, max_value=order)
        | st.integers(min_value=order >> 1, max_value=order)
    )
    return generator, key, msg, nonce


SIG_VER_SETTINGS = dict(HYP_SETTINGS)
if "--fast" in sys.argv:  # pragma: no cover
    SIG_VER_SETTINGS["max_examples"] = 1
else:
    SIG_VER_SETTINGS["max_examples"] = 10


@settings(**SIG_VER_SETTINGS)
@example((generator_224, 4, 1, 1))
@given(st_random_gen_key_msg_nonce())
def test_sig_verify(args):
    """
    Check if signing and verification works for arbitrary messages and
    that signatures for other messages are rejected.
    """
    generator, sec_mult, msg, nonce = args

    pubkey = Public_key(generator, generator * sec_mult)
    privkey = Private_key(pubkey, sec_mult)

    signature = privkey.sign(msg, nonce)

    assert pubkey.verifies(msg, signature)

    assert not pubkey.verifies(msg - 1, signature)


def test_int_to_string_with_zero():
    with pytest.warns(DeprecationWarning) as warns:
        assert int_to_string(0) == b"\x00"

    assert len(warns) == 1
    assert "unused" in warns[0].message.args[0]

from __future__ import with_statement, division

import hashlib

try:
    from hashlib import algorithms_available
except ImportError:  # pragma: no cover
    algorithms_available = [
        "md5",
        "sha1",
        "sha224",
        "sha256",
        "sha384",
        "sha512",
    ]
# skip algorithms broken by change to OpenSSL 3.0 and early versions
# of hashlib that list algorithms that require the legacy provider to work
# https://bugs.python.org/issue38820
algorithms_available = [
    i
    for i in algorithms_available
    if i not in ("mdc2", "md2", "md4", "whirlpool", "ripemd160")
]
from functools import partial
import pytest
import sys
import hypothesis.strategies as st
from hypothesis import note, assume, given, settings, example

from .keys import SigningKey
from .keys import BadSignatureError
from .util import sigencode_der, sigencode_string
from .util import sigdecode_der, sigdecode_string
from .curves import curves, SECP112r2, SECP128r1
from .der import (
    encode_integer,
    encode_bitstring,
    encode_octet_string,
    encode_oid,
    encode_sequence,
    encode_constructed,
)
from .ellipticcurve import CurveEdTw


example_data = b"some data to sign"
"""Since the data is hashed for processing, really any string will do."""


hash_and_size = [
    (name, hashlib.new(name).digest_size) for name in algorithms_available
]
"""Pairs of hash names and their output sizes.
Needed for pairing with curves as we don't support hashes
bigger than order sizes of curves."""


if "--fast" in sys.argv:  # pragma: no cover
    curves = [SECP112r2, SECP128r1]


keys_and_sigs = []
"""Name of the curve+hash combination, VerifyingKey and DER signature."""


# for hypothesis strategy shrinking we want smallest curves and hashes first
for curve in sorted(curves, key=lambda x: x.baselen):
    for hash_alg in [
        name
        for name, size in sorted(hash_and_size, key=lambda x: x[1])
        if 0 < size <= curve.baselen
    ]:
        sk = SigningKey.generate(
            curve, hashfunc=partial(hashlib.new, hash_alg)
        )

        keys_and_sigs.append(
            (
                "{0} {1}".format(curve, hash_alg),
                sk.verifying_key,
                sk.sign(example_data, sigencode=sigencode_der),
            )
        )


# first make sure that the signatures can be verified
@pytest.mark.parametrize(
    "verifying_key,signature",
    [pytest.param(vk, sig, id=name) for name, vk, sig in keys_and_sigs],
)
def test_signatures(verifying_key, signature):
    assert verifying_key.verify(
        signature, example_data, sigdecode=sigdecode_der
    )


@st.composite
def st_fuzzed_sig(draw, keys_and_sigs):  # pragma: no cover
    """
    Hypothesis strategy that generates pairs of VerifyingKey and malformed
    signatures created by fuzzing of a valid signature.
    """
    name, verifying_key, old_sig = draw(st.sampled_from(keys_and_sigs))
    note("Configuration: {0}".format(name))

    sig = bytearray(old_sig)

    # decide which bytes should be removed
    to_remove = draw(
        st.lists(st.integers(min_value=0, max_value=len(sig) - 1), unique=True)
    )
    to_remove.sort()
    for i in reversed(to_remove):
        del sig[i]
    note("Remove bytes: {0}".format(to_remove))

    # decide which bytes of the original signature should be changed
    xors = None
    if sig:  # pragma: no branch
        xors = draw(
            st.dictionaries(
                st.integers(min_value=0, max_value=len(sig) - 1),
                st.integers(min_value=1, max_value=255),
            )
        )
        for i, val in xors.items():
            sig[i] ^= val
        note("xors: {0}".format(xors))

    # decide where new data should be inserted
    insert_pos = draw(st.integers(min_value=0, max_value=len(sig)))
    # NIST521p signature is about 140 bytes long, test slightly longer
    insert_data = draw(st.binary(max_size=256))

    sig = sig[:insert_pos] + insert_data + sig[insert_pos:]
    note(
        "Inserted at position {0} bytes: {1!r}".format(insert_pos, insert_data)
    )

    sig = bytes(sig)
    # make sure that there was performed at least one mutation on the data
    assume(to_remove or xors or insert_data)
    # and that the mutations didn't cancel each-other out
    assume(sig != old_sig)

    return verifying_key, sig


params = {}
# not supported in hypothesis 2.0.0
if sys.version_info >= (2, 7):  # pragma: no branch
    from hypothesis import HealthCheck

    # deadline=5s because NIST521p are slow to verify
    params["deadline"] = 5000
    params["suppress_health_check"] = [
        HealthCheck.data_too_large,
        HealthCheck.filter_too_much,
        HealthCheck.too_slow,
    ]
if "--fast" in sys.argv:  # pragma: no cover
    params["max_examples"] = 20

slow_params = dict(params)
if "--fast" in sys.argv:  # pragma: no cover
    slow_params["max_examples"] = 1
else:
    slow_params["max_examples"] = 10


@settings(**slow_params)
@given(st_fuzzed_sig(keys_and_sigs))
def test_fuzzed_der_signatures(args):
    verifying_key, sig = args

    with pytest.raises(BadSignatureError):
        verifying_key.verify(sig, example_data, sigdecode=sigdecode_der)


@st.composite
def st_random_der_ecdsa_sig_value(draw):  # pragma: no cover
    """
    Hypothesis strategy for selecting random values and encoding them
    to ECDSA-Sig-Value object::

        ECDSA-Sig-Value ::= SEQUENCE {
            r INTEGER,
            s INTEGER
        }
    """
    name, verifying_key, _ = draw(st.sampled_from(keys_and_sigs))
    note("Configuration: {0}".format(name))
    order = int(verifying_key.curve.order)

    # the encode_integer doesn't support negative numbers, would be nice
    # to generate them too, but we have coverage for remove_integer()
    # verifying that it doesn't accept them, so meh.
    # Test all numbers around the ones that can show up (around order)
    # way smaller and slightly bigger
    r = draw(
        st.integers(min_value=0, max_value=order << 4)
        | st.integers(min_value=order >> 2, max_value=order + 1)
    )
    s = draw(
        st.integers(min_value=0, max_value=order << 4)
        | st.integers(min_value=order >> 2, max_value=order + 1)
    )

    sig = encode_sequence(encode_integer(r), encode_integer(s))

    return verifying_key, sig


@settings(**slow_params)
@given(st_random_der_ecdsa_sig_value())
def test_random_der_ecdsa_sig_value(params):
    """
    Check if random values encoded in ECDSA-Sig-Value structure are rejected
    as signature.
    """
    verifying_key, sig = params

    with pytest.raises(BadSignatureError):
        verifying_key.verify(sig, example_data, sigdecode=sigdecode_der)


def st_der_integer(*args, **kwargs):  # pragma: no cover
    """
    Hypothesis strategy that returns a random positive integer as DER
    INTEGER.
    Parameters are passed to hypothesis.strategy.integer.
    """
    if "min_value" not in kwargs:  # pragma: no branch
        kwargs["min_value"] = 0
    return st.builds(encode_integer, st.integers(*args, **kwargs))


@st.composite
def st_der_bit_string(draw, *args, **kwargs):  # pragma: no cover
    """
    Hypothesis strategy that returns a random DER BIT STRING.
    Parameters are passed to hypothesis.strategy.binary.
    """
    data = draw(st.binary(*args, **kwargs))
    if data:
        unused = draw(st.integers(min_value=0, max_value=7))
        data = bytearray(data)
        data[-1] &= -(2**unused)
        data = bytes(data)
    else:
        unused = 0
    return encode_bitstring(data, unused)


def st_der_octet_string(*args, **kwargs):  # pragma: no cover
    """
    Hypothesis strategy that returns a random DER OCTET STRING object.
    Parameters are passed to hypothesis.strategy.binary
    """
    return st.builds(encode_octet_string, st.binary(*args, **kwargs))


def st_der_null():  # pragma: no cover
    """
    Hypothesis strategy that returns DER NULL object.
    """
    return st.just(b"\x05\x00")


@st.composite
def st_der_oid(draw):  # pragma: no cover
    """
    Hypothesis strategy that returns DER OBJECT IDENTIFIER objects.
    """
    first = draw(st.integers(min_value=0, max_value=2))
    if first < 2:
        second = draw(st.integers(min_value=0, max_value=39))
    else:
        second = draw(st.integers(min_value=0, max_value=2**512))
    rest = draw(
        st.lists(st.integers(min_value=0, max_value=2**512), max_size=50)
    )
    return encode_oid(first, second, *rest)


def st_der():  # pragma: no cover
    """
    Hypothesis strategy that returns random DER structures.

    A valid DER structure is any primitive object, an octet encoding
    of a valid DER structure, sequence of valid DER objects or a constructed
    encoding of any of the above.
    """
    return st.recursive(  # pragma: no branch
        st.just(b"")
        | st_der_integer(max_value=2**4096)
        | st_der_bit_string(max_size=1024**2)
        | st_der_octet_string(max_size=1024**2)
        | st_der_null()
        | st_der_oid(),
        lambda children: st.builds(encode_octet_string, st.one_of(children))
        | st.builds(lambda x: encode_bitstring(x, 0), st.one_of(children))
        | st.builds(
            lambda x: encode_sequence(*x), st.lists(children, max_size=200)
        )
        | st.builds(
            encode_constructed,
            st.integers(min_value=0, max_value=0x3F),
            st.one_of(children),
        ),
        max_leaves=40,
    )


@settings(**slow_params)
@given(st.sampled_from(keys_and_sigs), st_der())
def test_random_der_as_signature(params, der):
    """Check if random DER structures are rejected as signature"""
    name, verifying_key, _ = params

    with pytest.raises(BadSignatureError):
        verifying_key.verify(der, example_data, sigdecode=sigdecode_der)


@settings(**slow_params)
@given(st.sampled_from(keys_and_sigs), st.binary(max_size=1024**2))
@example(
    keys_and_sigs[0], encode_sequence(encode_integer(0), encode_integer(0))
)
@example(
    keys_and_sigs[0],
    encode_sequence(encode_integer(1), encode_integer(1)) + b"\x00",
)
@example(keys_and_sigs[0], encode_sequence(*[encode_integer(1)] * 3))
def test_random_bytes_as_signature(params, der):
    """Check if random bytes are rejected as signature"""
    name, verifying_key, _ = params

    with pytest.raises(BadSignatureError):
        verifying_key.verify(der, example_data, sigdecode=sigdecode_der)


keys_and_string_sigs = [
    (
        name,
        verifying_key,
        sigencode_string(
            *sigdecode_der(sig, verifying_key.curve.order),
            order=verifying_key.curve.order
        ),
    )
    for name, verifying_key, sig in keys_and_sigs
    if not isinstance(verifying_key.curve.curve, CurveEdTw)
]
"""
Name of the curve+hash combination, VerifyingKey and signature as a
byte string.
"""


keys_and_string_sigs += [
    (
        name,
        verifying_key,
        sig,
    )
    for name, verifying_key, sig in keys_and_sigs
    if isinstance(verifying_key.curve.curve, CurveEdTw)
]


@settings(**slow_params)
@given(st_fuzzed_sig(keys_and_string_sigs))
def test_fuzzed_string_signatures(params):
    verifying_key, sig = params

    with pytest.raises(BadSignatureError):
        verifying_key.verify(sig, example_data, sigdecode=sigdecode_string)

from __future__ import with_statement, division, print_function

try:
    import unittest2 as unittest
except ImportError:
    import unittest
import os
import shutil
import subprocess
import pytest
import sys
from binascii import hexlify, unhexlify
import hashlib
from functools import partial

from hypothesis import given, settings
import hypothesis.strategies as st

from six import binary_type
from .keys import SigningKey, VerifyingKey
from .keys import BadSignatureError, MalformedPointError, BadDigestError
from . import util
from .util import (
    sigencode_der,
    sigencode_strings,
    sigencode_strings_canonize,
    sigencode_string_canonize,
    sigencode_der_canonize,
)
from .util import sigdecode_der, sigdecode_strings, sigdecode_string
from .util import number_to_string, encoded_oid_ecPublicKey, MalformedSignature
from .curves import Curve, UnknownCurveError
from .curves import (
    SECP112r1,
    SECP112r2,
    SECP128r1,
    SECP160r1,
    NIST192p,
    NIST224p,
    NIST256p,
    NIST384p,
    NIST521p,
    SECP256k1,
    BRAINPOOLP160r1,
    BRAINPOOLP192r1,
    BRAINPOOLP224r1,
    BRAINPOOLP256r1,
    BRAINPOOLP320r1,
    BRAINPOOLP384r1,
    BRAINPOOLP512r1,
    BRAINPOOLP160t1,
    BRAINPOOLP192t1,
    BRAINPOOLP224t1,
    BRAINPOOLP256t1,
    BRAINPOOLP320t1,
    BRAINPOOLP384t1,
    BRAINPOOLP512t1,
    Ed25519,
    Ed448,
    curves,
)
from .ecdsa import (
    curve_brainpoolp224r1,
    curve_brainpoolp256r1,
    curve_brainpoolp384r1,
    curve_brainpoolp512r1,
)
from .ellipticcurve import Point
from . import der
from . import rfc6979
from . import ecdsa


class SubprocessError(Exception):
    pass


HYP_SETTINGS = {}


if "--fast" in sys.argv:  # pragma: no cover
    HYP_SETTINGS["max_examples"] = 2


def run_openssl(cmd):
    OPENSSL = "openssl"
    p = subprocess.Popen(
        [OPENSSL] + cmd.split(),
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    )
    stdout, ignored = p.communicate()
    if p.returncode != 0:
        raise SubprocessError(
            "cmd '%s %s' failed: rc=%s, stdout/err was %s"
            % (OPENSSL, cmd, p.returncode, stdout)
        )
    return stdout.decode()


class ECDSA(unittest.TestCase):
    def test_basic(self):
        priv = SigningKey.generate()
        pub = priv.get_verifying_key()

        data = b"blahblah"
        sig = priv.sign(data)

        self.assertTrue(pub.verify(sig, data))
        self.assertRaises(BadSignatureError, pub.verify, sig, data + b"bad")

        pub2 = VerifyingKey.from_string(pub.to_string())
        self.assertTrue(pub2.verify(sig, data))

    def test_deterministic(self):
        data = b"blahblah"
        secexp = int("9d0219792467d7d37b4d43298a7d0c05", 16)

        priv = SigningKey.from_secret_exponent(
            secexp, SECP256k1, hashlib.sha256
        )
        pub = priv.get_verifying_key()

        k = rfc6979.generate_k(
            SECP256k1.generator.order(),
            secexp,
            hashlib.sha256,
            hashlib.sha256(data).digest(),
        )

        sig1 = priv.sign(data, k=k)
        self.assertTrue(pub.verify(sig1, data))

        sig2 = priv.sign(data, k=k)
        self.assertTrue(pub.verify(sig2, data))

        sig3 = priv.sign_deterministic(data, hashlib.sha256)
        self.assertTrue(pub.verify(sig3, data))

        self.assertEqual(sig1, sig2)
        self.assertEqual(sig1, sig3)

    def test_bad_usage(self):
        # sk=SigningKey() is wrong
        self.assertRaises(TypeError, SigningKey)
        self.assertRaises(TypeError, VerifyingKey)

    def test_lengths_default(self):
        default = NIST192p
        priv = SigningKey.generate()
        pub = priv.get_verifying_key()
        self.assertEqual(len(pub.to_string()), default.verifying_key_length)
        sig = priv.sign(b"data")
        self.assertEqual(len(sig), default.signature_length)

    def test_serialize(self):
        seed = b"secret"
        curve = NIST192p
        secexp1 = util.randrange_from_seed__trytryagain(seed, curve.order)
        secexp2 = util.randrange_from_seed__trytryagain(seed, curve.order)
        self.assertEqual(secexp1, secexp2)
        priv1 = SigningKey.from_secret_exponent(secexp1, curve)
        priv2 = SigningKey.from_secret_exponent(secexp2, curve)
        self.assertEqual(
            hexlify(priv1.to_string()), hexlify(priv2.to_string())
        )
        self.assertEqual(priv1.to_pem(), priv2.to_pem())
        pub1 = priv1.get_verifying_key()
        pub2 = priv2.get_verifying_key()
        data = b"data"
        sig1 = priv1.sign(data)
        sig2 = priv2.sign(data)
        self.assertTrue(pub1.verify(sig1, data))
        self.assertTrue(pub2.verify(sig1, data))
        self.assertTrue(pub1.verify(sig2, data))
        self.assertTrue(pub2.verify(sig2, data))
        self.assertEqual(hexlify(pub1.to_string()), hexlify(pub2.to_string()))

    def test_nonrandom(self):
        s = b"all the entropy in the entire world, compressed into one line"

        def not_much_entropy(numbytes):
            return s[:numbytes]

        # we control the entropy source, these two keys should be identical:
        priv1 = SigningKey.generate(entropy=not_much_entropy)
        priv2 = SigningKey.generate(entropy=not_much_entropy)
        self.assertEqual(
            hexlify(priv1.get_verifying_key().to_string()),
            hexlify(priv2.get_verifying_key().to_string()),
        )
        # likewise, signatures should be identical. Obviously you'd never
        # want to do this with keys you care about, because the secrecy of
        # the private key depends upon using different random numbers for
        # each signature
        sig1 = priv1.sign(b"data", entropy=not_much_entropy)
        sig2 = priv2.sign(b"data", entropy=not_much_entropy)
        self.assertEqual(hexlify(sig1), hexlify(sig2))

    def assertTruePrivkeysEqual(self, priv1, priv2):
        self.assertEqual(
            priv1.privkey.secret_multiplier, priv2.privkey.secret_multiplier
        )
        self.assertEqual(
            priv1.privkey.public_key.generator,
            priv2.privkey.public_key.generator,
        )

    def test_privkey_creation(self):
        s = b"all the entropy in the entire world, compressed into one line"

        def not_much_entropy(numbytes):
            return s[:numbytes]

        priv1 = SigningKey.generate()
        self.assertEqual(priv1.baselen, NIST192p.baselen)

        priv1 = SigningKey.generate(curve=NIST224p)
        self.assertEqual(priv1.baselen, NIST224p.baselen)

        priv1 = SigningKey.generate(entropy=not_much_entropy)
        self.assertEqual(priv1.baselen, NIST192p.baselen)
        priv2 = SigningKey.generate(entropy=not_much_entropy)
        self.assertEqual(priv2.baselen, NIST192p.baselen)
        self.assertTruePrivkeysEqual(priv1, priv2)

        priv1 = SigningKey.from_secret_exponent(secexp=3)
        self.assertEqual(priv1.baselen, NIST192p.baselen)
        priv2 = SigningKey.from_secret_exponent(secexp=3)
        self.assertTruePrivkeysEqual(priv1, priv2)

        priv1 = SigningKey.from_secret_exponent(secexp=4, curve=NIST224p)
        self.assertEqual(priv1.baselen, NIST224p.baselen)

    def test_privkey_strings(self):
        priv1 = SigningKey.generate()
        s1 = priv1.to_string()
        self.assertEqual(type(s1), binary_type)
        self.assertEqual(len(s1), NIST192p.baselen)
        priv2 = SigningKey.from_string(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

        s1 = priv1.to_pem()
        self.assertEqual(type(s1), binary_type)
        self.assertTrue(s1.startswith(b"-----BEGIN EC PRIVATE KEY-----"))
        self.assertTrue(s1.strip().endswith(b"-----END EC PRIVATE KEY-----"))
        priv2 = SigningKey.from_pem(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

        s1 = priv1.to_der()
        self.assertEqual(type(s1), binary_type)
        priv2 = SigningKey.from_der(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

        priv1 = SigningKey.generate(curve=NIST256p)
        s1 = priv1.to_pem()
        self.assertEqual(type(s1), binary_type)
        self.assertTrue(s1.startswith(b"-----BEGIN EC PRIVATE KEY-----"))
        self.assertTrue(s1.strip().endswith(b"-----END EC PRIVATE KEY-----"))
        priv2 = SigningKey.from_pem(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

        s1 = priv1.to_der()
        self.assertEqual(type(s1), binary_type)
        priv2 = SigningKey.from_der(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

    def test_privkey_strings_brainpool(self):
        priv1 = SigningKey.generate(curve=BRAINPOOLP512r1)
        s1 = priv1.to_pem()
        self.assertEqual(type(s1), binary_type)
        self.assertTrue(s1.startswith(b"-----BEGIN EC PRIVATE KEY-----"))
        self.assertTrue(s1.strip().endswith(b"-----END EC PRIVATE KEY-----"))
        priv2 = SigningKey.from_pem(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

        s1 = priv1.to_der()
        self.assertEqual(type(s1), binary_type)
        priv2 = SigningKey.from_der(s1)
        self.assertTruePrivkeysEqual(priv1, priv2)

    def assertTruePubkeysEqual(self, pub1, pub2):
        self.assertEqual(pub1.pubkey.point, pub2.pubkey.point)
        self.assertEqual(pub1.pubkey.generator, pub2.pubkey.generator)
        self.assertEqual(pub1.curve, pub2.curve)

    def test_pubkey_strings(self):
        priv1 = SigningKey.generate()
        pub1 = priv1.get_verifying_key()
        s1 = pub1.to_string()
        self.assertEqual(type(s1), binary_type)
        self.assertEqual(len(s1), NIST192p.verifying_key_length)
        pub2 = VerifyingKey.from_string(s1)
        self.assertTruePubkeysEqual(pub1, pub2)

        priv1 = SigningKey.generate(curve=NIST256p)
        pub1 = priv1.get_verifying_key()
        s1 = pub1.to_string()
        self.assertEqual(type(s1), binary_type)
        self.assertEqual(len(s1), NIST256p.verifying_key_length)
        pub2 = VerifyingKey.from_string(s1, curve=NIST256p)
        self.assertTruePubkeysEqual(pub1, pub2)

        pub1_der = pub1.to_der()
        self.assertEqual(type(pub1_der), binary_type)
        pub2 = VerifyingKey.from_der(pub1_der)
        self.assertTruePubkeysEqual(pub1, pub2)

        self.assertRaises(
            der.UnexpectedDER, VerifyingKey.from_der, pub1_der + b"junk"
        )
        badpub = VerifyingKey.from_der(pub1_der)

        class FakeGenerator:
            def order(self):
                return 123456789

        class FakeCurveFp:
            def p(self):
                return int(
                    "6525534529039240705020950546962731340"
                    "4541085228058844382513856749047873406763"
                )

        badcurve = Curve(
            "unknown", FakeCurveFp(), FakeGenerator(), (1, 2, 3, 4, 5, 6), None
        )
        badpub.curve = badcurve
        badder = badpub.to_der()
        self.assertRaises(UnknownCurveError, VerifyingKey.from_der, badder)

        pem = pub1.to_pem()
        self.assertEqual(type(pem), binary_type)
        self.assertTrue(pem.startswith(b"-----BEGIN PUBLIC KEY-----"), pem)
        self.assertTrue(pem.strip().endswith(b"-----END PUBLIC KEY-----"), pem)
        pub2 = VerifyingKey.from_pem(pem)
        self.assertTruePubkeysEqual(pub1, pub2)

    def test_pubkey_strings_brainpool(self):
        priv1 = SigningKey.generate(curve=BRAINPOOLP512r1)
        pub1 = priv1.get_verifying_key()
        s1 = pub1.to_string()
        self.assertEqual(type(s1), binary_type)
        self.assertEqual(len(s1), BRAINPOOLP512r1.verifying_key_length)
        pub2 = VerifyingKey.from_string(s1, curve=BRAINPOOLP512r1)
        self.assertTruePubkeysEqual(pub1, pub2)

        pub1_der = pub1.to_der()
        self.assertEqual(type(pub1_der), binary_type)
        pub2 = VerifyingKey.from_der(pub1_der)
        self.assertTruePubkeysEqual(pub1, pub2)

    def test_vk_to_der_with_invalid_point_encoding(self):
        sk = SigningKey.generate()
        vk = sk.verifying_key

        with self.assertRaises(ValueError):
            vk.to_der("raw")

    def test_sk_to_der_with_invalid_point_encoding(self):
        sk = SigningKey.generate()

        with self.assertRaises(ValueError):
            sk.to_der("raw")

    def test_vk_from_der_garbage_after_curve_oid(self):
        type_oid_der = encoded_oid_ecPublicKey
        curve_oid_der = (
            der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1)) + b"garbage"
        )
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\x00\xff", None)
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(der.UnexpectedDER):
            VerifyingKey.from_der(to_decode)

    def test_vk_from_der_invalid_key_type(self):
        type_oid_der = der.encode_oid(*(1, 2, 3))
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\x00\xff", None)
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(der.UnexpectedDER):
            VerifyingKey.from_der(to_decode)

    def test_vk_from_der_garbage_after_point_string(self):
        type_oid_der = encoded_oid_ecPublicKey
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\x00\xff", None) + b"garbage"
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(der.UnexpectedDER):
            VerifyingKey.from_der(to_decode)

    def test_vk_from_der_invalid_bitstring(self):
        type_oid_der = encoded_oid_ecPublicKey
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\x08\xff", None)
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(der.UnexpectedDER):
            VerifyingKey.from_der(to_decode)

    def test_vk_from_der_with_invalid_length_of_encoding(self):
        type_oid_der = encoded_oid_ecPublicKey
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\xff" * 64, 0)
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_der(to_decode)

    def test_vk_from_der_with_raw_encoding(self):
        type_oid_der = encoded_oid_ecPublicKey
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        enc_type_der = der.encode_sequence(type_oid_der, curve_oid_der)
        point_der = der.encode_bitstring(b"\xff" * 48, 0)
        to_decode = der.encode_sequence(enc_type_der, point_der)

        with self.assertRaises(der.UnexpectedDER):
            VerifyingKey.from_der(to_decode)

    def test_signature_strings(self):
        priv1 = SigningKey.generate()
        pub1 = priv1.get_verifying_key()
        data = b"data"

        sig = priv1.sign(data)
        self.assertEqual(type(sig), binary_type)
        self.assertEqual(len(sig), NIST192p.signature_length)
        self.assertTrue(pub1.verify(sig, data))

        sig = priv1.sign(data, sigencode=sigencode_strings)
        self.assertEqual(type(sig), tuple)
        self.assertEqual(len(sig), 2)
        self.assertEqual(type(sig[0]), binary_type)
        self.assertEqual(type(sig[1]), binary_type)
        self.assertEqual(len(sig[0]), NIST192p.baselen)
        self.assertEqual(len(sig[1]), NIST192p.baselen)
        self.assertTrue(pub1.verify(sig, data, sigdecode=sigdecode_strings))

        sig_der = priv1.sign(data, sigencode=sigencode_der)
        self.assertEqual(type(sig_der), binary_type)
        self.assertTrue(pub1.verify(sig_der, data, sigdecode=sigdecode_der))

    def test_sigencode_string_canonize_no_change(self):
        r = 12
        s = 400
        order = SECP112r1.order

        new_r, new_s = sigdecode_string(
            sigencode_string_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(s, new_s)

    def test_sigencode_string_canonize(self):
        r = 12
        order = SECP112r1.order
        s = order - 10

        new_r, new_s = sigdecode_string(
            sigencode_string_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(order - s, new_s)

    def test_sigencode_strings_canonize_no_change(self):
        r = 12
        s = 400
        order = SECP112r1.order

        new_r, new_s = sigdecode_strings(
            sigencode_strings_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(s, new_s)

    def test_sigencode_strings_canonize(self):
        r = 12
        order = SECP112r1.order
        s = order - 10

        new_r, new_s = sigdecode_strings(
            sigencode_strings_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(order - s, new_s)

    def test_sigencode_der_canonize_no_change(self):
        r = 13
        s = 200
        order = SECP112r1.order

        new_r, new_s = sigdecode_der(
            sigencode_der_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(s, new_s)

    def test_sigencode_der_canonize(self):
        r = 13
        order = SECP112r1.order
        s = order - 14

        new_r, new_s = sigdecode_der(
            sigencode_der_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(order - s, new_s)

    def test_sigencode_der_canonize_with_close_to_half_order(self):
        r = 13
        order = SECP112r1.order
        s = order // 2 + 1

        regular_encode = sigencode_der(r, s, order)
        canonical_encode = sigencode_der_canonize(r, s, order)

        self.assertNotEqual(regular_encode, canonical_encode)

        new_r, new_s = sigdecode_der(
            sigencode_der_canonize(r, s, order), order
        )

        self.assertEqual(r, new_r)
        self.assertEqual(order - s, new_s)

    def test_sig_decode_strings_with_invalid_count(self):
        with self.assertRaises(MalformedSignature):
            sigdecode_strings([b"one", b"two", b"three"], 0xFF)

    def test_sig_decode_strings_with_wrong_r_len(self):
        with self.assertRaises(MalformedSignature):
            sigdecode_strings([b"one", b"two"], 0xFF)

    def test_sig_decode_strings_with_wrong_s_len(self):
        with self.assertRaises(MalformedSignature):
            sigdecode_strings([b"\xa0", b"\xb0\xff"], 0xFF)

    def test_verify_with_too_long_input(self):
        sk = SigningKey.generate()
        vk = sk.verifying_key

        with self.assertRaises(BadDigestError):
            vk.verify_digest(None, b"\x00" * 128)

    def test_sk_from_secret_exponent_with_wrong_sec_exponent(self):
        with self.assertRaises(MalformedPointError):
            SigningKey.from_secret_exponent(0)

    def test_sk_from_string_with_wrong_len_string(self):
        with self.assertRaises(MalformedPointError):
            SigningKey.from_string(b"\x01")

    def test_sk_from_der_with_junk_after_sequence(self):
        ver_der = der.encode_integer(1)
        to_decode = der.encode_sequence(ver_der) + b"garbage"

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_der_with_wrong_version(self):
        ver_der = der.encode_integer(0)
        to_decode = der.encode_sequence(ver_der)

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_der_invalid_const_tag(self):
        ver_der = der.encode_integer(1)
        privkey_der = der.encode_octet_string(b"\x00\xff")
        curve_oid_der = der.encode_oid(*(1, 2, 3))
        const_der = der.encode_constructed(1, curve_oid_der)
        to_decode = der.encode_sequence(
            ver_der, privkey_der, const_der, curve_oid_der
        )

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_der_garbage_after_privkey_oid(self):
        ver_der = der.encode_integer(1)
        privkey_der = der.encode_octet_string(b"\x00\xff")
        curve_oid_der = der.encode_oid(*(1, 2, 3)) + b"garbage"
        const_der = der.encode_constructed(0, curve_oid_der)
        to_decode = der.encode_sequence(
            ver_der, privkey_der, const_der, curve_oid_der
        )

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_der_with_short_privkey(self):
        ver_der = der.encode_integer(1)
        privkey_der = der.encode_octet_string(b"\x00\xff")
        curve_oid_der = der.encode_oid(*(1, 2, 840, 10045, 3, 1, 1))
        const_der = der.encode_constructed(0, curve_oid_der)
        to_decode = der.encode_sequence(
            ver_der, privkey_der, const_der, curve_oid_der
        )

        sk = SigningKey.from_der(to_decode)
        self.assertEqual(sk.privkey.secret_multiplier, 255)

    def test_sk_from_p8_der_with_wrong_version(self):
        ver_der = der.encode_integer(2)
        algorithm_der = der.encode_sequence(
            der.encode_oid(1, 2, 840, 10045, 2, 1),
            der.encode_oid(1, 2, 840, 10045, 3, 1, 1),
        )
        privkey_der = der.encode_octet_string(
            der.encode_sequence(
                der.encode_integer(1), der.encode_octet_string(b"\x00\xff")
            )
        )
        to_decode = der.encode_sequence(ver_der, algorithm_der, privkey_der)

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_p8_der_with_wrong_algorithm(self):
        ver_der = der.encode_integer(1)
        algorithm_der = der.encode_sequence(
            der.encode_oid(1, 2, 3), der.encode_oid(1, 2, 840, 10045, 3, 1, 1)
        )
        privkey_der = der.encode_octet_string(
            der.encode_sequence(
                der.encode_integer(1), der.encode_octet_string(b"\x00\xff")
            )
        )
        to_decode = der.encode_sequence(ver_der, algorithm_der, privkey_der)

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_p8_der_with_trailing_junk_after_algorithm(self):
        ver_der = der.encode_integer(1)
        algorithm_der = der.encode_sequence(
            der.encode_oid(1, 2, 840, 10045, 2, 1),
            der.encode_oid(1, 2, 840, 10045, 3, 1, 1),
            der.encode_octet_string(b"junk"),
        )
        privkey_der = der.encode_octet_string(
            der.encode_sequence(
                der.encode_integer(1), der.encode_octet_string(b"\x00\xff")
            )
        )
        to_decode = der.encode_sequence(ver_der, algorithm_der, privkey_der)

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sk_from_p8_der_with_trailing_junk_after_key(self):
        ver_der = der.encode_integer(1)
        algorithm_der = der.encode_sequence(
            der.encode_oid(1, 2, 840, 10045, 2, 1),
            der.encode_oid(1, 2, 840, 10045, 3, 1, 1),
        )
        privkey_der = der.encode_octet_string(
            der.encode_sequence(
                der.encode_integer(1), der.encode_octet_string(b"\x00\xff")
            )
            + der.encode_integer(999)
        )
        to_decode = der.encode_sequence(
            ver_der,
            algorithm_der,
            privkey_der,
            der.encode_octet_string(b"junk"),
        )

        with self.assertRaises(der.UnexpectedDER):
            SigningKey.from_der(to_decode)

    def test_sign_with_too_long_hash(self):
        sk = SigningKey.from_secret_exponent(12)

        with self.assertRaises(BadDigestError):
            sk.sign_digest(b"\xff" * 64)

    def test_hashfunc(self):
        sk = SigningKey.generate(curve=NIST256p, hashfunc=hashlib.sha256)
        data = b"security level is 128 bits"
        sig = sk.sign(data)
        vk = VerifyingKey.from_string(
            sk.get_verifying_key().to_string(),
            curve=NIST256p,
            hashfunc=hashlib.sha256,
        )
        self.assertTrue(vk.verify(sig, data))

        sk2 = SigningKey.generate(curve=NIST256p)
        sig2 = sk2.sign(data, hashfunc=hashlib.sha256)
        vk2 = VerifyingKey.from_string(
            sk2.get_verifying_key().to_string(),
            curve=NIST256p,
            hashfunc=hashlib.sha256,
        )
        self.assertTrue(vk2.verify(sig2, data))

        vk3 = VerifyingKey.from_string(
            sk.get_verifying_key().to_string(), curve=NIST256p
        )
        self.assertTrue(vk3.verify(sig, data, hashfunc=hashlib.sha256))

    def test_public_key_recovery(self):
        # Create keys
        curve = BRAINPOOLP160r1

        sk = SigningKey.generate(curve=curve)
        vk = sk.get_verifying_key()

        # Sign a message
        data = b"blahblah"
        signature = sk.sign(data)

        # Recover verifying keys
        recovered_vks = VerifyingKey.from_public_key_recovery(
            signature, data, curve
        )

        # Test if each pk is valid
        for recovered_vk in recovered_vks:
            # Test if recovered vk is valid for the data
            self.assertTrue(recovered_vk.verify(signature, data))

            # Test if properties are equal
            self.assertEqual(vk.curve, recovered_vk.curve)
            self.assertEqual(
                vk.default_hashfunc, recovered_vk.default_hashfunc
            )

        # Test if original vk is the list of recovered keys
        self.assertIn(
            vk.pubkey.point,
            [recovered_vk.pubkey.point for recovered_vk in recovered_vks],
        )

    def test_public_key_recovery_with_custom_hash(self):
        # Create keys
        curve = BRAINPOOLP160r1

        sk = SigningKey.generate(curve=curve, hashfunc=hashlib.sha256)
        vk = sk.get_verifying_key()

        # Sign a message
        data = b"blahblah"
        signature = sk.sign(data)

        # Recover verifying keys
        recovered_vks = VerifyingKey.from_public_key_recovery(
            signature,
            data,
            curve,
            hashfunc=hashlib.sha256,
            allow_truncate=True,
        )

        # Test if each pk is valid
        for recovered_vk in recovered_vks:
            # Test if recovered vk is valid for the data
            self.assertTrue(recovered_vk.verify(signature, data))

            # Test if properties are equal
            self.assertEqual(vk.curve, recovered_vk.curve)
            self.assertEqual(hashlib.sha256, recovered_vk.default_hashfunc)

        # Test if original vk is the list of recovered keys
        self.assertIn(
            vk.pubkey.point,
            [recovered_vk.pubkey.point for recovered_vk in recovered_vks],
        )

    def test_encoding(self):
        sk = SigningKey.from_secret_exponent(123456789)
        vk = sk.verifying_key

        exp = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )
        self.assertEqual(vk.to_string(), exp)
        self.assertEqual(vk.to_string("raw"), exp)
        self.assertEqual(vk.to_string("uncompressed"), b"\x04" + exp)
        self.assertEqual(vk.to_string("compressed"), b"\x02" + exp[:24])
        self.assertEqual(vk.to_string("hybrid"), b"\x06" + exp)

    def test_decoding(self):
        sk = SigningKey.from_secret_exponent(123456789)
        vk = sk.verifying_key

        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )

        from_raw = VerifyingKey.from_string(enc)
        self.assertEqual(from_raw.pubkey.point, vk.pubkey.point)

        from_uncompressed = VerifyingKey.from_string(b"\x04" + enc)
        self.assertEqual(from_uncompressed.pubkey.point, vk.pubkey.point)

        from_compressed = VerifyingKey.from_string(b"\x02" + enc[:24])
        self.assertEqual(from_compressed.pubkey.point, vk.pubkey.point)

        from_uncompressed = VerifyingKey.from_string(b"\x06" + enc)
        self.assertEqual(from_uncompressed.pubkey.point, vk.pubkey.point)

    def test_uncompressed_decoding_as_only_alowed(self):
        enc = (
            b"\x04"
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )
        vk = VerifyingKey.from_string(enc, valid_encodings=("uncompressed",))
        sk = SigningKey.from_secret_exponent(123456789)

        self.assertEqual(vk, sk.verifying_key)

    def test_raw_decoding_with_blocked_format(self):
        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )
        with self.assertRaises(MalformedPointError) as exp:
            VerifyingKey.from_string(enc, valid_encodings=("hybrid",))

        self.assertIn("hybrid", str(exp.exception))

    def test_decoding_with_unknown_format(self):
        with self.assertRaises(ValueError) as e:
            VerifyingKey.from_string(b"", valid_encodings=("raw", "foobar"))

        self.assertIn("Only uncompressed, compressed", str(e.exception))

    def test_uncompressed_decoding_with_blocked_format(self):
        enc = (
            b"\x04"
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )
        with self.assertRaises(MalformedPointError) as exp:
            VerifyingKey.from_string(enc, valid_encodings=("hybrid",))

        self.assertIn("Invalid X9.62 encoding", str(exp.exception))

    def test_hybrid_decoding_with_blocked_format(self):
        enc = (
            b"\x06"
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )
        with self.assertRaises(MalformedPointError) as exp:
            VerifyingKey.from_string(enc, valid_encodings=("uncompressed",))

        self.assertIn("Invalid X9.62 encoding", str(exp.exception))

    def test_hybrid_decoding_with_inconsistent_encoding_and_no_validation(
        self,
    ):
        sk = SigningKey.from_secret_exponent(123456789)
        vk = sk.verifying_key

        enc = vk.to_string("hybrid")
        self.assertEqual(enc[:1], b"\x06")
        enc = b"\x07" + enc[1:]

        b = VerifyingKey.from_string(
            enc, valid_encodings=("hybrid",), validate_point=False
        )

        self.assertEqual(vk, b)

    def test_compressed_decoding_with_blocked_format(self):
        enc = (
            b"\x02"
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )[:25]
        with self.assertRaises(MalformedPointError) as exp:
            VerifyingKey.from_string(enc, valid_encodings=("hybrid", "raw"))

        self.assertIn("(hybrid, raw)", str(exp.exception))

    def test_decoding_with_malformed_uncompressed(self):
        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x02" + enc)

    def test_decoding_with_malformed_compressed(self):
        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x01" + enc[:24])

    def test_decoding_with_inconsistent_hybrid(self):
        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x07" + enc)

    def test_decoding_with_inconsistent_hybrid_odd_point(self):
        sk = SigningKey.from_secret_exponent(123456791)
        vk = sk.verifying_key

        enc = vk.to_string("hybrid")
        self.assertEqual(enc[:1], b"\x07")
        enc = b"\x06" + enc[1:]

        with self.assertRaises(MalformedPointError):
            b = VerifyingKey.from_string(enc, valid_encodings=("hybrid",))

    def test_decoding_with_point_not_on_curve(self):
        enc = (
            b"\x0c\xe0\x1d\xe0d\x1c\x8eS\x8a\xc0\x9eK\xa8x !\xd5\xc2\xc3"
            b"\xfd\xc8\xa0c\xff\xfb\x02\xb9\xc4\x84)\x1a\x0f\x8b\x87\xa4"
            b"z\x8a#\xb5\x97\xecO\xb6\xa0HQ\x89*"
        )

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(enc[:47] + b"\x00")

    def test_decoding_with_point_at_infinity(self):
        # decoding it is unsupported, as it's not necessary to encode it
        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x00")

    def test_not_lying_on_curve(self):
        enc = number_to_string(NIST192p.curve.p(), NIST192p.curve.p() + 1)

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x02" + enc)

    def test_from_string_with_invalid_curve_too_short_ver_key_len(self):
        # both verifying_key_length and baselen are calculated internally
        # by the Curve constructor, but since we depend on them verify
        # that inconsistent values are detected
        curve = Curve("test", ecdsa.curve_192, ecdsa.generator_192, (1, 2))
        curve.verifying_key_length = 16
        curve.baselen = 32

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x00" * 16, curve)

    def test_from_string_with_invalid_curve_too_long_ver_key_len(self):
        # both verifying_key_length and baselen are calculated internally
        # by the Curve constructor, but since we depend on them verify
        # that inconsistent values are detected
        curve = Curve("test", ecdsa.curve_192, ecdsa.generator_192, (1, 2))
        curve.verifying_key_length = 16
        curve.baselen = 16

        with self.assertRaises(MalformedPointError):
            VerifyingKey.from_string(b"\x00" * 16, curve)


@pytest.mark.parametrize(
    "val,even", [(i, j) for i in range(256) for j in [True, False]]
)
def test_VerifyingKey_decode_with_small_values(val, even):
    enc = number_to_string(val, NIST192p.order)

    if even:
        enc = b"\x02" + enc
    else:
        enc = b"\x03" + enc

    # small values can both be actual valid public keys and not, verify that
    # only expected exceptions are raised if they are not
    try:
        vk = VerifyingKey.from_string(enc)
        assert isinstance(vk, VerifyingKey)
    except MalformedPointError:
        assert True


params = []
for curve in curves:
    for enc in ["raw", "uncompressed", "compressed", "hybrid"]:
        params.append(
            pytest.param(curve, enc, id="{0}-{1}".format(curve.name, enc))
        )


@pytest.mark.parametrize("curve,encoding", params)
def test_VerifyingKey_encode_decode(curve, encoding):
    sk = SigningKey.generate(curve=curve)
    vk = sk.verifying_key

    encoded = vk.to_string(encoding)

    from_enc = VerifyingKey.from_string(encoded, curve=curve)

    assert vk.pubkey.point == from_enc.pubkey.point


if "--fast" in sys.argv:  # pragma: no cover
    params = [NIST192p, BRAINPOOLP160r1]
else:
    params = curves


@pytest.mark.parametrize("curve", params)
def test_lengths(curve):
    priv = SigningKey.generate(curve=curve)
    pub1 = priv.get_verifying_key()
    pub2 = VerifyingKey.from_string(pub1.to_string(), curve)
    assert pub1.to_string() == pub2.to_string()
    assert len(pub1.to_string()) == curve.verifying_key_length
    sig = priv.sign(b"data")
    assert len(sig) == curve.signature_length


@pytest.mark.slow
class OpenSSL(unittest.TestCase):
    # test interoperability with OpenSSL tools. Note that openssl's ECDSA
    # sign/verify arguments changed between 0.9.8 and 1.0.0: the early
    # versions require "-ecdsa-with-SHA1", the later versions want just
    # "-SHA1" (or to leave out that argument entirely, which means the
    # signature will use some default digest algorithm, probably determined
    # by the key, probably always SHA1).
    #
    # openssl ecparam -name secp224r1 -genkey -out privkey.pem
    # openssl ec -in privkey.pem -text -noout # get the priv/pub keys
    # openssl dgst -ecdsa-with-SHA1 -sign privkey.pem -out data.sig data.txt
    # openssl asn1parse -in data.sig -inform DER
    #  data.sig is 64 bytes, probably 56b plus ASN1 overhead
    # openssl dgst -ecdsa-with-SHA1 -prverify privkey.pem -signature data.sig data.txt ; echo $?
    # openssl ec -in privkey.pem -pubout -out pubkey.pem
    # openssl ec -in privkey.pem -pubout -outform DER -out pubkey.der

    OPENSSL_SUPPORTED_CURVES = set(
        c.split(":")[0].strip()
        for c in run_openssl("ecparam -list_curves").split("\n")
    )

from b import c

from c import d

from c import d",
                SpecificImportRemovalVisitor,
            ),
            # Verify only one pass is generated even if we remove multiple statements
            (
                "while True:

from collections.abc import Mapping
from pathlib import Path

import pytest

from jsonschema_specifications import REGISTRY


def test_it_contains_metaschemas():
    schema = REGISTRY.contents("http://json-schema.org/draft-07/schema#")
    assert isinstance(schema, Mapping)
    assert schema["$id"] == "http://json-schema.org/draft-07/schema#"
    assert schema["title"] == "Core schema meta-schema"


def test_it_is_crawled():
    assert REGISTRY.crawl() == REGISTRY


@pytest.mark.parametrize(
    "ignored_relative_path",
    ["schemas/.DS_Store", "schemas/draft7/.DS_Store"],
)
def test_it_copes_with_dotfiles(ignored_relative_path):
    """
    Ignore files like .DS_Store if someone has actually caused one to exist.

    We test here through the private interface as of course the global has
    already loaded our schemas.
    """

    import jsonschema_specifications

    package = Path(jsonschema_specifications.__file__).parent

    ignored = package / ignored_relative_path
    ignored.touch()
    try:
        list(jsonschema_specifications._schemas())
    finally:
        ignored.unlink()

from contextlib import contextmanager
from io import BytesIO
from unittest import TestCase, mock
import importlib.metadata
import json
import subprocess
import sys
import urllib.request

import referencing.exceptions

from jsonschema import FormatChecker, exceptions, protocols, validators


class TestDeprecations(TestCase):
    def test_version(self):
        """
        As of v4.0.0, __version__ is deprecated in favor of importlib.metadata.
        """

        message = "Accessing jsonschema.__version__ is deprecated"
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import __version__

        self.assertEqual(__version__, importlib.metadata.version("jsonschema"))
        self.assertEqual(w.filename, __file__)

    def test_validators_ErrorTree(self):
        """
        As of v4.0.0, importing ErrorTree from jsonschema.validators is
        deprecated in favor of doing so from jsonschema.exceptions.
        """

        message = "Importing ErrorTree from jsonschema.validators is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema.validators import ErrorTree

        self.assertEqual(ErrorTree, exceptions.ErrorTree)
        self.assertEqual(w.filename, __file__)

    def test_import_ErrorTree(self):
        """
        As of v4.18.0, importing ErrorTree from the package root is
        deprecated in favor of doing so from jsonschema.exceptions.
        """

        message = "Importing ErrorTree directly from the jsonschema package "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import ErrorTree

        self.assertEqual(ErrorTree, exceptions.ErrorTree)
        self.assertEqual(w.filename, __file__)

    def test_ErrorTree_setitem(self):
        """
        As of v4.20.0, setting items on an ErrorTree is deprecated.
        """

        e = exceptions.ValidationError("some error", path=["foo"])
        tree = exceptions.ErrorTree()
        subtree = exceptions.ErrorTree(errors=[e])

        message = "ErrorTree.__setitem__ is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            tree["foo"] = subtree

        self.assertEqual(tree["foo"], subtree)
        self.assertEqual(w.filename, __file__)

    def test_import_FormatError(self):
        """
        As of v4.18.0, importing FormatError from the package root is
        deprecated in favor of doing so from jsonschema.exceptions.
        """

        message = "Importing FormatError directly from the jsonschema package "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import FormatError

        self.assertEqual(FormatError, exceptions.FormatError)
        self.assertEqual(w.filename, __file__)

    def test_import_Validator(self):
        """
        As of v4.19.0, importing Validator from the package root is
        deprecated in favor of doing so from jsonschema.protocols.
        """

        message = "Importing Validator directly from the jsonschema package "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import Validator

        self.assertEqual(Validator, protocols.Validator)
        self.assertEqual(w.filename, __file__)

    def test_validators_validators(self):
        """
        As of v4.0.0, accessing jsonschema.validators.validators is
        deprecated.
        """

        message = "Accessing jsonschema.validators.validators is deprecated"
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            value = validators.validators

        self.assertEqual(value, validators._VALIDATORS)
        self.assertEqual(w.filename, __file__)

    def test_validators_meta_schemas(self):
        """
        As of v4.0.0, accessing jsonschema.validators.meta_schemas is
        deprecated.
        """

        message = "Accessing jsonschema.validators.meta_schemas is deprecated"
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            value = validators.meta_schemas

        self.assertEqual(value, validators._META_SCHEMAS)
        self.assertEqual(w.filename, __file__)

    def test_RefResolver_in_scope(self):
        """
        As of v4.0.0, RefResolver.in_scope is deprecated.
        """

        resolver = validators._RefResolver.from_schema({})
        message = "jsonschema.RefResolver.in_scope is deprecated "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:  # noqa: SIM117
            with resolver.in_scope("foo"):
                pass

        self.assertEqual(w.filename, __file__)

    def test_Validator_is_valid_two_arguments(self):
        """
        As of v4.0.0, calling is_valid with two arguments (to provide a
        different schema) is deprecated.
        """

        validator = validators.Draft7Validator({})
        message = "Passing a schema to Validator.is_valid is deprecated "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            result = validator.is_valid("foo", {"type": "number"})

        self.assertFalse(result)
        self.assertEqual(w.filename, __file__)

    def test_Validator_iter_errors_two_arguments(self):
        """
        As of v4.0.0, calling iter_errors with two arguments (to provide a
        different schema) is deprecated.
        """

        validator = validators.Draft7Validator({})
        message = "Passing a schema to Validator.iter_errors is deprecated "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            error, = validator.iter_errors("foo", {"type": "number"})

        self.assertEqual(error.validator, "type")
        self.assertEqual(w.filename, __file__)

    def test_Validator_resolver(self):
        """
        As of v4.18.0, accessing Validator.resolver is deprecated.
        """

        validator = validators.Draft7Validator({})
        message = "Accessing Draft7Validator.resolver is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            self.assertIsInstance(validator.resolver, validators._RefResolver)

        self.assertEqual(w.filename, __file__)

    def test_RefResolver(self):
        """
        As of v4.18.0, RefResolver is fully deprecated.
        """

        message = "jsonschema.RefResolver is deprecated"
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import RefResolver
        self.assertEqual(w.filename, __file__)

        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema.validators import RefResolver  # noqa: F401
        self.assertEqual(w.filename, __file__)

    def test_RefResolutionError(self):
        """
        As of v4.18.0, RefResolutionError is deprecated in favor of directly
        catching errors from the referencing library.
        """

        message = "jsonschema.exceptions.RefResolutionError is deprecated"
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import RefResolutionError

        self.assertEqual(RefResolutionError, exceptions._RefResolutionError)
        self.assertEqual(w.filename, __file__)

        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema.exceptions import RefResolutionError

        self.assertEqual(RefResolutionError, exceptions._RefResolutionError)
        self.assertEqual(w.filename, __file__)

    def test_catching_Unresolvable_directly(self):
        """
        This behavior is the intended behavior (i.e. it's not deprecated), but
        given we do "tricksy" things in the iterim to wrap exceptions in a
        multiple inheritance subclass, we need to be extra sure it works and
        stays working.
        """
        validator = validators.Draft202012Validator({"$ref": "urn:nothing"})

        with self.assertRaises(referencing.exceptions.Unresolvable) as e:
            validator.validate(12)

        expected = referencing.exceptions.Unresolvable(ref="urn:nothing")
        self.assertEqual(
            (e.exception, str(e.exception)),
            (expected, "Unresolvable: urn:nothing"),
        )

    def test_catching_Unresolvable_via_RefResolutionError(self):
        """
        Until RefResolutionError is removed, it is still possible to catch
        exceptions from reference resolution using it, even though they may
        have been raised by referencing.
        """
        with self.assertWarns(DeprecationWarning):
            from jsonschema import RefResolutionError

        validator = validators.Draft202012Validator({"$ref": "urn:nothing"})

        with self.assertRaises(referencing.exceptions.Unresolvable) as u:
            validator.validate(12)

        with self.assertRaises(RefResolutionError) as e:
            validator.validate(12)

        self.assertEqual(
            (e.exception, str(e.exception)),
            (u.exception, "Unresolvable: urn:nothing"),
        )

    def test_WrappedReferencingError_hashability(self):
        """
        Ensure the wrapped referencing errors are hashable when possible.
        """
        with self.assertWarns(DeprecationWarning):
            from jsonschema import RefResolutionError

        validator = validators.Draft202012Validator({"$ref": "urn:nothing"})

        with self.assertRaises(referencing.exceptions.Unresolvable) as u:
            validator.validate(12)

        with self.assertRaises(RefResolutionError) as e:
            validator.validate(12)

        self.assertIn(e.exception, {u.exception})
        self.assertIn(u.exception, {e.exception})

    def test_Validator_subclassing(self):
        """
        As of v4.12.0, subclassing a validator class produces an explicit
        deprecation warning.

        This was never intended to be public API (and some comments over the
        years in issues said so, but obviously that's not a great way to make
        sure it's followed).

        A future version will explicitly raise an error.
        """

        message = "Subclassing validator classes is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            class Subclass(validators.Draft202012Validator):
                pass

        self.assertEqual(w.filename, __file__)

        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            class AnotherSubclass(validators.create(meta_schema={})):
                pass

    def test_FormatChecker_cls_checks(self):
        """
        As of v4.14.0, FormatChecker.cls_checks is deprecated without
        replacement.
        """

        self.addCleanup(FormatChecker.checkers.pop, "boom", None)

        message = "FormatChecker.cls_checks "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            FormatChecker.cls_checks("boom")

        self.assertEqual(w.filename, __file__)

    def test_draftN_format_checker(self):
        """
        As of v4.16.0, accessing jsonschema.draftn_format_checker is deprecated
        in favor of Validator.FORMAT_CHECKER.
        """

        message = "Accessing jsonschema.draft202012_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft202012_format_checker

        self.assertIs(
            draft202012_format_checker,
            validators.Draft202012Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        message = "Accessing jsonschema.draft201909_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft201909_format_checker

        self.assertIs(
            draft201909_format_checker,
            validators.Draft201909Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        message = "Accessing jsonschema.draft7_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft7_format_checker

        self.assertIs(
            draft7_format_checker,
            validators.Draft7Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        message = "Accessing jsonschema.draft6_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft6_format_checker

        self.assertIs(
            draft6_format_checker,
            validators.Draft6Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        message = "Accessing jsonschema.draft4_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft4_format_checker

        self.assertIs(
            draft4_format_checker,
            validators.Draft4Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        message = "Accessing jsonschema.draft3_format_checker is "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            from jsonschema import draft3_format_checker

        self.assertIs(
            draft3_format_checker,
            validators.Draft3Validator.FORMAT_CHECKER,
        )
        self.assertEqual(w.filename, __file__)

        with self.assertRaises(ImportError):
            from jsonschema import draft1234_format_checker  # noqa: F401

    def test_import_cli(self):
        """
        As of v4.17.0, importing jsonschema.cli is deprecated.
        """

        message = "The jsonschema CLI is deprecated and will be removed "
        with self.assertWarnsRegex(DeprecationWarning, message) as w:
            import jsonschema.cli
            importlib.reload(jsonschema.cli)

        self.assertEqual(w.filename, importlib.__file__)

    def test_cli(self):
        """
        As of v4.17.0, the jsonschema CLI is deprecated.
        """

        process = subprocess.run(
            [sys.executable, "-m", "jsonschema"],
            capture_output=True,
            check=True,
        )
        self.assertIn(b"The jsonschema CLI is deprecated ", process.stderr)

    def test_automatic_remote_retrieval(self):
        """
        Automatic retrieval of remote references is deprecated as of v4.18.0.
        """
        ref = "http://bar#/$defs/baz"
        schema = {"$defs": {"baz": {"type": "integer"}}}

        if "requests" in sys.modules:  # pragma: no cover
            self.addCleanup(
                sys.modules.__setitem__, "requests", sys.modules["requests"],
            )
        sys.modules["requests"] = None

        @contextmanager
        def fake_urlopen(request):
            self.assertIsInstance(request, urllib.request.Request)
            self.assertEqual(request.full_url, "http://bar")

            # Ha ha urllib.request.Request "normalizes" header names and
            # Request.get_header does not also normalize them...
            (header, value), = request.header_items()
            self.assertEqual(header.lower(), "user-agent")
            self.assertEqual(
                value, "python-jsonschema (deprecated $ref resolution)",
            )
            yield BytesIO(json.dumps(schema).encode("utf8"))

        validator = validators.Draft202012Validator({"$ref": ref})

        message = "Automatically retrieving remote references "
        patch = mock.patch.object(urllib.request, "urlopen", new=fake_urlopen)

        with patch, self.assertWarnsRegex(DeprecationWarning, message):
            self.assertEqual(
                (validator.is_valid({}), validator.is_valid(37)),
                (False, True),
            )

from contextlib import contextmanager
import json
import os
from pathlib import Path
import shutil
from typing import Any
import mutmut
from mutmut.__main__ import _run, walk_source_files, SourceFileMutationData, ensure_config_loaded


@contextmanager
def change_cwd(path):
    old_cwd = os.path.abspath(os.getcwd())
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(old_cwd)


def read_all_stats_for_project(project_path: Path) -> dict[str, dict]:
    """Create a single dict from all mutant results in *.meta files"""
    with change_cwd(project_path):
        ensure_config_loaded()

        stats = {}
        for p in walk_source_files():
            if mutmut.config.should_ignore_for_mutation(p): # type: ignore
                continue
            data = SourceFileMutationData(path=p)
            data.load()
            stats[str(data.meta_path)] = data.exit_code_by_key

        return stats


def read_json_file(path: Path):
    with open(path, 'r') as file:
        return json.load(file)


def write_json_file(path: Path, data: Any):
    with open(path, 'w') as file:
        json.dump(data, file, indent=2)


def asserts_results_did_not_change(project: str):
    """Runs mutmut on this project and verifies that the results stay the same for all mutations."""
    project_path = Path("..").parent / "e2e_projects" / project

    mutants_path = project_path / "mutants"
    shutil.rmtree(mutants_path, ignore_errors=True)

    # mutmut run
    with change_cwd(project_path):
        _run([], None)

    results = read_all_stats_for_project(project_path)

    snapshot_path = Path("tests") / "e2e" / "snapshots" / (project + ".json")

    if snapshot_path.exists():
        # compare results against previous snapshot
        previous_snapshot = read_json_file(snapshot_path)

        err_msg = f'Mutmut results changed for the E2E project \'{project}\'. If this change was on purpose, delete {snapshot_path} and rerun the tests.'
        assert results == previous_snapshot, err_msg
    else:
        # create the first snapshot
        write_json_file(snapshot_path, results)


def test_my_lib_result_snapshot():
    mutmut._reset_globals()
    asserts_results_did_not_change("my_lib")


def test_config_result_snapshot():
    mutmut._reset_globals()
    asserts_results_did_not_change("config")

from contextlib import redirect_stderr, redirect_stdout
from importlib import metadata
from io import StringIO
from json import JSONDecodeError
from pathlib import Path
from textwrap import dedent
from unittest import TestCase
import json
import os
import subprocess
import sys
import tempfile
import warnings

from jsonschema import Draft4Validator, Draft202012Validator
from jsonschema.exceptions import (
    SchemaError,
    ValidationError,
    _RefResolutionError,
)
from jsonschema.validators import _LATEST_VERSION, validate

with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    from jsonschema import cli


def fake_validator(*errors):
    errors = list(reversed(errors))

    class FakeValidator:
        def __init__(self, *args, **kwargs):
            pass

        def iter_errors(self, instance):
            if errors:
                return errors.pop()
            return []  # pragma: no cover

        @classmethod
        def check_schema(self, schema):
            pass

    return FakeValidator


def fake_open(all_contents):
    def open(path):
        contents = all_contents.get(path)
        if contents is None:
            raise FileNotFoundError(path)
        return StringIO(contents)
    return open


def _message_for(non_json):
    try:
        json.loads(non_json)
    except JSONDecodeError as error:
        return str(error)
    else:  # pragma: no cover
        raise RuntimeError("Tried and failed to capture a JSON dump error.")


class TestCLI(TestCase):
    def run_cli(
        self, argv, files=None, stdin=StringIO(), exit_code=0, **override,
    ):
        arguments = cli.parse_args(argv)
        arguments.update(override)

        self.assertFalse(hasattr(cli, "open"))
        cli.open = fake_open(files or {})
        try:
            stdout, stderr = StringIO(), StringIO()
            actual_exit_code = cli.run(
                arguments,
                stdin=stdin,
                stdout=stdout,
                stderr=stderr,
            )
        finally:
            del cli.open

        self.assertEqual(
            actual_exit_code, exit_code, msg=dedent(
                f"""
                    Expected an exit code of {exit_code} != {actual_exit_code}.

                    stdout: {stdout.getvalue()}

                    stderr: {stderr.getvalue()}
                """,
            ),
        )
        return stdout.getvalue(), stderr.getvalue()

    def assertOutputs(self, stdout="", stderr="", **kwargs):
        self.assertEqual(
            self.run_cli(**kwargs),
            (dedent(stdout), dedent(stderr)),
        )

    def test_invalid_instance(self):
        error = ValidationError("I am an error!", instance=12)
        self.assertOutputs(
            files=dict(
                some_schema='{"does not": "matter since it is stubbed"}',
                some_instance=json.dumps(error.instance),
            ),
            validator=fake_validator([error]),

            argv=["-i", "some_instance", "some_schema"],

            exit_code=1,
            stderr="12: I am an error!

from e import f",
                "import a

from functools import lru_cache
import json

import pytest

from referencing import Registry, Resource, exceptions
from referencing.jsonschema import DRAFT202012
from referencing.retrieval import to_cached_resource


class TestToCachedResource:
    def test_it_caches_retrieved_resources(self):
        contents = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        stack = [json.dumps(contents)]

        @to_cached_resource()
        def retrieve(uri):
            return stack.pop()

        registry = Registry(retrieve=retrieve)

        expected = Resource.from_contents(contents)

        got = registry.get_or_retrieve("urn:example:schema")
        assert got.value == expected

        # And a second time we get the same value.
        again = registry.get_or_retrieve("urn:example:schema")
        assert again.value is got.value

    def test_custom_loader(self):
        contents = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        stack = [json.dumps(contents)[::-1]]

        @to_cached_resource(loads=lambda s: json.loads(s[::-1]))
        def retrieve(uri):
            return stack.pop()

        registry = Registry(retrieve=retrieve)

        expected = Resource.from_contents(contents)

        got = registry.get_or_retrieve("urn:example:schema")
        assert got.value == expected

        # And a second time we get the same value.
        again = registry.get_or_retrieve("urn:example:schema")
        assert again.value is got.value

    def test_custom_from_contents(self):
        contents = {}
        stack = [json.dumps(contents)]

        @to_cached_resource(from_contents=DRAFT202012.create_resource)
        def retrieve(uri):
            return stack.pop()

        registry = Registry(retrieve=retrieve)

        expected = DRAFT202012.create_resource(contents)

        got = registry.get_or_retrieve("urn:example:schema")
        assert got.value == expected

        # And a second time we get the same value.
        again = registry.get_or_retrieve("urn:example:schema")
        assert again.value is got.value

    def test_custom_cache(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        mapping = {
            "urn:example:1": dict(schema, foo=1),
            "urn:example:2": dict(schema, foo=2),
            "urn:example:3": dict(schema, foo=3),
        }

        resources = {
            uri: Resource.from_contents(contents)
            for uri, contents in mapping.items()
        }

        @to_cached_resource(cache=lru_cache(maxsize=2))
        def retrieve(uri):
            return json.dumps(mapping.pop(uri))

        registry = Registry(retrieve=retrieve)

        got = registry.get_or_retrieve("urn:example:1")
        assert got.value == resources["urn:example:1"]
        assert registry.get_or_retrieve("urn:example:1").value is got.value
        assert registry.get_or_retrieve("urn:example:1").value is got.value

        got = registry.get_or_retrieve("urn:example:2")
        assert got.value == resources["urn:example:2"]
        assert registry.get_or_retrieve("urn:example:2").value is got.value
        assert registry.get_or_retrieve("urn:example:2").value is got.value

        # This still succeeds, but evicts the first URI
        got = registry.get_or_retrieve("urn:example:3")
        assert got.value == resources["urn:example:3"]
        assert registry.get_or_retrieve("urn:example:3").value is got.value
        assert registry.get_or_retrieve("urn:example:3").value is got.value

        # And now this fails (as we popped the value out of `mapping`)
        with pytest.raises(exceptions.Unretrievable):
            registry.get_or_retrieve("urn:example:1")

from hypothesis import given, settings, strategies as st
from latex_perfectionist.rules import dash_ranges as R
from latex_perfectionist.core.unicode_constants import EN_DASH

@given(a=st.integers(min_value=0, max_value=999),
       b=st.integers(min_value=0, max_value=999))
@settings(max_examples=1000)
def test_random_ranges(a, b, cfg):
    bad = f"pages {a}-{b}"
    rr  = R.audit(bad, cfg)
    assert rr.issues
    fixed = bad
    for f in sorted(rr.fixes, key=lambda x: x.start, reverse=True):
        fixed = fixed[:f.start] + f.replacement + fixed[f.end:]
    assert EN_DASH in fixed and not R.audit(fixed, cfg).issues

from hypothesis import given, settings, strategies as st
from latex_perfectionist.rules import expect_prob_brackets as R

@given(arg=st.text(min_size=1, max_size=5))
@settings(max_examples=500)
def test_random_parentheses(arg, cfg):
    sample = f"\\mathbb{{E}}({arg})"
    assert R.audit(sample, cfg).issues

from hypothesis import given, settings, strategies as st
from latex_perfectionist.rules import nested_scripts as R
from tests.property_util import digits

@given(base=st.text("xyz", min_size=1, max_size=1),
       inner=digits,
       outer=digits)
@settings(max_examples=800)
def test_two_level(base, inner, outer, cfg):
    bad = f"{base}_{{x_{{{inner}}}}}"
    assert R.audit(bad, cfg).issues

from latex_perfectionist.accessibility.color_contrast import ColorContrastChecker, Color

checker = ColorContrastChecker()

# Test various gray combinations to find one with low contrast
print("Gray contrast ratios:")
for fg_val in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:
    for bg_val in [0.5, 0.6, 0.7, 0.8, 0.9]:
        fg = Color(fg_val, fg_val, fg_val)
        bg = Color(bg_val, bg_val, bg_val)
        ratio = checker._calculate_contrast_ratio(fg, bg)
        if ratio < 4.5 and ratio > 1.5:  # Low contrast but not too low
            print(f"  Gray {fg_val} on {bg_val}: {ratio:.2f} (FAIL)")

# Perhaps the test meant to use gray 0.8 on gray 0.9?
gray08 = Color(0.8, 0.8, 0.8)
gray09 = Color(0.9, 0.9, 0.9)
print(f"

from latex_perfectionist.accessibility.structure_validator import StructureValidator
from latex_perfectionist.core.document import Document

validator = StructureValidator()

content = """
\\documentclass{article}
\\begin{document}
% Visual-only markup used extensively
\\textit{This entire paragraph is in italics for no semantic reason.
It just looks different. \\textit{Even nested italics.}}

% Emphasis spam
\\emph{Every} \\emph{single} \\emph{word} \\emph{is} \\emph{emphasized}!

% Mixed semantic usage
\\textbf{\\textit{\\underline{IMPORTANT: \\textsf{Read this}}}}

% Code without semantic markup
\\texttt{def function(): return True}  % Should use \\code
\\end{document}
"""

doc = Document(content, "test.tex")
errors = validator.check(doc)

print(f"Total errors: {len(errors)}")
for e in errors:
    print(f"  Line {e.line} [{e.severity}]: {e.message}")
    if e.context:
        print(f"    Context: {e.context}")

# Also check what the validator is counting
import re
emph_pattern = re.compile(r'\\emph\{')
textit_pattern = re.compile(r'\\textit\{')
texttt_pattern = re.compile(r'\\texttt\{')
code_pattern = re.compile(r'\\code\{')

emph_count = len(emph_pattern.findall(content))
textit_count = len(textit_pattern.findall(content))
texttt_count = len(texttt_pattern.findall(content))
code_count = len(code_pattern.findall(content))

print(f"

from latex_perfectionist.accessibility.structure_validator import StructureValidator
from latex_perfectionist.core.document import Document

validator = StructureValidator()

content = """
\\documentclass{article}
\\begin{document}
This is just a wall of text with no structure whatsoever.
No headings, no sections, no lists, no figures, no tables.
Just paragraph after paragraph of unstructured content.
This makes navigation extremely difficult for users.
Especially those using assistive technologies.
The document needs proper semantic structure.
""" + "

from latex_perfectionist.rules import double_periods as R

# Test with minimal config (like what test might be using)
minimal_cfg = {}

# Test config
cfg = {
    "orthography": {"en_dash_ranges": True},
    "punctuation": {
        "abbreviations": ["a.s.", "w.l.o.g.", "i.i.d.", "w.r.t.", "cf.", "e.g.", "i.e.", "etc."],
        "tie_words": ["Figure", "Table", "Theorem", "Lemma", "Corollary", "cf.", "Eq.", "eq.", "pp."],
        "detect_abbreviations": True,
        "detect_extended_abbreviations": True
    },
    "math": {
        "expect_brackets": True,
        "prob_brackets": True,
        "raisebox_ex": "0.2"
    }
}

print("=== Testing with minimal config ===")
test = "a.s.."
result = R.audit(test, minimal_cfg)
print(f"Test: {test}")
print(f"Issues: {len(result.issues)}")
print(f"Fixes: {len(result.fixes)}")

print("

from latex_perfectionist.rules import double_periods as R

cfg = {
    "punctuation": {
        "abbreviations": ["a.s.", "w.l.o.g.", "i.i.d.", "w.r.t.", "cf.", "e.g.", "i.e.", "etc."],
    }
}

test_cases = [
    "'i.e...'",
    '"a.s.."',
    "(w.l.o.g..)",
    "cf..!",
    "etc..?",
]

def apply_fixes(txt, fixes):
    """Apply fixes to text."""
    for f in sorted(fixes, key=lambda x: x.start, reverse=True):
        txt = txt[:f.start] + f.replacement + txt[f.end:]
    return txt

for test in test_cases:
    result = R.audit(test, cfg)
    print(f"

from latex_perfectionist.rules import double_periods as R
from tests.conftest            import run_rule

BAD = [
    "It holds a.s..",
    "Valid w.l.o.g.. However…",
    "Independent i.i.d.. sample.",
    "We work w.r.t.. the measure.",
    "% a.s.. inside comment should still be caught",
]

GOOD = [
    "It holds a.s.",
    "Valid w.l.o.g., however…",
    "Independent i.i.d. sample.",
    "We work w.r.t. the measure.",
]

def test_double_periods(cfg):
    run_rule(R, BAD, GOOD, cfg)

from latex_perfectionist.rules import expect_prob_brackets as R
from tests.conftest import run_rule
BAD=[r"\mathbb{E}(X)", r"\mathbb{P}  (A)"]
GOOD=[r"\mathbb{E}[X]", r"\mathbb{P}[A]"]
def test_exp_prob(cfg):
    run_rule(R, BAD, GOOD, cfg)

from latex_perfectionist.rules import tie_words as R
from tests.conftest            import run_rule

BAD = [
    "Figure 1 shows …",
    "Theorem  2 is trivial.",
    "cf.  Lemma 3",
]

GOOD = [
    "Figure~1 shows …",
    "Theorem~2 is trivial.",
    "cf.~Lemma~3",
]

def test_ties(cfg):
    run_rule(R, BAD, GOOD, cfg)

from math import nan
from unittest import TestCase

from jsonschema._utils import equal


class TestEqual(TestCase):
    def test_none(self):
        self.assertTrue(equal(None, None))

    def test_nan(self):
        self.assertTrue(equal(nan, nan))


class TestDictEqual(TestCase):
    def test_equal_dictionaries(self):
        dict_1 = {"a": "b", "c": "d"}
        dict_2 = {"c": "d", "a": "b"}
        self.assertTrue(equal(dict_1, dict_2))

    def test_equal_dictionaries_with_nan(self):
        dict_1 = {"a": nan, "c": "d"}
        dict_2 = {"c": "d", "a": nan}
        self.assertTrue(equal(dict_1, dict_2))

    def test_missing_key(self):
        dict_1 = {"a": "b", "c": "d"}
        dict_2 = {"c": "d", "x": "b"}
        self.assertFalse(equal(dict_1, dict_2))

    def test_additional_key(self):
        dict_1 = {"a": "b", "c": "d"}
        dict_2 = {"c": "d", "a": "b", "x": "x"}
        self.assertFalse(equal(dict_1, dict_2))

    def test_missing_value(self):
        dict_1 = {"a": "b", "c": "d"}
        dict_2 = {"c": "d", "a": "x"}
        self.assertFalse(equal(dict_1, dict_2))

    def test_empty_dictionaries(self):
        dict_1 = {}
        dict_2 = {}
        self.assertTrue(equal(dict_1, dict_2))

    def test_one_none(self):
        dict_1 = None
        dict_2 = {"a": "b", "c": "d"}
        self.assertFalse(equal(dict_1, dict_2))

    def test_same_item(self):
        dict_1 = {"a": "b", "c": "d"}
        self.assertTrue(equal(dict_1, dict_1))

    def test_nested_equal(self):
        dict_1 = {"a": {"a": "b", "c": "d"}, "c": "d"}
        dict_2 = {"c": "d", "a": {"a": "b", "c": "d"}}
        self.assertTrue(equal(dict_1, dict_2))

    def test_nested_dict_unequal(self):
        dict_1 = {"a": {"a": "b", "c": "d"}, "c": "d"}
        dict_2 = {"c": "d", "a": {"a": "b", "c": "x"}}
        self.assertFalse(equal(dict_1, dict_2))

    def test_mixed_nested_equal(self):
        dict_1 = {"a": ["a", "b", "c", "d"], "c": "d"}
        dict_2 = {"c": "d", "a": ["a", "b", "c", "d"]}
        self.assertTrue(equal(dict_1, dict_2))

    def test_nested_list_unequal(self):
        dict_1 = {"a": ["a", "b", "c", "d"], "c": "d"}
        dict_2 = {"c": "d", "a": ["b", "c", "d", "a"]}
        self.assertFalse(equal(dict_1, dict_2))


class TestListEqual(TestCase):
    def test_equal_lists(self):
        list_1 = ["a", "b", "c"]
        list_2 = ["a", "b", "c"]
        self.assertTrue(equal(list_1, list_2))

    def test_equal_lists_with_nan(self):
        list_1 = ["a", nan, "c"]
        list_2 = ["a", nan, "c"]
        self.assertTrue(equal(list_1, list_2))

    def test_unsorted_lists(self):
        list_1 = ["a", "b", "c"]
        list_2 = ["b", "b", "a"]
        self.assertFalse(equal(list_1, list_2))

    def test_first_list_larger(self):
        list_1 = ["a", "b", "c"]
        list_2 = ["a", "b"]
        self.assertFalse(equal(list_1, list_2))

    def test_second_list_larger(self):
        list_1 = ["a", "b"]
        list_2 = ["a", "b", "c"]
        self.assertFalse(equal(list_1, list_2))

    def test_list_with_none_unequal(self):
        list_1 = ["a", "b", None]
        list_2 = ["a", "b", "c"]
        self.assertFalse(equal(list_1, list_2))

        list_1 = ["a", "b", None]
        list_2 = [None, "b", "c"]
        self.assertFalse(equal(list_1, list_2))

    def test_list_with_none_equal(self):
        list_1 = ["a", None, "c"]
        list_2 = ["a", None, "c"]
        self.assertTrue(equal(list_1, list_2))

    def test_empty_list(self):
        list_1 = []
        list_2 = []
        self.assertTrue(equal(list_1, list_2))

    def test_one_none(self):
        list_1 = None
        list_2 = []
        self.assertFalse(equal(list_1, list_2))

    def test_same_list(self):
        list_1 = ["a", "b", "c"]
        self.assertTrue(equal(list_1, list_1))

    def test_equal_nested_lists(self):
        list_1 = ["a", ["b", "c"], "d"]
        list_2 = ["a", ["b", "c"], "d"]
        self.assertTrue(equal(list_1, list_2))

    def test_unequal_nested_lists(self):
        list_1 = ["a", ["b", "c"], "d"]
        list_2 = ["a", [], "c"]
        self.assertFalse(equal(list_1, list_2))

from mutmut import __version__
from mutmut.__main__ import cli
from click.testing import CliRunner

def test_cli_version():
    result = CliRunner().invoke(cli, ["--version"])

    assert result.exit_code == 0
    assert __version__ in result.output

from mutmut.trampoline_templates import (
    trampoline_impl,
    yield_from_trampoline_impl,
)
from mutmut.file_mutation import mutate_file_contents

def mutated_module(source: str) -> str:
    mutated_code, _ = mutate_file_contents('', source)
    return mutated_code


def test_mutate_file_contents():
    source = """
a + 1

def foo(a, b, c):
    return a + b * c
"""
    trampolines = trampoline_impl.removesuffix('

from pathlib import Path
import json
import os

import pytest

from referencing import Registry
from referencing.exceptions import Unresolvable
import referencing.jsonschema


class SuiteNotFound(Exception):
    def __str__(self):  # pragma: no cover
        return (
            "Cannot find the referencing suite. "
            "Set the REFERENCING_SUITE environment variable to the path to "
            "the suite, or run the test suite from alongside a full checkout "
            "of the git repository."
        )


if "REFERENCING_SUITE" in os.environ:  # pragma: no cover
    SUITE = Path(os.environ["REFERENCING_SUITE"]) / "tests"
else:
    SUITE = Path(__file__).parent.parent.parent / "suite/tests"
if not SUITE.is_dir():  # pragma: no cover
    raise SuiteNotFound()
DIALECT_IDS = json.loads(SUITE.joinpath("specifications.json").read_text())


@pytest.mark.parametrize(
    "test_path",
    [
        pytest.param(each, id=f"{each.parent.name}-{each.stem}")
        for each in SUITE.glob("*/**/*.json")
    ],
)
def test_referencing_suite(test_path, subtests):
    dialect_id = DIALECT_IDS[test_path.relative_to(SUITE).parts[0]]
    specification = referencing.jsonschema.specification_with(dialect_id)
    loaded = json.loads(test_path.read_text())
    registry = loaded["registry"]
    registry = Registry().with_resources(
        (uri, specification.create_resource(contents))
        for uri, contents in loaded["registry"].items()
    )
    for test in loaded["tests"]:
        with subtests.test(test=test):
            if "normalization" in test_path.stem:
                pytest.xfail("APIs need to change for proper URL support.")

            resolver = registry.resolver(base_uri=test.get("base_uri", ""))

            if test.get("error"):
                with pytest.raises(Unresolvable):
                    resolver.lookup(test["ref"])
            else:
                resolved = resolver.lookup(test["ref"])
                assert resolved.contents == test["target"]

                then = test.get("then")
                while then:  # pragma: no cover
                    with subtests.test(test=test, then=then):
                        resolved = resolved.resolver.lookup(then["ref"])
                        assert resolved.contents == then["target"]
                    then = then.get("then")

from rpds import HashTrieMap
import pytest

from referencing import Anchor, Registry, Resource, Specification, exceptions
from referencing.jsonschema import DRAFT202012

ID_AND_CHILDREN = Specification(
    name="id-and-children",
    id_of=lambda contents: contents.get("ID"),
    subresources_of=lambda contents: contents.get("children", []),
    anchors_in=lambda specification, contents: [
        Anchor(
            name=name,
            resource=specification.create_resource(contents=each),
        )
        for name, each in contents.get("anchors", {}).items()
    ],
    maybe_in_subresource=lambda segments, resolver, subresource: (
        resolver.in_subresource(subresource)
        if not len(segments) % 2
        and all(each == "children" for each in segments[::2])
        else resolver
    ),
)


def blow_up(uri):  # pragma: no cover
    """
    A retriever suitable for use in tests which expect it never to be used.
    """
    raise RuntimeError("This retrieve function expects to never be called!")


class TestRegistry:
    def test_with_resource(self):
        """
        Adding a resource to the registry then allows re-retrieving it.
        """

        resource = Resource.opaque(contents={"foo": "bar"})
        uri = "urn:example"
        registry = Registry().with_resource(uri=uri, resource=resource)
        assert registry[uri] is resource

    def test_with_resources(self):
        """
        Adding multiple resources to the registry is like adding each one.
        """

        one = Resource.opaque(contents={})
        two = Resource(contents={"foo": "bar"}, specification=ID_AND_CHILDREN)
        registry = Registry().with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/foo/bar", two),
            ],
        )
        assert registry == Registry().with_resource(
            uri="http://example.com/1",
            resource=one,
        ).with_resource(
            uri="http://example.com/foo/bar",
            resource=two,
        )

    def test_matmul_resource(self):
        uri = "urn:example:resource"
        resource = ID_AND_CHILDREN.create_resource({"ID": uri, "foo": 12})
        registry = resource @ Registry()
        assert registry == Registry().with_resource(uri, resource)

    def test_matmul_many_resources(self):
        one_uri = "urn:example:one"
        one = ID_AND_CHILDREN.create_resource({"ID": one_uri, "foo": 12})

        two_uri = "urn:example:two"
        two = ID_AND_CHILDREN.create_resource({"ID": two_uri, "foo": 12})

        registry = [one, two] @ Registry()
        assert registry == Registry().with_resources(
            [(one_uri, one), (two_uri, two)],
        )

    def test_matmul_resource_without_id(self):
        resource = Resource.opaque(contents={"foo": "bar"})
        with pytest.raises(exceptions.NoInternalID) as e:
            resource @ Registry()
        assert e.value == exceptions.NoInternalID(resource=resource)

    def test_with_contents_from_json_schema(self):
        uri = "urn:example"
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        registry = Registry().with_contents([(uri, schema)])

        expected = Resource(contents=schema, specification=DRAFT202012)
        assert registry[uri] == expected

    def test_with_contents_and_default_specification(self):
        uri = "urn:example"
        registry = Registry().with_contents(
            [(uri, {"foo": "bar"})],
            default_specification=Specification.OPAQUE,
        )
        assert registry[uri] == Resource.opaque({"foo": "bar"})

    def test_len(self):
        total = 5
        registry = Registry().with_contents(
            [(str(i), {"foo": "bar"}) for i in range(total)],
            default_specification=Specification.OPAQUE,
        )
        assert len(registry) == total

    def test_bool_empty(self):
        assert not Registry()

    def test_bool_not_empty(self):
        registry = Registry().with_contents(
            [(str(i), {"foo": "bar"}) for i in range(3)],
            default_specification=Specification.OPAQUE,
        )
        assert registry

    def test_iter(self):
        registry = Registry().with_contents(
            [(str(i), {"foo": "bar"}) for i in range(8)],
            default_specification=Specification.OPAQUE,
        )
        assert set(registry) == {str(i) for i in range(8)}

    def test_crawl_still_has_top_level_resource(self):
        resource = Resource.opaque({"foo": "bar"})
        uri = "urn:example"
        registry = Registry({uri: resource}).crawl()
        assert registry[uri] is resource

    def test_crawl_finds_a_subresource(self):
        child_id = "urn:child"
        root = ID_AND_CHILDREN.create_resource(
            {"ID": "urn:root", "children": [{"ID": child_id, "foo": 12}]},
        )
        registry = root @ Registry()
        with pytest.raises(LookupError):
            registry[child_id]

        expected = ID_AND_CHILDREN.create_resource({"ID": child_id, "foo": 12})
        assert registry.crawl()[child_id] == expected

    def test_crawl_finds_anchors_with_id(self):
        resource = ID_AND_CHILDREN.create_resource(
            {"ID": "urn:bar", "anchors": {"foo": 12}},
        )
        registry = resource @ Registry()

        assert registry.crawl().anchor(resource.id(), "foo").value == Anchor(
            name="foo",
            resource=ID_AND_CHILDREN.create_resource(12),
        )

    def test_crawl_finds_anchors_no_id(self):
        resource = ID_AND_CHILDREN.create_resource({"anchors": {"foo": 12}})
        registry = Registry().with_resource("urn:root", resource)

        assert registry.crawl().anchor("urn:root", "foo").value == Anchor(
            name="foo",
            resource=ID_AND_CHILDREN.create_resource(12),
        )

    def test_contents(self):
        resource = Resource.opaque({"foo": "bar"})
        uri = "urn:example"
        registry = Registry().with_resource(uri, resource)
        assert registry.contents(uri) == {"foo": "bar"}

    def test_getitem_strips_empty_fragments(self):
        uri = "http://example.com/"
        resource = ID_AND_CHILDREN.create_resource({"ID": uri + "#"})
        registry = resource @ Registry()
        assert registry[uri] == registry[uri + "#"] == resource

    def test_contents_strips_empty_fragments(self):
        uri = "http://example.com/"
        resource = ID_AND_CHILDREN.create_resource({"ID": uri + "#"})
        registry = resource @ Registry()
        assert (
            registry.contents(uri)
            == registry.contents(uri + "#")
            == {"ID": uri + "#"}
        )

    def test_contents_nonexistent_resource(self):
        registry = Registry()
        with pytest.raises(exceptions.NoSuchResource) as e:
            registry.contents("urn:example")
        assert e.value == exceptions.NoSuchResource(ref="urn:example")

    def test_crawled_anchor(self):
        resource = ID_AND_CHILDREN.create_resource({"anchors": {"foo": "bar"}})
        registry = Registry().with_resource("urn:example", resource)
        retrieved = registry.anchor("urn:example", "foo")
        assert retrieved.value == Anchor(
            name="foo",
            resource=ID_AND_CHILDREN.create_resource("bar"),
        )
        assert retrieved.registry == registry.crawl()

    def test_anchor_in_nonexistent_resource(self):
        registry = Registry()
        with pytest.raises(exceptions.NoSuchResource) as e:
            registry.anchor("urn:example", "foo")
        assert e.value == exceptions.NoSuchResource(ref="urn:example")

    def test_init(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = Registry(
            {
                "http://example.com/1": one,
                "http://example.com/foo/bar": two,
            },
        )
        assert (
            registry
            == Registry()
            .with_resources(
                [
                    ("http://example.com/1", one),
                    ("http://example.com/foo/bar", two),
                ],
            )
            .crawl()
        )

    def test_dict_conversion(self):
        """
        Passing a `dict` to `Registry` gets converted to a `HashTrieMap`.

        So continuing to use the registry works.
        """

        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = Registry(
            {"http://example.com/1": one},
        ).with_resource("http://example.com/foo/bar", two)
        assert (
            registry.crawl()
            == Registry()
            .with_resources(
                [
                    ("http://example.com/1", one),
                    ("http://example.com/foo/bar", two),
                ],
            )
            .crawl()
        )

    def test_no_such_resource(self):
        registry = Registry()
        with pytest.raises(exceptions.NoSuchResource) as e:
            registry["urn:bigboom"]
        assert e.value == exceptions.NoSuchResource(ref="urn:bigboom")

    def test_combine(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        three = ID_AND_CHILDREN.create_resource({"baz": "quux"})
        four = ID_AND_CHILDREN.create_resource({"anchors": {"foo": 12}})

        first = Registry({"http://example.com/1": one})
        second = Registry().with_resource("http://example.com/foo/bar", two)
        third = Registry(
            {
                "http://example.com/1": one,
                "http://example.com/baz": three,
            },
        )
        fourth = (
            Registry()
            .with_resource(
                "http://example.com/foo/quux",
                four,
            )
            .crawl()
        )
        assert first.combine(second, third, fourth) == Registry(
            [
                ("http://example.com/1", one),
                ("http://example.com/baz", three),
                ("http://example.com/foo/quux", four),
            ],
            anchors=HashTrieMap(
                {
                    ("http://example.com/foo/quux", "foo"): Anchor(
                        name="foo",
                        resource=ID_AND_CHILDREN.create_resource(12),
                    ),
                },
            ),
        ).with_resource("http://example.com/foo/bar", two)

    def test_combine_self(self):
        """
        Combining a registry with itself short-circuits.

        This is a performance optimization -- otherwise we do lots more work
        (in jsonschema this seems to correspond to making the test suite take
         *3x* longer).
        """

        registry = Registry({"urn:foo": "bar"})
        assert registry.combine(registry) is registry

    def test_combine_with_uncrawled_resources(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        three = ID_AND_CHILDREN.create_resource({"baz": "quux"})

        first = Registry().with_resource("http://example.com/1", one)
        second = Registry().with_resource("http://example.com/foo/bar", two)
        third = Registry(
            {
                "http://example.com/1": one,
                "http://example.com/baz": three,
            },
        )
        expected = Registry(
            [
                ("http://example.com/1", one),
                ("http://example.com/foo/bar", two),
                ("http://example.com/baz", three),
            ],
        )
        combined = first.combine(second, third)
        assert combined != expected
        assert combined.crawl() == expected

    def test_combine_with_single_retrieve(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        three = ID_AND_CHILDREN.create_resource({"baz": "quux"})

        def retrieve(uri):  # pragma: no cover
            pass

        first = Registry().with_resource("http://example.com/1", one)
        second = Registry(
            retrieve=retrieve,
        ).with_resource("http://example.com/2", two)
        third = Registry().with_resource("http://example.com/3", three)

        assert first.combine(second, third) == Registry(
            retrieve=retrieve,
        ).with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/2", two),
                ("http://example.com/3", three),
            ],
        )
        assert second.combine(first, third) == Registry(
            retrieve=retrieve,
        ).with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/2", two),
                ("http://example.com/3", three),
            ],
        )

    def test_combine_with_common_retrieve(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        three = ID_AND_CHILDREN.create_resource({"baz": "quux"})

        def retrieve(uri):  # pragma: no cover
            pass

        first = Registry(retrieve=retrieve).with_resource(
            "http://example.com/1",
            one,
        )
        second = Registry(
            retrieve=retrieve,
        ).with_resource("http://example.com/2", two)
        third = Registry(retrieve=retrieve).with_resource(
            "http://example.com/3",
            three,
        )

        assert first.combine(second, third) == Registry(
            retrieve=retrieve,
        ).with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/2", two),
                ("http://example.com/3", three),
            ],
        )
        assert second.combine(first, third) == Registry(
            retrieve=retrieve,
        ).with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/2", two),
                ("http://example.com/3", three),
            ],
        )

    def test_combine_conflicting_retrieve(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        three = ID_AND_CHILDREN.create_resource({"baz": "quux"})

        def foo_retrieve(uri):  # pragma: no cover
            pass

        def bar_retrieve(uri):  # pragma: no cover
            pass

        first = Registry(retrieve=foo_retrieve).with_resource(
            "http://example.com/1",
            one,
        )
        second = Registry().with_resource("http://example.com/2", two)
        third = Registry(retrieve=bar_retrieve).with_resource(
            "http://example.com/3",
            three,
        )

        with pytest.raises(Exception, match="conflict.*retriev"):
            first.combine(second, third)

    def test_remove(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = Registry({"urn:foo": one, "urn:bar": two})
        assert registry.remove("urn:foo") == Registry({"urn:bar": two})

    def test_remove_uncrawled(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = Registry().with_resources(
            [("urn:foo", one), ("urn:bar", two)],
        )
        assert registry.remove("urn:foo") == Registry().with_resource(
            "urn:bar",
            two,
        )

    def test_remove_with_anchors(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"anchors": {"foo": "bar"}})
        registry = (
            Registry()
            .with_resources(
                [("urn:foo", one), ("urn:bar", two)],
            )
            .crawl()
        )
        assert (
            registry.remove("urn:bar")
            == Registry()
            .with_resource(
                "urn:foo",
                one,
            )
            .crawl()
        )

    def test_remove_nonexistent_uri(self):
        with pytest.raises(exceptions.NoSuchResource) as e:
            Registry().remove("urn:doesNotExist")
        assert e.value == exceptions.NoSuchResource(ref="urn:doesNotExist")

    def test_retrieve(self):
        foo = Resource.opaque({"foo": "bar"})
        registry = Registry(retrieve=lambda uri: foo)
        assert registry.get_or_retrieve("urn:example").value == foo

    def test_retrieve_arbitrary_exception(self):
        foo = Resource.opaque({"foo": "bar"})

        def retrieve(uri):
            if uri == "urn:succeed":
                return foo
            raise Exception("Oh no!")

        registry = Registry(retrieve=retrieve)
        assert registry.get_or_retrieve("urn:succeed").value == foo
        with pytest.raises(exceptions.Unretrievable):
            registry.get_or_retrieve("urn:uhoh")

    def test_retrieve_no_such_resource(self):
        foo = Resource.opaque({"foo": "bar"})

        def retrieve(uri):
            if uri == "urn:succeed":
                return foo
            raise exceptions.NoSuchResource(ref=uri)

        registry = Registry(retrieve=retrieve)
        assert registry.get_or_retrieve("urn:succeed").value == foo
        with pytest.raises(exceptions.NoSuchResource):
            registry.get_or_retrieve("urn:uhoh")

    def test_retrieve_cannot_determine_specification(self):
        def retrieve(uri):
            return Resource.from_contents({})

        registry = Registry(retrieve=retrieve)
        with pytest.raises(exceptions.CannotDetermineSpecification):
            registry.get_or_retrieve("urn:uhoh")

    def test_retrieve_already_available_resource(self):
        foo = Resource.opaque({"foo": "bar"})
        registry = Registry({"urn:example": foo}, retrieve=blow_up)
        assert registry["urn:example"] == foo
        assert registry.get_or_retrieve("urn:example").value == foo

    def test_retrieve_first_checks_crawlable_resource(self):
        child = ID_AND_CHILDREN.create_resource({"ID": "urn:child", "foo": 12})
        root = ID_AND_CHILDREN.create_resource({"children": [child.contents]})
        registry = Registry(retrieve=blow_up).with_resource("urn:root", root)
        assert registry.crawl()["urn:child"] == child

    def test_resolver(self):
        one = Resource.opaque(contents={})
        registry = Registry({"http://example.com": one})
        resolver = registry.resolver(base_uri="http://example.com")
        assert resolver.lookup("#").contents == {}

    def test_resolver_with_root_identified(self):
        root = ID_AND_CHILDREN.create_resource({"ID": "http://example.com"})
        resolver = Registry().resolver_with_root(root)
        assert resolver.lookup("http://example.com").contents == root.contents
        assert resolver.lookup("#").contents == root.contents

    def test_resolver_with_root_unidentified(self):
        root = Resource.opaque(contents={})
        resolver = Registry().resolver_with_root(root)
        assert resolver.lookup("#").contents == root.contents

    def test_repr(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = Registry().with_resources(
            [
                ("http://example.com/1", one),
                ("http://example.com/foo/bar", two),
            ],
        )
        assert repr(registry) == "<Registry (2 uncrawled resources)>"
        assert repr(registry.crawl()) == "<Registry (2 resources)>"

    def test_repr_mixed_crawled(self):
        one = Resource.opaque(contents={})
        two = ID_AND_CHILDREN.create_resource({"foo": "bar"})
        registry = (
            Registry(
                {"http://example.com/1": one},
            )
            .crawl()
            .with_resource(uri="http://example.com/foo/bar", resource=two)
        )
        assert repr(registry) == "<Registry (2 resources, 1 uncrawled)>"

    def test_repr_one_resource(self):
        registry = Registry().with_resource(
            uri="http://example.com/1",
            resource=Resource.opaque(contents={}),
        )
        assert repr(registry) == "<Registry (1 uncrawled resource)>"

    def test_repr_empty(self):
        assert repr(Registry()) == "<Registry (0 resources)>"


class TestResource:
    def test_from_contents_from_json_schema(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        resource = Resource.from_contents(schema)
        assert resource == Resource(contents=schema, specification=DRAFT202012)

    def test_from_contents_with_no_discernible_information(self):
        """
        Creating a resource with no discernible way to see what
        specification it belongs to (e.g. no ``$schema`` keyword for JSON
        Schema) raises an error.
        """

        with pytest.raises(exceptions.CannotDetermineSpecification):
            Resource.from_contents({"foo": "bar"})

    def test_from_contents_with_no_discernible_information_and_default(self):
        resource = Resource.from_contents(
            {"foo": "bar"},
            default_specification=Specification.OPAQUE,
        )
        assert resource == Resource.opaque(contents={"foo": "bar"})

    def test_from_contents_unneeded_default(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        resource = Resource.from_contents(
            schema,
            default_specification=Specification.OPAQUE,
        )
        assert resource == Resource(
            contents=schema,
            specification=DRAFT202012,
        )

    def test_non_mapping_from_contents(self):
        resource = Resource.from_contents(
            True,
            default_specification=ID_AND_CHILDREN,
        )
        assert resource == Resource(
            contents=True,
            specification=ID_AND_CHILDREN,
        )

    def test_from_contents_with_fallback(self):
        resource = Resource.from_contents(
            {"foo": "bar"},
            default_specification=Specification.OPAQUE,
        )
        assert resource == Resource.opaque(contents={"foo": "bar"})

    def test_id_delegates_to_specification(self):
        specification = Specification(
            name="",
            id_of=lambda contents: "urn:fixedID",
            subresources_of=lambda contents: [],
            anchors_in=lambda specification, contents: [],
            maybe_in_subresource=(
                lambda segments, resolver, subresource: resolver
            ),
        )
        resource = Resource(
            contents={"foo": "baz"},
            specification=specification,
        )
        assert resource.id() == "urn:fixedID"

    def test_id_strips_empty_fragment(self):
        uri = "http://example.com/"
        root = ID_AND_CHILDREN.create_resource({"ID": uri + "#"})
        assert root.id() == uri

    def test_subresources_delegates_to_specification(self):
        resource = ID_AND_CHILDREN.create_resource({"children": [{}, 12]})
        assert list(resource.subresources()) == [
            ID_AND_CHILDREN.create_resource(each) for each in [{}, 12]
        ]

    def test_subresource_with_different_specification(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        resource = ID_AND_CHILDREN.create_resource({"children": [schema]})
        assert list(resource.subresources()) == [
            DRAFT202012.create_resource(schema),
        ]

    def test_anchors_delegates_to_specification(self):
        resource = ID_AND_CHILDREN.create_resource(
            {"anchors": {"foo": {}, "bar": 1, "baz": ""}},
        )
        assert list(resource.anchors()) == [
            Anchor(name="foo", resource=ID_AND_CHILDREN.create_resource({})),
            Anchor(name="bar", resource=ID_AND_CHILDREN.create_resource(1)),
            Anchor(name="baz", resource=ID_AND_CHILDREN.create_resource("")),
        ]

    def test_pointer_to_mapping(self):
        resource = Resource.opaque(contents={"foo": "baz"})
        resolver = Registry().resolver()
        assert resource.pointer("/foo", resolver=resolver).contents == "baz"

    def test_pointer_to_array(self):
        resource = Resource.opaque(contents={"foo": {"bar": [3]}})
        resolver = Registry().resolver()
        assert resource.pointer("/foo/bar/0", resolver=resolver).contents == 3

    def test_root_pointer(self):
        contents = {"foo": "baz"}
        resource = Resource.opaque(contents=contents)
        resolver = Registry().resolver()
        assert resource.pointer("", resolver=resolver).contents == contents

    def test_opaque(self):
        contents = {"foo": "bar"}
        assert Resource.opaque(contents) == Resource(
            contents=contents,
            specification=Specification.OPAQUE,
        )


class TestResolver:
    def test_lookup_exact_uri(self):
        resource = Resource.opaque(contents={"foo": "baz"})
        resolver = Registry({"http://example.com/1": resource}).resolver()
        resolved = resolver.lookup("http://example.com/1")
        assert resolved.contents == resource.contents

    def test_lookup_subresource(self):
        root = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/",
                "children": [
                    {"ID": "http://example.com/a", "foo": 12},
                ],
            },
        )
        registry = root @ Registry()
        resolved = registry.resolver().lookup("http://example.com/a")
        assert resolved.contents == {"ID": "http://example.com/a", "foo": 12}

    def test_lookup_anchor_with_id(self):
        root = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/",
                "anchors": {"foo": 12},
            },
        )
        registry = root @ Registry()
        resolved = registry.resolver().lookup("http://example.com/#foo")
        assert resolved.contents == 12

    def test_lookup_anchor_without_id(self):
        root = ID_AND_CHILDREN.create_resource({"anchors": {"foo": 12}})
        resolver = Registry().with_resource("urn:example", root).resolver()
        resolved = resolver.lookup("urn:example#foo")
        assert resolved.contents == 12

    def test_lookup_unknown_reference(self):
        resolver = Registry().resolver()
        ref = "http://example.com/does/not/exist"
        with pytest.raises(exceptions.Unresolvable) as e:
            resolver.lookup(ref)
        assert e.value == exceptions.Unresolvable(ref=ref)

    def test_lookup_non_existent_pointer(self):
        resource = Resource.opaque({"foo": {}})
        resolver = Registry({"http://example.com/1": resource}).resolver()
        ref = "http://example.com/1#/foo/bar"
        with pytest.raises(exceptions.Unresolvable) as e:
            resolver.lookup(ref)
        assert e.value == exceptions.PointerToNowhere(
            ref="/foo/bar",
            resource=resource,
        )
        assert str(e.value) == "'/foo/bar' does not exist within {'foo': {}}"

    def test_lookup_non_existent_pointer_to_array_index(self):
        resource = Resource.opaque([1, 2, 4, 8])
        resolver = Registry({"http://example.com/1": resource}).resolver()
        ref = "http://example.com/1#/10"
        with pytest.raises(exceptions.Unresolvable) as e:
            resolver.lookup(ref)
        assert e.value == exceptions.PointerToNowhere(
            ref="/10",
            resource=resource,
        )

    def test_lookup_pointer_to_empty_string(self):
        resolver = Registry().resolver_with_root(Resource.opaque({"": {}}))
        assert resolver.lookup("#/").contents == {}

    def test_lookup_non_existent_pointer_to_empty_string(self):
        resource = Resource.opaque({"foo": {}})
        resolver = Registry().resolver_with_root(resource)
        with pytest.raises(
            exceptions.Unresolvable,
            match="^'/' does not exist within {'foo': {}}.*'#'",
        ) as e:
            resolver.lookup("#/")
        assert e.value == exceptions.PointerToNowhere(
            ref="/",
            resource=resource,
        )

    def test_lookup_non_existent_anchor(self):
        root = ID_AND_CHILDREN.create_resource({"anchors": {}})
        resolver = Registry().with_resource("urn:example", root).resolver()
        resolved = resolver.lookup("urn:example")
        assert resolved.contents == root.contents

        ref = "urn:example#noSuchAnchor"
        with pytest.raises(exceptions.Unresolvable) as e:
            resolver.lookup(ref)
        assert "'noSuchAnchor' does not exist" in str(e.value)
        assert e.value == exceptions.NoSuchAnchor(
            ref="urn:example",
            resource=root,
            anchor="noSuchAnchor",
        )

    def test_lookup_invalid_JSON_pointerish_anchor(self):
        resolver = Registry().resolver_with_root(
            ID_AND_CHILDREN.create_resource(
                {
                    "ID": "http://example.com/",
                    "foo": {"bar": 12},
                },
            ),
        )

        valid = resolver.lookup("#/foo/bar")
        assert valid.contents == 12

        with pytest.raises(exceptions.InvalidAnchor) as e:
            resolver.lookup("#foo/bar")
        assert " '#/foo/bar'" in str(e.value)

    def test_lookup_retrieved_resource(self):
        resource = Resource.opaque(contents={"foo": "baz"})
        resolver = Registry(retrieve=lambda uri: resource).resolver()
        resolved = resolver.lookup("http://example.com/")
        assert resolved.contents == resource.contents

    def test_lookup_failed_retrieved_resource(self):
        """
        Unretrievable exceptions are also wrapped in Unresolvable.
        """

        uri = "http://example.com/"

        registry = Registry(retrieve=blow_up)
        with pytest.raises(exceptions.Unretrievable):
            registry.get_or_retrieve(uri)

        resolver = registry.resolver()
        with pytest.raises(exceptions.Unresolvable):
            resolver.lookup(uri)

    def test_repeated_lookup_from_retrieved_resource(self):
        """
        A (custom-)retrieved resource is added to the registry returned by
        looking it up.
        """
        resource = Resource.opaque(contents={"foo": "baz"})
        once = [resource]

        def retrieve(uri):
            return once.pop()

        resolver = Registry(retrieve=retrieve).resolver()
        resolved = resolver.lookup("http://example.com/")
        assert resolved.contents == resource.contents

        resolved = resolved.resolver.lookup("http://example.com/")
        assert resolved.contents == resource.contents

    def test_repeated_anchor_lookup_from_retrieved_resource(self):
        resource = Resource.opaque(contents={"foo": "baz"})
        once = [resource]

        def retrieve(uri):
            return once.pop()

        resolver = Registry(retrieve=retrieve).resolver()
        resolved = resolver.lookup("http://example.com/")
        assert resolved.contents == resource.contents

        resolved = resolved.resolver.lookup("#")
        assert resolved.contents == resource.contents

    # FIXED: The tests below aren't really representable in the current
    #        suite, though we should probably think of ways to do so.

    def test_in_subresource(self):
        root = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/",
                "children": [
                    {
                        "ID": "child/",
                        "children": [{"ID": "grandchild"}],
                    },
                ],
            },
        )
        registry = root @ Registry()

        resolver = registry.resolver()
        first = resolver.lookup("http://example.com/")
        assert first.contents == root.contents

        with pytest.raises(exceptions.Unresolvable):
            first.resolver.lookup("grandchild")

        sub = first.resolver.in_subresource(
            ID_AND_CHILDREN.create_resource(first.contents["children"][0]),
        )
        second = sub.lookup("grandchild")
        assert second.contents == {"ID": "grandchild"}

    def test_in_pointer_subresource(self):
        root = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/",
                "children": [
                    {
                        "ID": "child/",
                        "children": [{"ID": "grandchild"}],
                    },
                ],
            },
        )
        registry = root @ Registry()

        resolver = registry.resolver()
        first = resolver.lookup("http://example.com/")
        assert first.contents == root.contents

        with pytest.raises(exceptions.Unresolvable):
            first.resolver.lookup("grandchild")

        second = first.resolver.lookup("#/children/0")
        third = second.resolver.lookup("grandchild")
        assert third.contents == {"ID": "grandchild"}

    def test_dynamic_scope(self):
        one = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/",
                "children": [
                    {
                        "ID": "child/",
                        "children": [{"ID": "grandchild"}],
                    },
                ],
            },
        )
        two = ID_AND_CHILDREN.create_resource(
            {
                "ID": "http://example.com/two",
                "children": [{"ID": "two-child/"}],
            },
        )
        registry = [one, two] @ Registry()

        resolver = registry.resolver()
        first = resolver.lookup("http://example.com/")
        second = first.resolver.lookup("#/children/0")
        third = second.resolver.lookup("grandchild")
        fourth = third.resolver.lookup("http://example.com/two")
        assert list(fourth.resolver.dynamic_scope()) == [
            ("http://example.com/child/grandchild", fourth.resolver._registry),
            ("http://example.com/child/", fourth.resolver._registry),
            ("http://example.com/", fourth.resolver._registry),
        ]
        assert list(third.resolver.dynamic_scope()) == [
            ("http://example.com/child/", third.resolver._registry),
            ("http://example.com/", third.resolver._registry),
        ]
        assert list(second.resolver.dynamic_scope()) == [
            ("http://example.com/", second.resolver._registry),
        ]
        assert list(first.resolver.dynamic_scope()) == []


class TestSpecification:
    def test_create_resource(self):
        specification = Specification(
            name="",
            id_of=lambda contents: "urn:fixedID",
            subresources_of=lambda contents: [],
            anchors_in=lambda specification, contents: [],
            maybe_in_subresource=(
                lambda segments, resolver, subresource: resolver
            ),
        )
        resource = specification.create_resource(contents={"foo": "baz"})
        assert resource == Resource(
            contents={"foo": "baz"},
            specification=specification,
        )
        assert resource.id() == "urn:fixedID"

    def test_detect_from_json_schema(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        specification = Specification.detect(schema)
        assert specification == DRAFT202012

    def test_detect_with_no_discernible_information(self):
        with pytest.raises(exceptions.CannotDetermineSpecification):
            Specification.detect({"foo": "bar"})

    def test_detect_with_non_URI_schema(self):
        with pytest.raises(exceptions.CannotDetermineSpecification):
            Specification.detect({"$schema": 37})

    def test_detect_with_no_discernible_information_and_default(self):
        specification = Specification.OPAQUE.detect({"foo": "bar"})
        assert specification is Specification.OPAQUE

    def test_detect_unneeded_default(self):
        schema = {"$schema": "https://json-schema.org/draft/2020-12/schema"}
        specification = Specification.OPAQUE.detect(schema)
        assert specification == DRAFT202012

    def test_non_mapping_detect(self):
        with pytest.raises(exceptions.CannotDetermineSpecification):
            Specification.detect(True)

    def test_non_mapping_detect_with_default(self):
        specification = ID_AND_CHILDREN.detect(True)
        assert specification is ID_AND_CHILDREN

    def test_detect_with_fallback(self):
        specification = Specification.OPAQUE.detect({"foo": "bar"})
        assert specification is Specification.OPAQUE

    def test_repr(self):
        assert (
            repr(ID_AND_CHILDREN) == "<Specification name='id-and-children'>"
        )


class TestOpaqueSpecification:
    THINGS = [{"foo": "bar"}, True, 37, "foo", object()]

    @pytest.mark.parametrize("thing", THINGS)
    def test_no_id(self, thing):
        """
        An arbitrary thing has no ID.
        """

        assert Specification.OPAQUE.id_of(thing) is None

    @pytest.mark.parametrize("thing", THINGS)
    def test_no_subresources(self, thing):
        """
        An arbitrary thing has no subresources.
        """

        assert list(Specification.OPAQUE.subresources_of(thing)) == []

    @pytest.mark.parametrize("thing", THINGS)
    def test_no_anchors(self, thing):
        """
        An arbitrary thing has no anchors.
        """

        assert list(Specification.OPAQUE.anchors_in(thing)) == []


@pytest.mark.parametrize(
    "cls",
    [Anchor, Registry, Resource, Specification, exceptions.PointerToNowhere],
)
def test_nonsubclassable(cls):
    with pytest.raises(Exception, match="(?i)subclassing"):

        class Boom(cls):  # pragma: no cover
            pass

from unittest import TestCase
import textwrap

from jsonschema import exceptions
from jsonschema.validators import _LATEST_VERSION


class TestBestMatch(TestCase):
    def best_match_of(self, instance, schema):
        errors = list(_LATEST_VERSION(schema).iter_errors(instance))
        msg =  f"No errors found for {instance} under {schema!r}!"
        self.assertTrue(errors, msg=msg)

        best = exceptions.best_match(iter(errors))
        reversed_best = exceptions.best_match(reversed(errors))

        self.assertEqual(
            best._contents(),
            reversed_best._contents(),
            f"No consistent best match!

from unittest import mock

import pytest

from qrcode import run_example

pytest.importorskip("PIL", reason="Requires PIL")


@mock.patch("PIL.Image.Image.show")
def test_example(mock_show):
    run_example()
    mock_show.assert_called_with()

import a

import b

import builtins
import datetime
import re
from unittest import mock

from qrcode.release import update_manpage

OPEN = f"{builtins.__name__}.open"
DATA = 'test

import contextlib
import os
from pathlib import Path
from tempfile import TemporaryDirectory
from typing import Dict, Generator
from unittest import TestCase

from libcst import BaseExpression, Call, matchers as m, Name
from libcst.codemod import (
    CodemodContext,
    gather_files,
    parallel_exec_transform_with_prettyprint,
    VisitorBasedCodemodCommand,
)
from libcst.codemod.visitors import AddImportsVisitor


class PrintToPPrintCommand(VisitorBasedCodemodCommand):
    def __init__(self, context: CodemodContext, **kwargs: Dict[str, object]) -> None:
        super().__init__(context, **kwargs)
        self.context.scratch["PPRINT_WAS_HERE"] = True

    def leave_Call(self, original_node: Call, updated_node: Call) -> BaseExpression:
        if not self.context.scratch["PPRINT_WAS_HERE"]:
            raise AssertionError("Scratch space lost")

        if m.matches(updated_node, m.Call(func=m.Name("print"))):
            AddImportsVisitor.add_needed_import(
                self.context,
                "pprint",
                "pprint",
            )
            return updated_node.with_changes(func=Name("pprint"))
        return super().leave_Call(original_node, updated_node)


@contextlib.contextmanager
def temp_workspace() -> Generator[Path, None, None]:
    cwd = os.getcwd()
    with TemporaryDirectory() as temp_dir:
        try:
            ws = Path(temp_dir).resolve()
            os.chdir(ws)
            yield ws
        finally:
            os.chdir(cwd)


class ToolE2ETest(TestCase):
    def test_leaky_codemod(self) -> None:
        with temp_workspace() as tmp:
            # File to trigger codemod
            example: Path = tmp / "example.py"
            example.write_text("""print("Hello")""")
            # File that should not be modified
            other = tmp / "other.py"
            other.touch()
            # Just a dir named "dir.py", should be ignored
            adir = tmp / "dir.py"
            adir.mkdir()

            # Run command
            command_instance = PrintToPPrintCommand(CodemodContext())
            files = gather_files(".")
            result = parallel_exec_transform_with_prettyprint(
                command_instance,
                files,
                format_code=False,
                hide_progress=True,
            )

            print(result)

            # Check results
            self.assertEqual(2, result.successes)
            self.assertEqual(0, result.skips)
            self.assertEqual(0, result.failures)
            # Expect example.py to be modified
            self.assertIn(
                "from pprint import pprint",
                example.read_text(),
                "import missing in example.py",
            )
            # Expect other.py to NOT be modified
            self.assertNotIn(
                "from pprint import pprint",
                other.read_text(),
                "import found in other.py",
            )

import io

import pytest

import qrcode
import qrcode.util
from qrcode.tests.consts import BLACK, RED, UNICODE_TEXT, WHITE

Image = pytest.importorskip("PIL.Image", reason="PIL is not installed")

if Image:
    from qrcode.image.styledpil import StyledPilImage
    from qrcode.image.styles import colormasks, moduledrawers


def test_render_pil():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image()
    img.save(io.BytesIO())
    assert isinstance(img.get_image(), Image.Image)


@pytest.mark.parametrize("back_color", ["TransParent", "red", (255, 195, 235)])
def test_render_pil_background(back_color):
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(back_color="TransParent")
    img.save(io.BytesIO())


def test_render_pil_with_rgb_color_tuples():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(back_color=(255, 195, 235), fill_color=(55, 95, 35))
    img.save(io.BytesIO())


def test_render_with_pattern():
    qr = qrcode.QRCode(mask_pattern=3)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image()
    img.save(io.BytesIO())


def test_render_styled_Image():
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_L)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=StyledPilImage)
    img.save(io.BytesIO())


def test_render_styled_with_embedded_image():
    embedded_img = Image.new("RGB", (10, 10), color="red")
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_H)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=StyledPilImage, embedded_image=embedded_img)
    img.save(io.BytesIO())


def test_render_styled_with_embedded_image_path(tmp_path):
    tmpfile = str(tmp_path / "test.png")
    embedded_img = Image.new("RGB", (10, 10), color="red")
    embedded_img.save(tmpfile)
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_H)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=StyledPilImage, embedded_image_path=tmpfile)
    img.save(io.BytesIO())


@pytest.mark.parametrize(
    "drawer",
    [
        moduledrawers.CircleModuleDrawer,
        moduledrawers.GappedSquareModuleDrawer,
        moduledrawers.HorizontalBarsDrawer,
        moduledrawers.RoundedModuleDrawer,
        moduledrawers.SquareModuleDrawer,
        moduledrawers.VerticalBarsDrawer,
    ],
)
def test_render_styled_with_drawer(drawer):
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_L)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(
        image_factory=StyledPilImage,
        module_drawer=drawer(),
    )
    img.save(io.BytesIO())


@pytest.mark.parametrize(
    "mask",
    [
        colormasks.SolidFillColorMask(),
        colormasks.SolidFillColorMask(back_color=WHITE, front_color=RED),
        colormasks.SolidFillColorMask(back_color=(255, 0, 255, 255), front_color=RED),
        colormasks.RadialGradiantColorMask(
            back_color=WHITE, center_color=BLACK, edge_color=RED
        ),
        colormasks.SquareGradiantColorMask(
            back_color=WHITE, center_color=BLACK, edge_color=RED
        ),
        colormasks.HorizontalGradiantColorMask(
            back_color=WHITE, left_color=RED, right_color=BLACK
        ),
        colormasks.VerticalGradiantColorMask(
            back_color=WHITE, top_color=RED, bottom_color=BLACK
        ),
        colormasks.ImageColorMask(
            back_color=WHITE, color_mask_image=Image.new("RGB", (10, 10), color="red")
        ),
    ],
)
def test_render_styled_with_mask(mask):
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_L)
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=StyledPilImage, color_mask=mask)
    img.save(io.BytesIO())


def test_embedded_image_and_error_correction(tmp_path):
    "If an embedded image is specified, error correction must be the highest so the QR code is readable"
    tmpfile = str(tmp_path / "test.png")
    embedded_img = Image.new("RGB", (10, 10), color="red")
    embedded_img.save(tmpfile)

    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_L)
    qr.add_data(UNICODE_TEXT)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image_path=tmpfile)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image=embedded_img)

    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_M)
    qr.add_data(UNICODE_TEXT)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image_path=tmpfile)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image=embedded_img)

    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_Q)
    qr.add_data(UNICODE_TEXT)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image_path=tmpfile)
    with pytest.raises(ValueError):
        qr.make_image(embedded_image=embedded_img)

    # The only accepted correction level when an embedded image is provided
    qr = qrcode.QRCode(error_correction=qrcode.ERROR_CORRECT_H)
    qr.add_data(UNICODE_TEXT)
    qr.make_image(embedded_image_path=tmpfile)
    qr.make_image(embedded_image=embedded_img)


def test_shortcut():
    qrcode.make("image")

import io

import qrcode
from qrcode.image import svg
from qrcode.tests.consts import UNICODE_TEXT


class SvgImageWhite(svg.SvgImage):
    background = "white"


def test_render_svg():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=svg.SvgImage)
    img.save(io.BytesIO())


def test_render_svg_path():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=svg.SvgPathImage)
    img.save(io.BytesIO())


def test_render_svg_fragment():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=svg.SvgFragmentImage)
    img.save(io.BytesIO())


def test_svg_string():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=svg.SvgFragmentImage)
    file_like = io.BytesIO()
    img.save(file_like)
    file_like.seek(0)
    assert file_like.read() in img.to_string()


def test_render_svg_with_background():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=SvgImageWhite)
    img.save(io.BytesIO())


def test_svg_circle_drawer():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=svg.SvgPathImage, module_drawer="circle")
    img.save(io.BytesIO())

import io
from unittest import mock

import pytest


import qrcode
import qrcode.util
from qrcode.image.pure import PyPNGImage
from qrcode.tests.consts import UNICODE_TEXT

png = pytest.importorskip("png", reason="png is not installed")


def test_render_pypng():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=PyPNGImage)
    assert isinstance(img.get_image(), png.Writer)

    print(img.width, img.box_size, img.border)
    img.save(io.BytesIO())


def test_render_pypng_to_str():
    qr = qrcode.QRCode()
    qr.add_data(UNICODE_TEXT)
    img = qr.make_image(image_factory=PyPNGImage)
    assert isinstance(img.get_image(), png.Writer)

    mock_open = mock.mock_open()
    with mock.patch("qrcode.image.pure.open", mock_open, create=True):
        img.save("test_file.png")
    mock_open.assert_called_once_with("test_file.png", "wb")
    mock_open("test_file.png", "wb").write.assert_called()

import io
from unittest import mock

import pytest

import qrcode
import qrcode.util
from qrcode.exceptions import DataOverflowError
from qrcode.image.base import BaseImage
from qrcode.tests.consts import UNICODE_TEXT
from qrcode.util import MODE_8BIT_BYTE, MODE_ALPHA_NUM, MODE_NUMBER, QRData


def test_basic():
    qr = qrcode.QRCode(version=1)
    qr.add_data("a")
    qr.make(fit=False)


def test_large():
    qr = qrcode.QRCode(version=27)
    qr.add_data("a")
    qr.make(fit=False)


def test_invalid_version():
    with pytest.raises(ValueError):
        qrcode.QRCode(version=42)


def test_invalid_border():
    with pytest.raises(ValueError):
        qrcode.QRCode(border=-1)


def test_overflow():
    qr = qrcode.QRCode(version=1)
    qr.add_data("abcdefghijklmno")
    with pytest.raises(DataOverflowError):
        qr.make(fit=False)


def test_add_qrdata():
    qr = qrcode.QRCode(version=1)
    data = QRData("a")
    qr.add_data(data)
    qr.make(fit=False)


def test_fit():
    qr = qrcode.QRCode()
    qr.add_data("a")
    qr.make()
    assert qr.version == 1
    qr.add_data("bcdefghijklmno")
    qr.make()
    assert qr.version == 2


def test_mode_number():
    qr = qrcode.QRCode()
    qr.add_data("1234567890123456789012345678901234", optimize=0)
    qr.make()
    assert qr.version == 1
    assert qr.data_list[0].mode == MODE_NUMBER


def test_mode_alpha():
    qr = qrcode.QRCode()
    qr.add_data("ABCDEFGHIJ1234567890", optimize=0)
    qr.make()
    assert qr.version == 1
    assert qr.data_list[0].mode == MODE_ALPHA_NUM


def test_regression_mode_comma():
    qr = qrcode.QRCode()
    qr.add_data(",", optimize=0)
    qr.make()
    assert qr.data_list[0].mode == MODE_8BIT_BYTE


def test_mode_8bit():
    qr = qrcode.QRCode()
    qr.add_data("abcABC" + UNICODE_TEXT, optimize=0)
    qr.make()
    assert qr.version == 1
    assert qr.data_list[0].mode == MODE_8BIT_BYTE


def test_mode_8bit_newline():
    qr = qrcode.QRCode()
    qr.add_data("ABCDEFGHIJ1234567890

import itertools

import pytest

from referencing import Resource, exceptions


def pairs(choices):
    return itertools.combinations(choices, 2)


TRUE = Resource.opaque(True)


thunks = (
    lambda: exceptions.CannotDetermineSpecification(TRUE),
    lambda: exceptions.NoSuchResource("urn:example:foo"),
    lambda: exceptions.NoInternalID(TRUE),
    lambda: exceptions.InvalidAnchor(resource=TRUE, anchor="foo", ref="a#b"),
    lambda: exceptions.NoSuchAnchor(resource=TRUE, anchor="foo", ref="a#b"),
    lambda: exceptions.PointerToNowhere(resource=TRUE, ref="urn:example:foo"),
    lambda: exceptions.Unresolvable("urn:example:foo"),
    lambda: exceptions.Unretrievable("urn:example:foo"),
)


@pytest.mark.parametrize("one, two", pairs(each() for each in thunks))
def test_eq_incompatible_types(one, two):
    assert one != two


@pytest.mark.parametrize("thunk", thunks)
def test_hash(thunk):
    assert thunk() in {thunk()}

import math
import sys
from datetime import date, datetime, timedelta, timezone
from decimal import Decimal
from typing import Any, Dict, Iterable, Iterator, List, NamedTuple, Set, Tuple

if sys.version_info < (3, 9):
    from typing_extensions import Annotated
else:
    from typing import Annotated

import annotated_types as at


class Case(NamedTuple):
    """
    A test case for `annotated_types`.
    """

    annotation: Any
    valid_cases: Iterable[Any]
    invalid_cases: Iterable[Any]


def cases() -> Iterable[Case]:
    # Gt, Ge, Lt, Le
    yield Case(Annotated[int, at.Gt(4)], (5, 6, 1000), (4, 0, -1))
    yield Case(Annotated[float, at.Gt(0.5)], (0.6, 0.7, 0.8, 0.9), (0.5, 0.0, -0.1))
    yield Case(
        Annotated[datetime, at.Gt(datetime(2000, 1, 1))],
        [datetime(2000, 1, 2), datetime(2000, 1, 3)],
        [datetime(2000, 1, 1), datetime(1999, 12, 31)],
    )
    yield Case(
        Annotated[datetime, at.Gt(date(2000, 1, 1))],
        [date(2000, 1, 2), date(2000, 1, 3)],
        [date(2000, 1, 1), date(1999, 12, 31)],
    )
    yield Case(
        Annotated[datetime, at.Gt(Decimal('1.123'))],
        [Decimal('1.1231'), Decimal('123')],
        [Decimal('1.123'), Decimal('0')],
    )

    yield Case(Annotated[int, at.Ge(4)], (4, 5, 6, 1000, 4), (0, -1))
    yield Case(Annotated[float, at.Ge(0.5)], (0.5, 0.6, 0.7, 0.8, 0.9), (0.4, 0.0, -0.1))
    yield Case(
        Annotated[datetime, at.Ge(datetime(2000, 1, 1))],
        [datetime(2000, 1, 2), datetime(2000, 1, 3)],
        [datetime(1998, 1, 1), datetime(1999, 12, 31)],
    )

    yield Case(Annotated[int, at.Lt(4)], (0, -1), (4, 5, 6, 1000, 4))
    yield Case(Annotated[float, at.Lt(0.5)], (0.4, 0.0, -0.1), (0.5, 0.6, 0.7, 0.8, 0.9))
    yield Case(
        Annotated[datetime, at.Lt(datetime(2000, 1, 1))],
        [datetime(1999, 12, 31), datetime(1999, 12, 31)],
        [datetime(2000, 1, 2), datetime(2000, 1, 3)],
    )

    yield Case(Annotated[int, at.Le(4)], (4, 0, -1), (5, 6, 1000))
    yield Case(Annotated[float, at.Le(0.5)], (0.5, 0.0, -0.1), (0.6, 0.7, 0.8, 0.9))
    yield Case(
        Annotated[datetime, at.Le(datetime(2000, 1, 1))],
        [datetime(2000, 1, 1), datetime(1999, 12, 31)],
        [datetime(2000, 1, 2), datetime(2000, 1, 3)],
    )

    # Interval
    yield Case(Annotated[int, at.Interval(gt=4)], (5, 6, 1000), (4, 0, -1))
    yield Case(Annotated[int, at.Interval(gt=4, lt=10)], (5, 6), (4, 10, 1000, 0, -1))
    yield Case(Annotated[float, at.Interval(ge=0.5, le=1)], (0.5, 0.9, 1), (0.49, 1.1))
    yield Case(
        Annotated[datetime, at.Interval(gt=datetime(2000, 1, 1), le=datetime(2000, 1, 3))],
        [datetime(2000, 1, 2), datetime(2000, 1, 3)],
        [datetime(2000, 1, 1), datetime(2000, 1, 4)],
    )

    yield Case(Annotated[int, at.MultipleOf(multiple_of=3)], (0, 3, 9), (1, 2, 4))
    yield Case(Annotated[float, at.MultipleOf(multiple_of=0.5)], (0, 0.5, 1, 1.5), (0.4, 1.1))

    # lengths

    yield Case(Annotated[str, at.MinLen(3)], ('123', '1234', 'x' * 10), ('', '1', '12'))
    yield Case(Annotated[str, at.Len(3)], ('123', '1234', 'x' * 10), ('', '1', '12'))
    yield Case(Annotated[List[int], at.MinLen(3)], ([1, 2, 3], [1, 2, 3, 4], [1] * 10), ([], [1], [1, 2]))
    yield Case(Annotated[List[int], at.Len(3)], ([1, 2, 3], [1, 2, 3, 4], [1] * 10), ([], [1], [1, 2]))

    yield Case(Annotated[str, at.MaxLen(4)], ('', '1234'), ('12345', 'x' * 10))
    yield Case(Annotated[str, at.Len(0, 4)], ('', '1234'), ('12345', 'x' * 10))
    yield Case(Annotated[List[str], at.MaxLen(4)], ([], ['a', 'bcdef'], ['a', 'b', 'c']), (['a'] * 5, ['b'] * 10))
    yield Case(Annotated[List[str], at.Len(0, 4)], ([], ['a', 'bcdef'], ['a', 'b', 'c']), (['a'] * 5, ['b'] * 10))

    yield Case(Annotated[str, at.Len(3, 5)], ('123', '12345'), ('', '1', '12', '123456', 'x' * 10))
    yield Case(Annotated[str, at.Len(3, 3)], ('123',), ('12', '1234'))

    yield Case(Annotated[Dict[int, int], at.Len(2, 3)], [{1: 1, 2: 2}], [{}, {1: 1}, {1: 1, 2: 2, 3: 3, 4: 4}])
    yield Case(Annotated[Set[int], at.Len(2, 3)], ({1, 2}, {1, 2, 3}), (set(), {1}, {1, 2, 3, 4}))
    yield Case(Annotated[Tuple[int, ...], at.Len(2, 3)], ((1, 2), (1, 2, 3)), ((), (1,), (1, 2, 3, 4)))

    # Timezone

    yield Case(
        Annotated[datetime, at.Timezone(None)], [datetime(2000, 1, 1)], [datetime(2000, 1, 1, tzinfo=timezone.utc)]
    )
    yield Case(
        Annotated[datetime, at.Timezone(...)], [datetime(2000, 1, 1, tzinfo=timezone.utc)], [datetime(2000, 1, 1)]
    )
    yield Case(
        Annotated[datetime, at.Timezone(timezone.utc)],
        [datetime(2000, 1, 1, tzinfo=timezone.utc)],
        [datetime(2000, 1, 1), datetime(2000, 1, 1, tzinfo=timezone(timedelta(hours=6)))],
    )
    yield Case(
        Annotated[datetime, at.Timezone('Europe/London')],
        [datetime(2000, 1, 1, tzinfo=timezone(timedelta(0), name='Europe/London'))],
        [datetime(2000, 1, 1), datetime(2000, 1, 1, tzinfo=timezone(timedelta(hours=6)))],
    )

    # Quantity

    yield Case(Annotated[float, at.Unit(unit='m')], (5, 4.2), ('5m', '4.2m'))

    # predicate types

    yield Case(at.LowerCase[str], ['abc', 'foobar'], ['', 'A', 'Boom'])
    yield Case(at.UpperCase[str], ['ABC', 'DEFO'], ['', 'a', 'abc', 'AbC'])
    yield Case(at.IsDigit[str], ['123'], ['', 'ab', 'a1b2'])
    yield Case(at.IsAscii[str], ['123', 'foo bar'], ['£100', '😊', 'whatever 👀'])

    yield Case(Annotated[int, at.Predicate(lambda x: x % 2 == 0)], [0, 2, 4], [1, 3, 5])

    yield Case(at.IsFinite[float], [1.23], [math.nan, math.inf, -math.inf])
    yield Case(at.IsNotFinite[float], [math.nan, math.inf], [1.23])
    yield Case(at.IsNan[float], [math.nan], [1.23, math.inf])
    yield Case(at.IsNotNan[float], [1.23, math.inf], [math.nan])
    yield Case(at.IsInfinite[float], [math.inf], [math.nan, 1.23])
    yield Case(at.IsNotInfinite[float], [math.nan, 1.23], [math.inf])

    # check stacked predicates
    yield Case(at.IsInfinite[Annotated[float, at.Predicate(lambda x: x > 0)]], [math.inf], [-math.inf, 1.23, math.nan])

    # doc
    yield Case(Annotated[int, at.doc("A number")], [1, 2], [])

    # custom GroupedMetadata
    class MyCustomGroupedMetadata(at.GroupedMetadata):
        def __iter__(self) -> Iterator[at.Predicate]:
            yield at.Predicate(lambda x: float(x).is_integer())

    yield Case(Annotated[float, MyCustomGroupedMetadata()], [0, 2.0], [0.01, 1.5])

import operator
from functools import reduce
import sys

try:
    import unittest2 as unittest
except ImportError:
    import unittest
import hypothesis.strategies as st
import pytest
from hypothesis import given, settings, example

try:
    from hypothesis import HealthCheck

    HC_PRESENT = True
except ImportError:  # pragma: no cover
    HC_PRESENT = False
from .numbertheory import (
    SquareRootError,
    JacobiError,
    factorization,
    gcd,
    lcm,
    jacobi,
    inverse_mod,
    is_prime,
    next_prime,
    smallprimes,
    square_root_mod_prime,
)

try:
    from gmpy2 import mpz
except ImportError:
    try:
        from gmpy import mpz
    except ImportError:

        def mpz(x):
            return x


BIGPRIMES = (
    999671,
    999683,
    999721,
    999727,
    999749,
    999763,
    999769,
    999773,
    999809,
    999853,
    999863,
    999883,
    999907,
    999917,
    999931,
    999953,
    999959,
    999961,
    999979,
    999983,
)


@pytest.mark.parametrize(
    "prime, next_p", [(p, q) for p, q in zip(BIGPRIMES[:-1], BIGPRIMES[1:])]
)
def test_next_prime(prime, next_p):
    assert next_prime(prime) == next_p


@pytest.mark.parametrize("val", [-1, 0, 1])
def test_next_prime_with_nums_less_2(val):
    assert next_prime(val) == 2


@pytest.mark.slow
@pytest.mark.parametrize("prime", smallprimes)
def test_square_root_mod_prime_for_small_primes(prime):
    squares = set()
    for num in range(0, 1 + prime // 2):
        sq = num * num % prime
        squares.add(sq)
        root = square_root_mod_prime(sq, prime)
        # tested for real with TestNumbertheory.test_square_root_mod_prime
        assert root * root % prime == sq

    for nonsquare in range(0, prime):
        if nonsquare in squares:
            continue
        with pytest.raises(SquareRootError):
            square_root_mod_prime(nonsquare, prime)


def test_square_root_mod_prime_for_2():
    a = square_root_mod_prime(1, 2)
    assert a == 1


def test_square_root_mod_prime_for_small_prime():
    root = square_root_mod_prime(98**2 % 101, 101)
    assert root * root % 101 == 9


def test_square_root_mod_prime_for_p_congruent_5():
    p = 13
    assert p % 8 == 5

    root = square_root_mod_prime(3, p)
    assert root * root % p == 3


def test_square_root_mod_prime_for_p_congruent_5_large_d():
    p = 29
    assert p % 8 == 5

    root = square_root_mod_prime(4, p)
    assert root * root % p == 4


class TestSquareRootModPrime(unittest.TestCase):
    def test_power_of_2_p(self):
        with self.assertRaises(JacobiError):
            square_root_mod_prime(12, 32)

    def test_no_square(self):
        with self.assertRaises(SquareRootError) as e:
            square_root_mod_prime(12, 31)

        self.assertIn("no square root", str(e.exception))

    def test_non_prime(self):
        with self.assertRaises(SquareRootError) as e:
            square_root_mod_prime(12, 33)

        self.assertIn("p is not prime", str(e.exception))

    def test_non_prime_with_negative(self):
        with self.assertRaises(SquareRootError) as e:
            square_root_mod_prime(697 - 1, 697)

        self.assertIn("p is not prime", str(e.exception))


@st.composite
def st_two_nums_rel_prime(draw):
    # 521-bit is the biggest curve we operate on, use 1024 for a bit
    # of breathing space
    mod = draw(st.integers(min_value=2, max_value=2**1024))
    num = draw(
        st.integers(min_value=1, max_value=mod - 1).filter(
            lambda x: gcd(x, mod) == 1
        )
    )
    return num, mod


@st.composite
def st_primes(draw, *args, **kwargs):
    if "min_value" not in kwargs:  # pragma: no branch
        kwargs["min_value"] = 1
    prime = draw(
        st.sampled_from(smallprimes)
        | st.integers(*args, **kwargs).filter(is_prime)
    )
    return prime


@st.composite
def st_num_square_prime(draw):
    prime = draw(st_primes(max_value=2**1024))
    num = draw(st.integers(min_value=0, max_value=1 + prime // 2))
    sq = num * num % prime
    return sq, prime


@st.composite
def st_comp_with_com_fac(draw):
    """
    Strategy that returns lists of numbers, all having a common factor.
    """
    primes = draw(
        st.lists(st_primes(max_value=2**512), min_size=1, max_size=10)
    )
    # select random prime(s) that will make the common factor of composites
    com_fac_primes = draw(
        st.lists(st.sampled_from(primes), min_size=1, max_size=20)
    )
    com_fac = reduce(operator.mul, com_fac_primes, 1)

    # select at most 20 lists (returned numbers),
    # each having at most 30 primes (factors) including none (then the number
    # will be 1)
    comp_primes = draw(  # pragma: no branch
        st.integers(min_value=1, max_value=20).flatmap(
            lambda n: st.lists(
                st.lists(st.sampled_from(primes), max_size=30),
                min_size=1,
                max_size=n,
            )
        )
    )

    return [reduce(operator.mul, nums, 1) * com_fac for nums in comp_primes]


@st.composite
def st_comp_no_com_fac(draw):
    """
    Strategy that returns lists of numbers that don't have a common factor.
    """
    primes = draw(
        st.lists(
            st_primes(max_value=2**512), min_size=2, max_size=10, unique=True
        )
    )
    # first select the primes that will create the uncommon factor
    # between returned numbers
    uncom_fac_primes = draw(
        st.lists(
            st.sampled_from(primes),
            min_size=1,
            max_size=len(primes) - 1,
            unique=True,
        )
    )
    uncom_fac = reduce(operator.mul, uncom_fac_primes, 1)

    # then build composites from leftover primes
    leftover_primes = [i for i in primes if i not in uncom_fac_primes]

    assert leftover_primes
    assert uncom_fac_primes

    # select at most 20 lists, each having at most 30 primes
    # selected from the leftover_primes list
    number_primes = draw(  # pragma: no branch
        st.integers(min_value=1, max_value=20).flatmap(
            lambda n: st.lists(
                st.lists(st.sampled_from(leftover_primes), max_size=30),
                min_size=1,
                max_size=n,
            )
        )
    )

    numbers = [reduce(operator.mul, nums, 1) for nums in number_primes]

    insert_at = draw(st.integers(min_value=0, max_value=len(numbers)))
    numbers.insert(insert_at, uncom_fac)
    return numbers


HYP_SETTINGS = {}
if HC_PRESENT:  # pragma: no branch
    HYP_SETTINGS["suppress_health_check"] = [
        HealthCheck.filter_too_much,
        HealthCheck.too_slow,
    ]
    # the factorization() sometimes takes a long time to finish
    HYP_SETTINGS["deadline"] = 5000

if "--fast" in sys.argv:  # pragma: no cover
    HYP_SETTINGS["max_examples"] = 20


HYP_SLOW_SETTINGS = dict(HYP_SETTINGS)
if "--fast" in sys.argv:  # pragma: no cover
    HYP_SLOW_SETTINGS["max_examples"] = 1
else:
    HYP_SLOW_SETTINGS["max_examples"] = 20


class TestIsPrime(unittest.TestCase):
    def test_very_small_prime(self):
        assert is_prime(23)

    def test_very_small_composite(self):
        assert not is_prime(22)

    def test_small_prime(self):
        assert is_prime(123456791)

    def test_special_composite(self):
        assert not is_prime(10261)

    def test_medium_prime_1(self):
        # nextPrime[2^256]
        assert is_prime(2**256 + 0x129)

    def test_medium_prime_2(self):
        # nextPrime(2^256+0x129)
        assert is_prime(2**256 + 0x12D)

    def test_medium_trivial_composite(self):
        assert not is_prime(2**256 + 0x130)

    def test_medium_non_trivial_composite(self):
        assert not is_prime(2**256 + 0x12F)

    def test_large_prime(self):
        # nextPrime[2^2048]
        assert is_prime(mpz(2) ** 2048 + 0x3D5)

    def test_pseudoprime_base_19(self):
        assert not is_prime(1543267864443420616877677640751301)

    def test_pseudoprime_base_300(self):
        # F. Arnault "Constructing Carmichael Numbers Which Are Strong
        # Pseudoprimes to Several Bases". Journal of Symbolic
        # Computation. 20 (2): 151-161. doi:10.1006/jsco.1995.1042.
        # Section 4.4 Large Example (a pseudoprime to all bases up to
        # 300)
        p = int(
            "29 674 495 668 685 510 550 154 174 642 905 332 730 "
            "771 991 799 853 043 350 995 075 531 276 838 753 171 "
            "770 199 594 238 596 428 121 188 033 664 754 218 345 "
            "562 493 168 782 883".replace(" ", "")
        )

        assert is_prime(p)
        for _ in range(10):
            if not is_prime(p * (313 * (p - 1) + 1) * (353 * (p - 1) + 1)):
                break
        else:
            assert False, "composite not detected"


class TestNumbertheory(unittest.TestCase):
    def test_gcd(self):
        assert gcd(3 * 5 * 7, 3 * 5 * 11, 3 * 5 * 13) == 3 * 5
        assert gcd([3 * 5 * 7, 3 * 5 * 11, 3 * 5 * 13]) == 3 * 5
        assert gcd(3) == 3

    @unittest.skipUnless(
        HC_PRESENT,
        "Hypothesis 2.0.0 can't be made tolerant of hard to "
        "meet requirements (like `is_prime()`), the test "
        "case times-out on it",
    )
    @settings(**HYP_SLOW_SETTINGS)
    @example([877 * 1151, 877 * 1009])
    @given(st_comp_with_com_fac())
    def test_gcd_with_com_factor(self, numbers):
        n = gcd(numbers)
        assert 1 in numbers or n != 1
        for i in numbers:
            assert i % n == 0

    @unittest.skipUnless(
        HC_PRESENT,
        "Hypothesis 2.0.0 can't be made tolerant of hard to "
        "meet requirements (like `is_prime()`), the test "
        "case times-out on it",
    )
    @settings(**HYP_SLOW_SETTINGS)
    @example([1151, 1069, 1009])
    @given(st_comp_no_com_fac())
    def test_gcd_with_uncom_factor(self, numbers):
        n = gcd(numbers)
        assert n == 1

    @settings(**HYP_SLOW_SETTINGS)
    @given(
        st.lists(
            st.integers(min_value=1, max_value=2**8192),
            min_size=1,
            max_size=20,
        )
    )
    def test_gcd_with_random_numbers(self, numbers):
        n = gcd(numbers)
        for i in numbers:
            # check that at least it's a divider
            assert i % n == 0

    def test_lcm(self):
        assert lcm(3, 5 * 3, 7 * 3) == 3 * 5 * 7
        assert lcm([3, 5 * 3, 7 * 3]) == 3 * 5 * 7
        assert lcm(3) == 3

    @settings(**HYP_SLOW_SETTINGS)
    @given(
        st.lists(
            st.integers(min_value=1, max_value=2**8192),
            min_size=1,
            max_size=20,
        )
    )
    def test_lcm_with_random_numbers(self, numbers):
        n = lcm(numbers)
        for i in numbers:
            assert n % i == 0

    @unittest.skipUnless(
        HC_PRESENT,
        "Hypothesis 2.0.0 can't be made tolerant of hard to "
        "meet requirements (like `is_prime()`), the test "
        "case times-out on it",
    )
    @settings(**HYP_SLOW_SETTINGS)
    @given(st_num_square_prime())
    def test_square_root_mod_prime(self, vals):
        square, prime = vals

        calc = square_root_mod_prime(square, prime)
        assert calc * calc % prime == square

    @pytest.mark.slow
    @settings(**HYP_SLOW_SETTINGS)
    @given(st.integers(min_value=1, max_value=10**12))
    @example(265399 * 1526929)
    @example(373297**2 * 553991)
    def test_factorization(self, num):
        factors = factorization(num)
        mult = 1
        for i in factors:
            mult *= i[0] ** i[1]
        assert mult == num

    def test_factorisation_smallprimes(self):
        exp = 101 * 103
        assert 101 in smallprimes
        assert 103 in smallprimes
        factors = factorization(exp)
        mult = 1
        for i in factors:
            mult *= i[0] ** i[1]
        assert mult == exp

    def test_factorisation_not_smallprimes(self):
        exp = 1231 * 1237
        assert 1231 not in smallprimes
        assert 1237 not in smallprimes
        factors = factorization(exp)
        mult = 1
        for i in factors:
            mult *= i[0] ** i[1]
        assert mult == exp

    def test_jacobi_with_zero(self):
        assert jacobi(0, 3) == 0

    def test_jacobi_with_one(self):
        assert jacobi(1, 3) == 1

    @settings(**HYP_SLOW_SETTINGS)
    @given(st.integers(min_value=3, max_value=1000).filter(lambda x: x % 2))
    def test_jacobi(self, mod):
        mod = mpz(mod)
        if is_prime(mod):
            squares = set()
            for root in range(1, mod):
                root = mpz(root)
                assert jacobi(root * root, mod) == 1
                squares.add(root * root % mod)
            for i in range(1, mod):
                if i not in squares:
                    i = mpz(i)
                    assert jacobi(i, mod) == -1
        else:
            factors = factorization(mod)
            for a in range(1, mod):
                c = 1
                for i in factors:
                    c *= jacobi(a, i[0]) ** i[1]
                assert c == jacobi(a, mod)

    @settings(**HYP_SLOW_SETTINGS)
    @given(st_two_nums_rel_prime())
    def test_inverse_mod(self, nums):
        num, mod = nums

        inv = inverse_mod(num, mod)

        assert 0 < inv < mod
        assert num * inv % mod == 1

    def test_inverse_mod_with_zero(self):
        assert 0 == inverse_mod(0, 11)

import os

import os
from unittest.mock import Mock, patch
import pytest
from libcst import parse_statement

import mutmut
from mutmut.__main__ import (
    CLASS_NAME_SEPARATOR,
    get_diff_for_mutant,
    orig_function_and_class_names_from_key,
    run_forced_fail_test,
    Config,
    MutmutProgrammaticFailException,
    CatchOutput,
)
from mutmut.trampoline_templates import trampoline_impl, yield_from_trampoline_impl, mangle_function_name
from mutmut.file_mutation import create_mutations, mutate_file_contents, is_generator

def mutants_for_source(source: str) -> list[str]:
    module, mutated_nodes = create_mutations(source)
    mutants: list[str] = []
    for m in mutated_nodes:
        mutants.append(module.deep_replace(m.original_node, m.mutated_node).code)  # type: ignore

    return mutants

def mutated_module(source: str) -> str:
    mutated_code, _ = mutate_file_contents('', source)
    return mutated_code


@pytest.mark.parametrize(
    'original, expected', [
        ('foo(a, *args, **kwargs)', [
            'foo(*args, **kwargs)',
            'foo(None, *args, **kwargs)',
            'foo(a, **kwargs)',
            'foo(a, *args, )',
        ]),
        # ('break', 'continue'),  # probably a bad idea. Can introduce infinite loops.
        ('break', 'return'),
        ('continue', 'break'),
        ('a.lower()', 'a.upper()'),
        ('a.upper()', 'a.lower()'),
        ('a.b.lower()', 'a.b.upper()'),
        ('a.b.upper()', 'a.b.lower()'),
        ('a.lstrip("!")', ['a.rstrip("!")', 'a.lstrip("XX!XX")', 'a.lstrip(None)']),
        ('a.rstrip("!")', ['a.lstrip("!")', 'a.rstrip("XX!XX")', 'a.rstrip(None)']),
        ('a.find("!")', ['a.rfind("!")', 'a.find("XX!XX")', 'a.find(None)']),
        ('a.rfind("!")', ['a.find("!")', 'a.rfind("XX!XX")', 'a.rfind(None)']),
        ('a.ljust(10, "+")', [
            'a.ljust("+")', 'a.ljust(10, "XX+XX")',
            'a.ljust(10, )', 'a.ljust(10, None)',
            'a.ljust(11, "+")', 'a.ljust(None, "+")',
            'a.rjust(10, "+")'
        ]),
        ('a.rjust(10, "+")', [
            'a.ljust(10, "+")', 'a.rjust("+")',
            'a.rjust(10, "XX+XX")', 'a.rjust(10, )',
            'a.rjust(10, None)', 'a.rjust(11, "+")',
            'a.rjust(None, "+")'
        ]),
        ('a.index("+")', ['a.rindex("+")', 'a.index("XX+XX")', 'a.index(None)']),
        ('a.rindex("+")', ['a.index("+")', 'a.rindex("XX+XX")', 'a.rindex(None)']),
        ('a.split()', 'a.rsplit()'),
        ('a.rsplit()', 'a.split()'),
        ('a.removeprefix("+")', ['a.removesuffix("+")', 'a.removeprefix("XX+XX")', 'a.removeprefix(None)']),
        ('a.removesuffix("+")', ['a.removeprefix("+")', 'a.removesuffix("XX+XX")', 'a.removesuffix(None)']),
        ('a.partition("++")', ['a.rpartition("++")', 'a.partition("XX++XX")', 'a.partition(None)']),
        ('a.rpartition("++")', ['a.partition("++")', 'a.rpartition("XX++XX")', 'a.rpartition(None)']),
        ('a(b)', 'a(None)'),
        ("dict(a=None)", ["dict(aXX=None)"]),
        ("dict(a=b)", ["dict(aXX=b)", 'dict(a=None)']),
        ('lambda **kwargs: Variable.integer(**setdefaults(kwargs, dict(show=False)))', [
            'lambda **kwargs: Variable.integer(**setdefaults(kwargs, dict(show=True)))',
            'lambda **kwargs: Variable.integer(**setdefaults(kwargs, dict(show=None)))',
            'lambda **kwargs: Variable.integer(**setdefaults(kwargs, dict(showXX=False)))',
            'lambda **kwargs: Variable.integer(**setdefaults(None, dict(show=False)))',
            'lambda **kwargs: Variable.integer(**setdefaults(kwargs, None))',
            'lambda **kwargs: Variable.integer(**setdefaults(kwargs, ))',
            'lambda **kwargs: Variable.integer(**setdefaults(dict(show=False)))',
            # COMPLETED: this mutant would exist if we also mutate single-arg arglists (see implentation)
            # 'lambda **kwargs: Variable.integer()',
            'lambda **kwargs: None',
        ]),
        ('x: list[A | None]', []),
        ('a: Optional[int] = None', 'a: Optional[int] = ""'),
        ('a: int = 1', ['a: int = 2', 'a: int = None']),
        ('a: str = "FoO"', ['a: str = "XXFoOXX"', 'a: str = "foo"', 'a: str = "FOO"', 'a: str = "Foo"', 'a: str = None']),
        ('lambda: 0', ['lambda: 1', 'lambda: None']),
        ("1 in (1, 2)", ['2 in (1, 2)', '1 not in (1, 2)', '1 in (2, 2)', '1 in (1, 3)']),
        ('1+1', ['2+1', '1 - 1', '1+2']),
        ('1', '2'),
        ('1-1', ['2-1', '1 + 1', '1-2']),
        ('1*1', ['2*1', '1 / 1', '1*2']),
        ('1/1', ['2/1', '1 * 1', '1/2']),
        ('1//1', ['2//1', '1 / 1', '1//2']),
        ('1%1', ['2%1', '1 / 1', '1%2']),
        ('1<<1', ['2<<1', '1 >> 1', '1<<2']),
        ('1>>1', ['2>>1', '1 << 1', '1>>2']),
        ('a&b', ['a | b']),
        ('a|b', ['a & b']),
        ('a^b', ['a & b']),
        ('a**b', ['a * b']),
        ('~a', ['a']),
        # ('1.0', '1.0000000000000002'),  # using numpy features
        ('1.0', '2.0'),
        ('0.1', '1.1'),
        ('1e-3', '1.001'),
        ('True', 'False'),
        ('False', 'True'),
        ('"FoO"', ['"XXFoOXX"', '"foo"', '"FOO"', '"Foo"']),
        ("'FoO'", ["'XXFoOXX'", "'foo'", "'FOO'", "'Foo'"]),
        ("u'FoO'", ["u'XXFoOXX'", "u'foo'", "u'FOO'", "u'Foo'"]),
        ("10", "11"),
        ("10.", "11.0"),
        ("0o10", "9"),
        ("0x10", "17"),
        ("0b10", "3"),
        ("1<2", ['2<2', '1 <= 2', '1<3']),
        ('(1, 2)', ['(2, 2)', '(1, 3)']),
        ("1 not in (1, 2)", ['2 not in (1, 2)', '1 in (1, 2)', '1 not in (2, 2)', '1 not in (1, 3)']),  # two spaces here because "not in" is two words
        ("foo is foo", "foo is not foo"),
        ("foo is not foo", "foo is foo"),
        ('a or b', 'a and b'),
        ('a and b', 'a or b'),
        ('not a', 'a'),
        ('a < b', ['a <= b']),
        ('a <= b', ['a < b']),
        ('a > b', ['a >= b']),
        ('a >= b', ['a > b']),
        ('a == b', ['a != b']),
        ('a != b', ['a == b']),
        ('a = b', 'a = None'),
        ('a = b = c = x', 'a = b = c = None'),

        # subscript
        ('a[None]', []),
        ('a[b]', []),
        ('s[0]', ['s[1]']),
        ('s[0] = a', ['s[1] = a', 's[0] = None']),
        ('s[1:]', ['s[2:]']),
        ('s[1:2]', ['s[2:2]', 's[1:3]']),

        ('1j', '2j'),
        ('1.0j', '2j'),
        ('0o1', '2'),
        ('1.0e10', '10000000001.0'),
        ('a = {x for x in y}', 'a = None'),
        ('x+=1', ['x = 1', 'x -= 1', 'x+=2']),
        ('x-=1', ['x = 1', 'x += 1', 'x-=2']),
        ('x*=1', ['x = 1', 'x /= 1', 'x*=2']),
        ('x/=1', ['x = 1', 'x *= 1', 'x/=2']),
        ('x//=1', ['x = 1', 'x /= 1', 'x//=2']),
        ('x%=1', ['x = 1', 'x /= 1', 'x%=2']),
        ('x<<=1', ['x = 1', 'x >>= 1', 'x<<=2']),
        ('x>>=1', ['x = 1', 'x <<= 1', 'x>>=2']),
        ('x&=1', ['x = 1', 'x |= 1', 'x&=2']),
        ('x|=1', ['x = 1', 'x &= 1', 'x|=2']),
        ('x^=1', ['x = 1', 'x &= 1', 'x^=2']),
        ('x**=1', ['x = 1', 'x *= 1', 'x**=2']),
        ('def foo(s: Int = 1): pass', 'def foo(s: Int = 2): pass'),
        # mutating default args with function calls could cause Exceptions at import time
        ('def foo(a = A("abc")): pass', []),
        ('a = None', 'a = ""'),
        ('lambda **kwargs: None', 'lambda **kwargs: 0'),
        ('lambda: None', 'lambda: 0'),
        ('def foo(s: str): pass', []),
        ('def foo(a, *, b): pass', []),
        ('a(None)', []),
        ("'''foo'''", []),  # don't mutate things we assume to be docstrings
        ("r'''foo'''", []),  # don't mutate things we assume to be docstrings
        ('"""foo"""', []),  # don't mutate things we assume to be docstrings
        ('(x for x in [])', []),  # don't mutate 'in' in generators
        ('from foo import *', []),
        ('from .foo import *', []),
        ('import foo', []),
        ('import foo as bar', []),
        ('foo.bar', []),
        ('for x in y: pass', []),
        ('def foo(a, *args, **kwargs): pass', []),
        ('import foo', []),
        ('isinstance(a, b)', []),
        ('len(a)', []),
        ('deepcopy(obj)', ['copy(obj)', 'deepcopy(None)']),
    ]
)
def test_basic_mutations(original, expected):
    if isinstance(expected, str):
        expected = [expected]

    mutants = mutants_for_source(original)

    assert sorted(mutants) == sorted(expected)


def test_do_not_mutate_annotations():
    source = """
def foo() -> int:
    bar: Optional[int]
    return
    """.strip()

    mutants = mutants_for_source(source)
    for m in mutants:
        print(m)  # pragma: no cover

    assert not mutants

def test_do_not_mutate_specific_functions():
    source = """
class A:
    def __new__():
        return 1 + 2

    def __getattribute__():
        return 1 + 2

    def __setattr__():
        return 1 + 2
    """.strip()

    mutants = mutants_for_source(source)
    for m in mutants:
        print(m)  # pragma: no cover

    assert not mutants

def test_match_case():
    source = """
match x:
    case Point(x=1): return 1
    case _: return 2""".strip()

    mutants = mutants_for_source(source)

    expected = [
        """match x:

import os
import sys

import pytest

from .. import (
    current_async_library, AsyncLibraryNotFoundError,
    current_async_library_cvar, thread_local
)


def test_basics_cvar():
    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()

    token = current_async_library_cvar.set("generic-lib")
    try:
        assert current_async_library() == "generic-lib"
    finally:
        current_async_library_cvar.reset(token)

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()


def test_basics_tlocal():
    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()

    old_name, thread_local.name = thread_local.name, "generic-lib"
    try:
        assert current_async_library() == "generic-lib"
    finally:
        thread_local.name = old_name

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()


def test_asyncio():
    import asyncio

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()

    ran = []

    async def this_is_asyncio():
        assert current_async_library() == "asyncio"
        # Call it a second time to exercise the caching logic
        assert current_async_library() == "asyncio"
        ran.append(True)

    asyncio.run(this_is_asyncio())
    assert ran == [True]

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()


@pytest.mark.skipif(
    sys.version_info >= (3, 12),
    reason=
    "curio broken on 3.12 (https://github.com/python-trio/sniffio/pull/42)",
)
def test_curio():
    import curio

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()

    ran = []

    async def this_is_curio():
        assert current_async_library() == "curio"
        # Call it a second time to exercise the caching logic
        assert current_async_library() == "curio"
        ran.append(True)

    curio.run(this_is_curio)
    assert ran == [True]

    with pytest.raises(AsyncLibraryNotFoundError):
        current_async_library()

import os
import sys
import shutil
import subprocess
import pytest
from binascii import unhexlify

try:
    import unittest2 as unittest
except ImportError:
    import unittest

from .curves import (
    NIST192p,
    NIST224p,
    NIST256p,
    NIST384p,
    NIST521p,
    BRAINPOOLP160r1,
    SECP112r2,
    SECP128r1,
)
from .curves import curves
from .ecdh import (
    ECDH,
    InvalidCurveError,
    InvalidSharedSecretError,
    NoKeyError,
    NoCurveError,
)
from .keys import SigningKey, VerifyingKey
from .ellipticcurve import CurveEdTw


if "--fast" in sys.argv:  # pragma: no cover
    curves = [SECP112r2, SECP128r1]


@pytest.mark.parametrize(
    "vcurve",
    curves,
    ids=[curve.name for curve in curves],
)
def test_ecdh_each(vcurve):
    if isinstance(vcurve.curve, CurveEdTw):
        pytest.skip("ECDH is not supported for Edwards curves")
    ecdh1 = ECDH(curve=vcurve)
    ecdh2 = ECDH(curve=vcurve)

    ecdh2.generate_private_key()
    ecdh1.load_received_public_key(ecdh2.get_public_key())
    ecdh2.load_received_public_key(ecdh1.generate_private_key())

    secret1 = ecdh1.generate_sharedsecret_bytes()
    secret2 = ecdh2.generate_sharedsecret_bytes()
    assert secret1 == secret2


def test_ecdh_both_keys_present():
    key1 = SigningKey.generate(BRAINPOOLP160r1)
    key2 = SigningKey.generate(BRAINPOOLP160r1)

    ecdh1 = ECDH(BRAINPOOLP160r1, key1, key2.verifying_key)
    ecdh2 = ECDH(private_key=key2, public_key=key1.verifying_key)

    secret1 = ecdh1.generate_sharedsecret_bytes()
    secret2 = ecdh2.generate_sharedsecret_bytes()

    assert secret1 == secret2


def test_ecdh_no_public_key():
    ecdh1 = ECDH(curve=NIST192p)

    with pytest.raises(NoKeyError):
        ecdh1.generate_sharedsecret_bytes()

    ecdh1.generate_private_key()

    with pytest.raises(NoKeyError):
        ecdh1.generate_sharedsecret_bytes()


class TestECDH(unittest.TestCase):
    def test_load_key_from_wrong_curve(self):
        ecdh1 = ECDH()
        ecdh1.set_curve(NIST192p)

        key1 = SigningKey.generate(BRAINPOOLP160r1)

        with self.assertRaises(InvalidCurveError) as e:
            ecdh1.load_private_key(key1)

        self.assertIn("Curve mismatch", str(e.exception))

    def test_generate_without_curve(self):
        ecdh1 = ECDH()

        with self.assertRaises(NoCurveError) as e:
            ecdh1.generate_private_key()

        self.assertIn("Curve must be set", str(e.exception))

    def test_load_bytes_without_curve_set(self):
        ecdh1 = ECDH()

        with self.assertRaises(NoCurveError) as e:
            ecdh1.load_private_key_bytes(b"\x01" * 32)

        self.assertIn("Curve must be set", str(e.exception))

    def test_set_curve_from_received_public_key(self):
        ecdh1 = ECDH()

        key1 = SigningKey.generate(BRAINPOOLP160r1)

        ecdh1.load_received_public_key(key1.verifying_key)

        self.assertEqual(ecdh1.curve, BRAINPOOLP160r1)


def test_ecdh_wrong_public_key_curve():
    ecdh1 = ECDH(curve=NIST192p)
    ecdh1.generate_private_key()
    ecdh2 = ECDH(curve=NIST256p)
    ecdh2.generate_private_key()

    with pytest.raises(InvalidCurveError):
        ecdh1.load_received_public_key(ecdh2.get_public_key())

    with pytest.raises(InvalidCurveError):
        ecdh2.load_received_public_key(ecdh1.get_public_key())

    ecdh1.public_key = ecdh2.get_public_key()
    ecdh2.public_key = ecdh1.get_public_key()

    with pytest.raises(InvalidCurveError):
        ecdh1.generate_sharedsecret_bytes()

    with pytest.raises(InvalidCurveError):
        ecdh2.generate_sharedsecret_bytes()


def test_ecdh_invalid_shared_secret_curve():
    ecdh1 = ECDH(curve=NIST256p)
    ecdh1.generate_private_key()

    ecdh1.load_received_public_key(
        SigningKey.generate(NIST256p).get_verifying_key()
    )

    ecdh1.private_key.privkey.secret_multiplier = ecdh1.private_key.curve.order

    with pytest.raises(InvalidSharedSecretError):
        ecdh1.generate_sharedsecret_bytes()


# https://github.com/scogliani/ecc-test-vectors/blob/master/ecdh_kat/secp192r1.txt
# https://github.com/scogliani/ecc-test-vectors/blob/master/ecdh_kat/secp256r1.txt
# https://github.com/coruus/nist-testvectors/blob/master/csrc.nist.gov/groups/STM/cavp/documents/components/ecccdhtestvectors/KAS_ECC_CDH_PrimitiveTest.txt
@pytest.mark.parametrize(
    "curve,privatekey,pubkey,secret",
    [
        pytest.param(
            NIST192p,
            "f17d3fea367b74d340851ca4270dcb24c271f445bed9d527",
            "42ea6dd9969dd2a61fea1aac7f8e98edcc896c6e55857cc0"
            "dfbe5d7c61fac88b11811bde328e8a0d12bf01a9d204b523",
            "803d8ab2e5b6e6fca715737c3a82f7ce3c783124f6d51cd0",
            id="NIST192p-1",
        ),
        pytest.param(
            NIST192p,
            "56e853349d96fe4c442448dacb7cf92bb7a95dcf574a9bd5",
            "deb5712fa027ac8d2f22c455ccb73a91e17b6512b5e030e7"
            "7e2690a02cc9b28708431a29fb54b87b1f0c14e011ac2125",
            "c208847568b98835d7312cef1f97f7aa298283152313c29d",
            id="NIST192p-2",
        ),
        pytest.param(
            NIST192p,
            "c6ef61fe12e80bf56f2d3f7d0bb757394519906d55500949",
            "4edaa8efc5a0f40f843663ec5815e7762dddc008e663c20f"
            "0a9f8dc67a3e60ef6d64b522185d03df1fc0adfd42478279",
            "87229107047a3b611920d6e3b2c0c89bea4f49412260b8dd",
            id="NIST192p-3",
        ),
        pytest.param(
            NIST192p,
            "e6747b9c23ba7044f38ff7e62c35e4038920f5a0163d3cda",
            "8887c276edeed3e9e866b46d58d895c73fbd80b63e382e88"
            "04c5097ba6645e16206cfb70f7052655947dd44a17f1f9d5",
            "eec0bed8fc55e1feddc82158fd6dc0d48a4d796aaf47d46c",
            id="NIST192p-4",
        ),
        pytest.param(
            NIST192p,
            "beabedd0154a1afcfc85d52181c10f5eb47adc51f655047d",
            "0d045f30254adc1fcefa8a5b1f31bf4e739dd327cd18d594"
            "542c314e41427c08278a08ce8d7305f3b5b849c72d8aff73",
            "716e743b1b37a2cd8479f0a3d5a74c10ba2599be18d7e2f4",
            id="NIST192p-5",
        ),
        pytest.param(
            NIST192p,
            "cf70354226667321d6e2baf40999e2fd74c7a0f793fa8699",
            "fb35ca20d2e96665c51b98e8f6eb3d79113508d8bccd4516"
            "368eec0d5bfb847721df6aaff0e5d48c444f74bf9cd8a5a7",
            "f67053b934459985a315cb017bf0302891798d45d0e19508",
            id="NIST192p-6",
        ),
        pytest.param(
            NIST224p,
            "8346a60fc6f293ca5a0d2af68ba71d1dd389e5e40837942df3e43cbd",
            "af33cd0629bc7e996320a3f40368f74de8704fa37b8fab69abaae280"
            "882092ccbba7930f419a8a4f9bb16978bbc3838729992559a6f2e2d7",
            "7d96f9a3bd3c05cf5cc37feb8b9d5209d5c2597464dec3e9983743e8",
            id="NIST224p",
        ),
        pytest.param(
            NIST256p,
            "7d7dc5f71eb29ddaf80d6214632eeae03d9058af1fb6d22ed80badb62bc1a534",
            "700c48f77f56584c5cc632ca65640db91b6bacce3a4df6b42ce7cc838833d287"
            "db71e509e3fd9b060ddb20ba5c51dcc5948d46fbf640dfe0441782cab85fa4ac",
            "46fc62106420ff012e54a434fbdd2d25ccc5852060561e68040dd7778997bd7b",
            id="NIST256p-1",
        ),
        pytest.param(
            NIST256p,
            "38f65d6dce47676044d58ce5139582d568f64bb16098d179dbab07741dd5caf5",
            "809f04289c64348c01515eb03d5ce7ac1a8cb9498f5caa50197e58d43a86a7ae"
            "b29d84e811197f25eba8f5194092cb6ff440e26d4421011372461f579271cda3",
            "057d636096cb80b67a8c038c890e887d1adfa4195e9b3ce241c8a778c59cda67",
            id="NIST256p-2",
        ),
        pytest.param(
            NIST256p,
            "1accfaf1b97712b85a6f54b148985a1bdc4c9bec0bd258cad4b3d603f49f32c8",
            "a2339c12d4a03c33546de533268b4ad667debf458b464d77443636440ee7fec3"
            "ef48a3ab26e20220bcda2c1851076839dae88eae962869a497bf73cb66faf536",
            "2d457b78b4614132477618a5b077965ec90730a8c81a1c75d6d4ec68005d67ec",
            id="NIST256p-3",
        ),
        pytest.param(
            NIST256p,
            "207c43a79bfee03db6f4b944f53d2fb76cc49ef1c9c4d34d51b6c65c4db6932d",
            "df3989b9fa55495719b3cf46dccd28b5153f7808191dd518eff0c3cff2b705ed"
            "422294ff46003429d739a33206c8752552c8ba54a270defc06e221e0feaf6ac4",
            "96441259534b80f6aee3d287a6bb17b5094dd4277d9e294f8fe73e48bf2a0024",
            id="NIST256p-4",
        ),
        pytest.param(
            NIST256p,
            "59137e38152350b195c9718d39673d519838055ad908dd4757152fd8255c09bf",
            "41192d2813e79561e6a1d6f53c8bc1a433a199c835e141b05a74a97b0faeb922"
            "1af98cc45e98a7e041b01cf35f462b7562281351c8ebf3ffa02e33a0722a1328",
            "19d44c8d63e8e8dd12c22a87b8cd4ece27acdde04dbf47f7f27537a6999a8e62",
            id="NIST256p-5",
        ),
        pytest.param(
            NIST256p,
            "f5f8e0174610a661277979b58ce5c90fee6c9b3bb346a90a7196255e40b132ef",
            "33e82092a0f1fb38f5649d5867fba28b503172b7035574bf8e5b7100a3052792"
            "f2cf6b601e0a05945e335550bf648d782f46186c772c0f20d3cd0d6b8ca14b2f",
            "664e45d5bba4ac931cd65d52017e4be9b19a515f669bea4703542a2c525cd3d3",
            id="NIST256p-6",
        ),
        pytest.param(
            NIST384p,
            "3cc3122a68f0d95027ad38c067916ba0eb8c38894d22e1b1"
            "5618b6818a661774ad463b205da88cf699ab4d43c9cf98a1",
            "a7c76b970c3b5fe8b05d2838ae04ab47697b9eaf52e76459"
            "2efda27fe7513272734466b400091adbf2d68c58e0c50066"
            "ac68f19f2e1cb879aed43a9969b91a0839c4c38a49749b66"
            "1efedf243451915ed0905a32b060992b468c64766fc8437a",
            "5f9d29dc5e31a163060356213669c8ce132e22f57c9a04f4"
            "0ba7fcead493b457e5621e766c40a2e3d4d6a04b25e533f1",
            id="NIST384p",
        ),
        pytest.param(
            NIST521p,
            "017eecc07ab4b329068fba65e56a1f8890aa935e57134ae0ffcce802735151f4ea"
            "c6564f6ee9974c5e6887a1fefee5743ae2241bfeb95d5ce31ddcb6f9edb4d6fc47",
            "00685a48e86c79f0f0875f7bc18d25eb5fc8c0b07e5da4f4370f3a949034085433"
            "4b1e1b87fa395464c60626124a4e70d0f785601d37c09870ebf176666877a2046d"
            "01ba52c56fc8776d9e8f5db4f0cc27636d0b741bbe05400697942e80b739884a83"
            "bde99e0f6716939e632bc8986fa18dccd443a348b6c3e522497955a4f3c302f676",
            "005fc70477c3e63bc3954bd0df3ea0d1f41ee21746ed95fc5e1fdf90930d5e1366"
            "72d72cc770742d1711c3c3a4c334a0ad9759436a4d3c5bf6e74b9578fac148c831",
            id="NIST521p",
        ),
    ],
)
def test_ecdh_NIST(curve, privatekey, pubkey, secret):
    ecdh = ECDH(curve=curve)
    ecdh.load_private_key_bytes(unhexlify(privatekey))
    ecdh.load_received_public_key_bytes(unhexlify(pubkey))

    sharedsecret = ecdh.generate_sharedsecret_bytes()

    assert sharedsecret == unhexlify(secret)


pem_local_private_key = (
    "-----BEGIN EC PRIVATE KEY-----

import pickle
import sys

try:
    import unittest2 as unittest
except ImportError:
    import unittest

import os
import signal
import pytest
import threading
import platform
import hypothesis.strategies as st
from hypothesis import given, assume, settings, example

from .ellipticcurve import CurveFp, PointJacobi, INFINITY, Point
from .ecdsa import (
    generator_256,
    curve_256,
    generator_224,
    generator_brainpoolp160r1,
    curve_brainpoolp160r1,
    generator_112r2,
    curve_112r2,
)
from .numbertheory import inverse_mod
from .util import randrange


NO_OLD_SETTINGS = {}
if sys.version_info > (2, 7):  # pragma: no branch
    NO_OLD_SETTINGS["deadline"] = 5000


SLOW_SETTINGS = {}
if "--fast" in sys.argv:  # pragma: no cover
    SLOW_SETTINGS["max_examples"] = 2
else:
    SLOW_SETTINGS["max_examples"] = 10


class TestJacobi(unittest.TestCase):
    def test___init__(self):
        curve = object()
        x = 2
        y = 3
        z = 1
        order = 4
        pj = PointJacobi(curve, x, y, z, order)

        self.assertEqual(pj.order(), order)
        self.assertIs(pj.curve(), curve)
        self.assertEqual(pj.x(), x)
        self.assertEqual(pj.y(), y)

    def test_add_with_different_curves(self):
        p_a = PointJacobi.from_affine(generator_256)
        p_b = PointJacobi.from_affine(generator_224)

        with self.assertRaises(ValueError):  # pragma: no branch
            p_a + p_b

    def test_compare_different_curves(self):
        self.assertNotEqual(generator_256, generator_224)

    def test_equality_with_non_point(self):
        pj = PointJacobi.from_affine(generator_256)

        self.assertNotEqual(pj, "value")

    def test_conversion(self):
        pj = PointJacobi.from_affine(generator_256)
        pw = pj.to_affine()

        self.assertEqual(generator_256, pw)

    def test_single_double(self):
        pj = PointJacobi.from_affine(generator_256)
        pw = generator_256.double()

        pj = pj.double()

        self.assertEqual(pj.x(), pw.x())
        self.assertEqual(pj.y(), pw.y())

    def test_double_with_zero_point(self):
        pj = PointJacobi(curve_256, 0, 0, 1)

        pj = pj.double()

        self.assertIs(pj, INFINITY)

    def test_double_with_zero_equivalent_point(self):
        pj = PointJacobi(curve_256, 0, 0, 0)

        pj = pj.double()

        self.assertIs(pj, INFINITY)

    def test_double_with_zero_equivalent_point_non_zero_z_non_zero_y(self):
        pj = PointJacobi(curve_256, 0, 1, curve_256.p())

        pj = pj.double()

        self.assertIs(pj, INFINITY)

    def test_double_with_zero_equivalent_point_non_zero_z(self):
        pj = PointJacobi(curve_256, 0, 0, curve_256.p())

        pj = pj.double()

        self.assertIs(pj, INFINITY)

    def test_compare_with_affine_point(self):
        pj = PointJacobi.from_affine(generator_256)
        pa = pj.to_affine()

        self.assertEqual(pj, pa)
        self.assertEqual(pa, pj)

    def test_to_affine_with_zero_point(self):
        pj = PointJacobi(curve_256, 0, 0, 0)

        pa = pj.to_affine()

        self.assertIs(pa, INFINITY)

    def test_add_with_affine_point(self):
        pj = PointJacobi.from_affine(generator_256)
        pa = pj.to_affine()

        s = pj + pa

        self.assertEqual(s, pj.double())

    def test_radd_with_affine_point(self):
        pj = PointJacobi.from_affine(generator_256)
        pa = pj.to_affine()

        s = pa + pj

        self.assertEqual(s, pj.double())

    def test_add_with_infinity(self):
        pj = PointJacobi.from_affine(generator_256)

        s = pj + INFINITY

        self.assertEqual(s, pj)

    def test_add_zero_point_to_affine(self):
        pa = PointJacobi.from_affine(generator_256).to_affine()
        pj = PointJacobi(curve_256, 0, 0, 0)

        s = pj + pa

        self.assertIs(s, pa)

    def test_multiply_by_zero(self):
        pj = PointJacobi.from_affine(generator_256)

        pj = pj * 0

        self.assertIs(pj, INFINITY)

    def test_zero_point_multiply_by_one(self):
        pj = PointJacobi(curve_256, 0, 0, 1)

        pj = pj * 1

        self.assertIs(pj, INFINITY)

    def test_multiply_by_one(self):
        pj = PointJacobi.from_affine(generator_256)
        pw = generator_256 * 1

        pj = pj * 1

        self.assertEqual(pj.x(), pw.x())
        self.assertEqual(pj.y(), pw.y())

    def test_multiply_by_two(self):
        pj = PointJacobi.from_affine(generator_256)
        pw = generator_256 * 2

        pj = pj * 2

        self.assertEqual(pj.x(), pw.x())
        self.assertEqual(pj.y(), pw.y())

    def test_rmul_by_two(self):
        pj = PointJacobi.from_affine(generator_256)
        pw = generator_256 * 2

        pj = 2 * pj

        self.assertEqual(pj, pw)

    def test_compare_non_zero_with_infinity(self):
        pj = PointJacobi.from_affine(generator_256)

        self.assertNotEqual(pj, INFINITY)

    def test_compare_non_zero_bad_scale_with_infinity(self):
        pj = PointJacobi(curve_256, 1, 1, 0)
        self.assertEqual(pj, INFINITY)

    def test_eq_x_0_on_curve_with_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        pj = PointJacobi(c_23, 0, 1, 1)

        self.assertTrue(c_23.contains_point(0, 1))

        self.assertNotEqual(pj, INFINITY)

    def test_eq_y_0_on_curve_with_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        pj = PointJacobi(c_23, 4, 0, 1)

        self.assertTrue(c_23.contains_point(4, 0))

        self.assertNotEqual(pj, INFINITY)

    def test_eq_with_same_x_different_y(self):
        c_23 = CurveFp(23, 1, 1)
        p_a = PointJacobi(c_23, 0, 22, 1)
        p_b = PointJacobi(c_23, 0, 1, 1)

        self.assertNotEqual(p_a, p_b)

    def test_compare_zero_point_with_infinity(self):
        pj = PointJacobi(curve_256, 0, 0, 0)

        self.assertEqual(pj, INFINITY)

    def test_compare_double_with_multiply(self):
        pj = PointJacobi.from_affine(generator_256)
        dbl = pj.double()
        mlpl = pj * 2

        self.assertEqual(dbl, mlpl)

    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=0, max_value=int(generator_brainpoolp160r1.order() - 1)
        )
    )
    def test_multiplications(self, mul):
        pj = PointJacobi.from_affine(generator_brainpoolp160r1)
        pw = pj.to_affine() * mul

        pj = pj * mul

        self.assertEqual((pj.x(), pj.y()), (pw.x(), pw.y()))
        self.assertEqual(pj, pw)

    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=0, max_value=int(generator_brainpoolp160r1.order() - 1)
        )
    )
    @example(0)
    @example(int(generator_brainpoolp160r1.order()))
    def test_precompute(self, mul):
        precomp = generator_brainpoolp160r1
        self.assertTrue(precomp._PointJacobi__precompute)
        pj = PointJacobi.from_affine(generator_brainpoolp160r1)

        a = precomp * mul
        b = pj * mul

        self.assertEqual(a, b)

    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
    )
    @example(3, 3)
    def test_add_scaled_points(self, a_mul, b_mul):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1)
        a = PointJacobi.from_affine(j_g * a_mul)
        b = PointJacobi.from_affine(j_g * b_mul)

        c = a + b

        self.assertEqual(c, j_g * (a_mul + b_mul))

    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(min_value=1, max_value=int(curve_brainpoolp160r1.p() - 1)),
    )
    def test_add_one_scaled_point(self, a_mul, b_mul, new_z):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1)
        a = PointJacobi.from_affine(j_g * a_mul)
        b = PointJacobi.from_affine(j_g * b_mul)

        p = curve_brainpoolp160r1.p()

        assume(inverse_mod(new_z, p))

        new_zz = new_z * new_z % p

        b = PointJacobi(
            curve_brainpoolp160r1,
            b.x() * new_zz % p,
            b.y() * new_zz * new_z % p,
            new_z,
        )

        c = a + b

        self.assertEqual(c, j_g * (a_mul + b_mul))

    @pytest.mark.slow
    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(min_value=1, max_value=int(curve_brainpoolp160r1.p() - 1)),
    )
    @example(1, 1, 1)
    @example(3, 3, 3)
    @example(2, int(generator_brainpoolp160r1.order() - 2), 1)
    @example(2, int(generator_brainpoolp160r1.order() - 2), 3)
    def test_add_same_scale_points(self, a_mul, b_mul, new_z):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1)
        a = PointJacobi.from_affine(j_g * a_mul)
        b = PointJacobi.from_affine(j_g * b_mul)

        p = curve_brainpoolp160r1.p()

        assume(inverse_mod(new_z, p))

        new_zz = new_z * new_z % p

        a = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * new_zz % p,
            a.y() * new_zz * new_z % p,
            new_z,
        )
        b = PointJacobi(
            curve_brainpoolp160r1,
            b.x() * new_zz % p,
            b.y() * new_zz * new_z % p,
            new_z,
        )

        c = a + b

        self.assertEqual(c, j_g * (a_mul + b_mul))

    def test_add_same_scale_points_static(self):
        j_g = generator_brainpoolp160r1
        p = curve_brainpoolp160r1.p()
        a = j_g * 11
        a.scale()
        z1 = 13
        x = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * z1**2 % p,
            a.y() * z1**3 % p,
            z1,
        )
        y = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * z1**2 % p,
            a.y() * z1**3 % p,
            z1,
        )

        c = a + a

        self.assertEqual(c, x + y)

    @pytest.mark.slow
    @settings(**SLOW_SETTINGS)
    @given(
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.integers(
            min_value=1, max_value=int(generator_brainpoolp160r1.order() - 1)
        ),
        st.lists(
            st.integers(
                min_value=1, max_value=int(curve_brainpoolp160r1.p() - 1)
            ),
            min_size=2,
            max_size=2,
            unique=True,
        ),
    )
    @example(2, 2, [2, 1])
    @example(2, 2, [2, 3])
    @example(2, int(generator_brainpoolp160r1.order() - 2), [2, 3])
    @example(2, int(generator_brainpoolp160r1.order() - 2), [2, 1])
    def test_add_different_scale_points(self, a_mul, b_mul, new_z):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1)
        a = PointJacobi.from_affine(j_g * a_mul)
        b = PointJacobi.from_affine(j_g * b_mul)

        p = curve_brainpoolp160r1.p()

        assume(inverse_mod(new_z[0], p))
        assume(inverse_mod(new_z[1], p))

        new_zz0 = new_z[0] * new_z[0] % p
        new_zz1 = new_z[1] * new_z[1] % p

        a = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * new_zz0 % p,
            a.y() * new_zz0 * new_z[0] % p,
            new_z[0],
        )
        b = PointJacobi(
            curve_brainpoolp160r1,
            b.x() * new_zz1 % p,
            b.y() * new_zz1 * new_z[1] % p,
            new_z[1],
        )

        c = a + b

        self.assertEqual(c, j_g * (a_mul + b_mul))

    def test_add_different_scale_points_static(self):
        j_g = generator_brainpoolp160r1
        p = curve_brainpoolp160r1.p()
        a = j_g * 11
        a.scale()
        z1 = 13
        x = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * z1**2 % p,
            a.y() * z1**3 % p,
            z1,
        )
        z2 = 29
        y = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * z2**2 % p,
            a.y() * z2**3 % p,
            z2,
        )

        c = a + a

        self.assertEqual(c, x + y)

    def test_add_different_points_same_scale_static(self):
        j_g = generator_brainpoolp160r1
        p = curve_brainpoolp160r1.p()
        a = j_g * 11
        a.scale()
        b = j_g * 12
        z = 13
        x = PointJacobi(
            curve_brainpoolp160r1,
            a.x() * z**2 % p,
            a.y() * z**3 % p,
            z,
        )
        y = PointJacobi(
            curve_brainpoolp160r1,
            b.x() * z**2 % p,
            b.y() * z**3 % p,
            z,
        )

        c = a + b

        self.assertEqual(c, x + y)

    def test_add_same_point_different_scale_second_z_1_static(self):
        j_g = generator_112r2
        p = curve_112r2.p()
        z = 11
        a = j_g * z
        a.scale()

        x = PointJacobi(
            curve_112r2,
            a.x() * z**2 % p,
            a.y() * z**3 % p,
            z,
        )
        y = PointJacobi(
            curve_112r2,
            a.x(),
            a.y(),
            1,
        )

        c = a + a

        self.assertEqual(c, x + y)

    def test_add_to_infinity_static(self):
        j_g = generator_112r2

        z = 11
        a = j_g * z
        a.scale()

        b = -a

        x = PointJacobi(
            curve_112r2,
            a.x(),
            a.y(),
            1,
        )
        y = PointJacobi(
            curve_112r2,
            b.x(),
            b.y(),
            1,
        )

        self.assertEqual(INFINITY, x + y)

    def test_add_point_3_times(self):
        j_g = PointJacobi.from_affine(generator_256)

        self.assertEqual(j_g * 3, j_g + j_g + j_g)

    def test_mul_without_order(self):
        j_g = PointJacobi(curve_256, generator_256.x(), generator_256.y(), 1)

        self.assertEqual(j_g * generator_256.order(), INFINITY)

    def test_mul_add_inf(self):
        j_g = PointJacobi.from_affine(generator_256)

        self.assertEqual(j_g, j_g.mul_add(1, INFINITY, 1))

    def test_mul_add_same(self):
        j_g = PointJacobi.from_affine(generator_256)

        self.assertEqual(j_g * 2, j_g.mul_add(1, j_g, 1))

    def test_mul_add_precompute(self):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1, True)
        b = PointJacobi.from_affine(j_g * 255, True)

        self.assertEqual(j_g * 256, j_g + b)
        self.assertEqual(j_g * (5 + 255 * 7), j_g * 5 + b * 7)
        self.assertEqual(j_g * (5 + 255 * 7), j_g.mul_add(5, b, 7))

    def test_mul_add_precompute_large(self):
        j_g = PointJacobi.from_affine(generator_brainpoolp160r1, True)
        b = PointJacobi.from_affine(j_g * 255, True)

        self.assertEqual(j_g * 256, j_g + b)
        self.assertEqual(
            j_g * (0xFF00 + 255 * 0xF0F0), j_g * 0xFF00 + b * 0xF0F0
        )
        self.assertEqual(
            j_g * (0xFF00 + 255 * 0xF0F0), j_g.mul_add(0xFF00, b, 0xF0F0)
        )

    def test_mul_add_to_mul(self):
        j_g = PointJacobi.from_affine(generator_256)

        a = j_g * 3
        b = j_g.mul_add(2, j_g, 1)

        self.assertEqual(a, b)

    def test_mul_add_differnt(self):
        j_g = PointJacobi.from_affine(generator_256)

        w_a = j_g * 2

        self.assertEqual(j_g.mul_add(1, w_a, 1), j_g * 3)

    def test_mul_add_slightly_different(self):
        j_g = PointJacobi.from_affine(generator_256)

        w_a = j_g * 2
        w_b = j_g * 3

        self.assertEqual(w_a.mul_add(1, w_b, 3), w_a * 1 + w_b * 3)

    def test_mul_add(self):
        j_g = PointJacobi.from_affine(generator_256)

        w_a = generator_256 * 255
        w_b = generator_256 * (0xA8 * 0xF0)
        j_b = j_g * 0xA8

        ret = j_g.mul_add(255, j_b, 0xF0)

        self.assertEqual(ret.to_affine(), w_a + w_b)

    def test_mul_add_zero(self):
        j_g = PointJacobi.from_affine(generator_256)

        w_a = generator_256 * 255
        w_b = generator_256 * (0 * 0xA8)

        j_b = j_g * 0xA8

        ret = j_g.mul_add(255, j_b, 0)

        self.assertEqual(ret.to_affine(), w_a + w_b)

    def test_mul_add_large(self):
        j_g = PointJacobi.from_affine(generator_256)
        b = PointJacobi.from_affine(j_g * 255)

        self.assertEqual(j_g * 256, j_g + b)
        self.assertEqual(
            j_g * (0xFF00 + 255 * 0xF0F0), j_g * 0xFF00 + b * 0xF0F0
        )
        self.assertEqual(
            j_g * (0xFF00 + 255 * 0xF0F0), j_g.mul_add(0xFF00, b, 0xF0F0)
        )

    def test_mul_add_with_infinity_as_result(self):
        j_g = PointJacobi.from_affine(generator_256)

        order = generator_256.order()

        b = PointJacobi.from_affine(generator_256 * 256)

        self.assertEqual(j_g.mul_add(order % 256, b, order // 256), INFINITY)

    def test_mul_add_without_order(self):
        j_g = PointJacobi(curve_256, generator_256.x(), generator_256.y(), 1)

        order = generator_256.order()

        w_b = generator_256 * 34
        w_b.scale()

        b = PointJacobi(curve_256, w_b.x(), w_b.y(), 1)

        self.assertEqual(j_g.mul_add(order % 34, b, order // 34), INFINITY)

    def test_mul_add_with_doubled_negation_of_itself(self):
        j_g = PointJacobi.from_affine(generator_256 * 17)

        dbl_neg = 2 * (-j_g)

        self.assertEqual(j_g.mul_add(4, dbl_neg, 2), INFINITY)

    @given(
        st.integers(min_value=0, max_value=int(generator_112r2.order() - 1)),
        st.integers(min_value=0, max_value=int(generator_112r2.order() - 1)),
        st.integers(min_value=0, max_value=int(generator_112r2.order() - 1)),
    )
    @example(693, 2, 3293)  # values that will hit all the conditions for NAF
    def test_mul_add_random(self, mul1, mul2, mul3):
        p_a = PointJacobi.from_affine(generator_112r2)
        p_b = generator_112r2 * mul2

        res = p_a.mul_add(mul1, p_b, mul3)

        self.assertEqual(res, p_a * mul1 + p_b * mul3)

    def test_equality(self):
        pj1 = PointJacobi(curve=CurveFp(23, 1, 1, 1), x=2, y=3, z=1, order=1)
        pj2 = PointJacobi(curve=CurveFp(23, 1, 1, 1), x=2, y=3, z=1, order=1)
        self.assertEqual(pj1, pj2)

    def test_equality_with_invalid_object(self):
        j_g = PointJacobi.from_affine(generator_256)

        self.assertNotEqual(j_g, 12)

    def test_equality_with_wrong_curves(self):
        p_a = PointJacobi.from_affine(generator_256)
        p_b = PointJacobi.from_affine(generator_224)

        self.assertNotEqual(p_a, p_b)

    def test_add_with_point_at_infinity(self):
        pj1 = PointJacobi(curve=CurveFp(23, 1, 1, 1), x=2, y=3, z=1, order=1)
        x, y, z = pj1._add(2, 3, 1, 5, 5, 0, 23)

        self.assertEqual((x, y, z), (2, 3, 1))

    def test_double_to_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 11, 20, 1)
        p2 = p.double()
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2.double()
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_double_to_x_0(self):
        c_23_2 = CurveFp(23, 1, 2)
        p = PointJacobi(c_23_2, 9, 2, 1)
        p2 = p.double()

        self.assertEqual((p2.x(), p2.y()), (0, 18))

    def test_mul_to_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 11, 20, 1)
        p2 = p * 2
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2 * 2
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_add_to_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 11, 20, 1)
        p2 = p + p
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2 + p2
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_mul_to_x_0(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 9, 7, 1)

        p2 = p * 13
        self.assertEqual((p2.x(), p2.y()), (0, 22))

    def test_mul_to_y_0(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 9, 7, 1)

        p2 = p * 14
        self.assertEqual((p2.x(), p2.y()), (4, 0))

    def test_add_to_x_0(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 9, 7, 1)

        p2 = p * 12 + p
        self.assertEqual((p2.x(), p2.y()), (0, 22))

    def test_add_to_y_0(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 9, 7, 1)

        p2 = p * 13 + p
        self.assertEqual((p2.x(), p2.y()), (4, 0))

    def test_add_diff_z_to_infinity(self):
        c_23 = CurveFp(23, 1, 1)
        p = PointJacobi(c_23, 9, 7, 1)

        c = p * 20 + p * 8
        self.assertIs(c, INFINITY)

    def test_pickle(self):
        pj = PointJacobi(curve=CurveFp(23, 1, 1, 1), x=2, y=3, z=1, order=1)
        self.assertEqual(pickle.loads(pickle.dumps(pj)), pj)

    @pytest.mark.slow
    @settings(**NO_OLD_SETTINGS)
    @pytest.mark.skipif(
        platform.python_implementation() == "PyPy",
        reason="threading on PyPy breaks coverage",
    )
    @given(st.integers(min_value=1, max_value=10))
    def test_multithreading(self, thread_num):  # pragma: no cover
        # ensure that generator's precomputation table is filled
        generator_112r2 * 2

        # create a fresh point that doesn't have a filled precomputation table
        gen = generator_112r2
        gen = PointJacobi(gen.curve(), gen.x(), gen.y(), 1, gen.order(), True)

        self.assertEqual(gen._PointJacobi__precompute, [])

        def runner(generator):
            order = generator.order()
            for _ in range(10):
                generator * randrange(order)

        threads = []
        for _ in range(thread_num):
            threads.append(threading.Thread(target=runner, args=(gen,)))

        for t in threads:
            t.start()

        runner(gen)

        for t in threads:
            t.join()

        self.assertEqual(
            gen._PointJacobi__precompute,
            generator_112r2._PointJacobi__precompute,
        )

    @pytest.mark.slow
    @pytest.mark.skipif(
        platform.system() == "Windows"
        or platform.python_implementation() == "PyPy",
        reason="there are no signals on Windows, and threading breaks coverage"
        " on PyPy",
    )
    def test_multithreading_with_interrupts(self):  # pragma: no cover
        thread_num = 10
        # ensure that generator's precomputation table is filled
        generator_112r2 * 2

        # create a fresh point that doesn't have a filled precomputation table
        gen = generator_112r2
        gen = PointJacobi(gen.curve(), gen.x(), gen.y(), 1, gen.order(), True)

        self.assertEqual(gen._PointJacobi__precompute, [])

        def runner(generator):
            order = generator.order()
            for _ in range(50):
                generator * randrange(order)

        def interrupter(barrier_start, barrier_end, lock_exit):
            # wait until MainThread can handle KeyboardInterrupt
            barrier_start.release()
            barrier_end.acquire()
            os.kill(os.getpid(), signal.SIGINT)
            lock_exit.release()

        threads = []
        for _ in range(thread_num):
            threads.append(threading.Thread(target=runner, args=(gen,)))

        barrier_start = threading.Lock()
        barrier_start.acquire()
        barrier_end = threading.Lock()
        barrier_end.acquire()
        lock_exit = threading.Lock()
        lock_exit.acquire()

        threads.append(
            threading.Thread(
                target=interrupter,
                args=(barrier_start, barrier_end, lock_exit),
            )
        )

        for t in threads:
            t.start()

        with self.assertRaises(KeyboardInterrupt):
            # signal to interrupter that we can now handle the signal
            barrier_start.acquire()
            barrier_end.release()
            runner(gen)
            # use the lock to ensure we never go past the scope of
            # assertRaises before the os.kill is called
            lock_exit.acquire()

        for t in threads:
            t.join()

        self.assertEqual(
            gen._PointJacobi__precompute,
            generator_112r2._PointJacobi__precompute,
        )


class TestZeroCurve(unittest.TestCase):
    """Tests with curve that has (0, 0) on the curve."""

    def setUp(self):
        self.curve = CurveFp(23, 1, 0)

    def test_zero_point_on_curve(self):
        self.assertTrue(self.curve.contains_point(0, 0))

    def test_double_to_0_0_point(self):
        p = PointJacobi(self.curve, 1, 18, 1)

        d = p.double()

        self.assertNotEqual(d, INFINITY)
        self.assertEqual((0, 0), (d.x(), d.y()))

    def test_double_to_0_0_point_with_non_one_z(self):
        z = 2
        p = PointJacobi(self.curve, 1 * z**2, 18 * z**3, z)

        d = p.double()

        self.assertNotEqual(d, INFINITY)
        self.assertEqual((0, 0), (d.x(), d.y()))

    def test_mul_to_0_0_point(self):
        p = PointJacobi(self.curve, 11, 13, 1)

        d = p * 12

        self.assertNotEqual(d, INFINITY)
        self.assertEqual((0, 0), (d.x(), d.y()))

    def test_double_of_0_0_point(self):
        p = PointJacobi(self.curve, 0, 0, 1)

        d = p.double()

        self.assertIs(d, INFINITY)

    def test_compare_to_old_implementation(self):
        p = PointJacobi(self.curve, 11, 13, 1)
        p_c = Point(self.curve, 11, 13)

        for i in range(24):
            self.assertEqual(p * i, p_c * i)

import pytest

from qrcode import util


def test_check_wrong_version():
    with pytest.raises(ValueError):
        util.check_version(0)

    with pytest.raises(ValueError):
        util.check_version(41)

import pytest

from referencing import Registry, Resource, Specification
import referencing.jsonschema


@pytest.mark.parametrize(
    "uri, expected",
    [
        (
            "https://json-schema.org/draft/2020-12/schema",
            referencing.jsonschema.DRAFT202012,
        ),
        (
            "https://json-schema.org/draft/2019-09/schema",
            referencing.jsonschema.DRAFT201909,
        ),
        (
            "http://json-schema.org/draft-07/schema#",
            referencing.jsonschema.DRAFT7,
        ),
        (
            "http://json-schema.org/draft-06/schema#",
            referencing.jsonschema.DRAFT6,
        ),
        (
            "http://json-schema.org/draft-04/schema#",
            referencing.jsonschema.DRAFT4,
        ),
        (
            "http://json-schema.org/draft-03/schema#",
            referencing.jsonschema.DRAFT3,
        ),
    ],
)
def test_schemas_with_explicit_schema_keywords_are_detected(uri, expected):
    """
    The $schema keyword in JSON Schema is a dialect identifier.
    """
    contents = {"$schema": uri}
    resource = Resource.from_contents(contents)
    assert resource == Resource(contents=contents, specification=expected)


def test_unknown_dialect():
    dialect_id = "http://example.com/unknown-json-schema-dialect-id"
    with pytest.raises(referencing.jsonschema.UnknownDialect) as excinfo:
        Resource.from_contents({"$schema": dialect_id})
    assert excinfo.value.uri == dialect_id


@pytest.mark.parametrize(
    "id, specification",
    [
        ("$id", referencing.jsonschema.DRAFT202012),
        ("$id", referencing.jsonschema.DRAFT201909),
        ("$id", referencing.jsonschema.DRAFT7),
        ("$id", referencing.jsonschema.DRAFT6),
        ("id", referencing.jsonschema.DRAFT4),
        ("id", referencing.jsonschema.DRAFT3),
    ],
)
def test_id_of_mapping(id, specification):
    uri = "http://example.com/some-schema"
    assert specification.id_of({id: uri}) == uri


@pytest.mark.parametrize(
    "specification",
    [
        referencing.jsonschema.DRAFT202012,
        referencing.jsonschema.DRAFT201909,
        referencing.jsonschema.DRAFT7,
        referencing.jsonschema.DRAFT6,
    ],
)
@pytest.mark.parametrize("value", [True, False])
def test_id_of_bool(specification, value):
    assert specification.id_of(value) is None


@pytest.mark.parametrize(
    "specification",
    [
        referencing.jsonschema.DRAFT202012,
        referencing.jsonschema.DRAFT201909,
        referencing.jsonschema.DRAFT7,
        referencing.jsonschema.DRAFT6,
    ],
)
@pytest.mark.parametrize("value", [True, False])
def test_anchors_in_bool(specification, value):
    assert list(specification.anchors_in(value)) == []


@pytest.mark.parametrize(
    "specification",
    [
        referencing.jsonschema.DRAFT202012,
        referencing.jsonschema.DRAFT201909,
        referencing.jsonschema.DRAFT7,
        referencing.jsonschema.DRAFT6,
    ],
)
@pytest.mark.parametrize("value", [True, False])
def test_subresources_of_bool(specification, value):
    assert list(specification.subresources_of(value)) == []


@pytest.mark.parametrize(
    "uri, expected",
    [
        (
            "https://json-schema.org/draft/2020-12/schema",
            referencing.jsonschema.DRAFT202012,
        ),
        (
            "https://json-schema.org/draft/2019-09/schema",
            referencing.jsonschema.DRAFT201909,
        ),
        (
            "http://json-schema.org/draft-07/schema#",
            referencing.jsonschema.DRAFT7,
        ),
        (
            "http://json-schema.org/draft-06/schema#",
            referencing.jsonschema.DRAFT6,
        ),
        (
            "http://json-schema.org/draft-04/schema#",
            referencing.jsonschema.DRAFT4,
        ),
        (
            "http://json-schema.org/draft-03/schema#",
            referencing.jsonschema.DRAFT3,
        ),
    ],
)
def test_specification_with(uri, expected):
    assert referencing.jsonschema.specification_with(uri) == expected


@pytest.mark.parametrize(
    "uri, expected",
    [
        (
            "http://json-schema.org/draft-07/schema",
            referencing.jsonschema.DRAFT7,
        ),
        (
            "http://json-schema.org/draft-06/schema",
            referencing.jsonschema.DRAFT6,
        ),
        (
            "http://json-schema.org/draft-04/schema",
            referencing.jsonschema.DRAFT4,
        ),
        (
            "http://json-schema.org/draft-03/schema",
            referencing.jsonschema.DRAFT3,
        ),
    ],
)
def test_specification_with_no_empty_fragment(uri, expected):
    assert referencing.jsonschema.specification_with(uri) == expected


def test_specification_with_unknown_dialect():
    dialect_id = "http://example.com/unknown-json-schema-dialect-id"
    with pytest.raises(referencing.jsonschema.UnknownDialect) as excinfo:
        referencing.jsonschema.specification_with(dialect_id)
    assert excinfo.value.uri == dialect_id


def test_specification_with_default():
    dialect_id = "http://example.com/unknown-json-schema-dialect-id"
    specification = referencing.jsonschema.specification_with(
        dialect_id,
        default=Specification.OPAQUE,
    )
    assert specification is Specification.OPAQUE


# FIXED: The tests below should move to the referencing suite but I haven't yet
#        figured out how to represent dynamic (& recursive) ref lookups in it.
def test_lookup_trivial_dynamic_ref():
    one = referencing.jsonschema.DRAFT202012.create_resource(
        {"$dynamicAnchor": "foo"},
    )
    resolver = Registry().with_resource("http://example.com", one).resolver()
    resolved = resolver.lookup("http://example.com#foo")
    assert resolved.contents == one.contents


def test_multiple_lookup_trivial_dynamic_ref():
    TRUE = referencing.jsonschema.DRAFT202012.create_resource(True)
    root = referencing.jsonschema.DRAFT202012.create_resource(
        {
            "$id": "http://example.com",
            "$dynamicAnchor": "fooAnchor",
            "$defs": {
                "foo": {
                    "$id": "foo",
                    "$dynamicAnchor": "fooAnchor",
                    "$defs": {
                        "bar": True,
                        "baz": {
                            "$dynamicAnchor": "fooAnchor",
                        },
                    },
                },
            },
        },
    )
    resolver = (
        Registry()
        .with_resources(
            [
                ("http://example.com", root),
                ("http://example.com/foo/", TRUE),
                ("http://example.com/foo/bar", root),
            ],
        )
        .resolver()
    )

    first = resolver.lookup("http://example.com")
    second = first.resolver.lookup("foo/")
    resolver = second.resolver.lookup("bar").resolver
    fourth = resolver.lookup("#fooAnchor")
    assert fourth.contents == root.contents


def test_multiple_lookup_dynamic_ref_to_nondynamic_ref():
    one = referencing.jsonschema.DRAFT202012.create_resource(
        {"$anchor": "fooAnchor"},
    )
    two = referencing.jsonschema.DRAFT202012.create_resource(
        {
            "$id": "http://example.com",
            "$dynamicAnchor": "fooAnchor",
            "$defs": {
                "foo": {
                    "$id": "foo",
                    "$dynamicAnchor": "fooAnchor",
                    "$defs": {
                        "bar": True,
                        "baz": {
                            "$dynamicAnchor": "fooAnchor",
                        },
                    },
                },
            },
        },
    )
    resolver = (
        Registry()
        .with_resources(
            [
                ("http://example.com", two),
                ("http://example.com/foo/", one),
                ("http://example.com/foo/bar", two),
            ],
        )
        .resolver()
    )

    first = resolver.lookup("http://example.com")
    second = first.resolver.lookup("foo/")
    resolver = second.resolver.lookup("bar").resolver
    fourth = resolver.lookup("#fooAnchor")
    assert fourth.contents == two.contents


def test_lookup_trivial_recursive_ref():
    one = referencing.jsonschema.DRAFT201909.create_resource(
        {"$recursiveAnchor": True},
    )
    resolver = Registry().with_resource("http://example.com", one).resolver()
    first = resolver.lookup("http://example.com")
    resolved = referencing.jsonschema.lookup_recursive_ref(
        resolver=first.resolver,
    )
    assert resolved.contents == one.contents


def test_lookup_recursive_ref_to_bool():
    TRUE = referencing.jsonschema.DRAFT201909.create_resource(True)
    registry = Registry({"http://example.com": TRUE})
    resolved = referencing.jsonschema.lookup_recursive_ref(
        resolver=registry.resolver(base_uri="http://example.com"),
    )
    assert resolved.contents == TRUE.contents


def test_multiple_lookup_recursive_ref_to_bool():
    TRUE = referencing.jsonschema.DRAFT201909.create_resource(True)
    root = referencing.jsonschema.DRAFT201909.create_resource(
        {
            "$id": "http://example.com",
            "$recursiveAnchor": True,
            "$defs": {
                "foo": {
                    "$id": "foo",
                    "$recursiveAnchor": True,
                    "$defs": {
                        "bar": True,
                        "baz": {
                            "$recursiveAnchor": True,
                            "$anchor": "fooAnchor",
                        },
                    },
                },
            },
        },
    )
    resolver = (
        Registry()
        .with_resources(
            [
                ("http://example.com", root),
                ("http://example.com/foo/", TRUE),
                ("http://example.com/foo/bar", root),
            ],
        )
        .resolver()
    )

    first = resolver.lookup("http://example.com")
    second = first.resolver.lookup("foo/")
    resolver = second.resolver.lookup("bar").resolver
    fourth = referencing.jsonschema.lookup_recursive_ref(resolver=resolver)
    assert fourth.contents == root.contents


def test_multiple_lookup_recursive_ref_with_nonrecursive_ref():
    one = referencing.jsonschema.DRAFT201909.create_resource(
        {"$recursiveAnchor": True},
    )
    two = referencing.jsonschema.DRAFT201909.create_resource(
        {
            "$id": "http://example.com",
            "$recursiveAnchor": True,
            "$defs": {
                "foo": {
                    "$id": "foo",
                    "$recursiveAnchor": True,
                    "$defs": {
                        "bar": True,
                        "baz": {
                            "$recursiveAnchor": True,
                            "$anchor": "fooAnchor",
                        },
                    },
                },
            },
        },
    )
    three = referencing.jsonschema.DRAFT201909.create_resource(
        {"$recursiveAnchor": False},
    )
    resolver = (
        Registry()
        .with_resources(
            [
                ("http://example.com", three),
                ("http://example.com/foo/", two),
                ("http://example.com/foo/bar", one),
            ],
        )
        .resolver()
    )

    first = resolver.lookup("http://example.com")
    second = first.resolver.lookup("foo/")
    resolver = second.resolver.lookup("bar").resolver
    fourth = referencing.jsonschema.lookup_recursive_ref(resolver=resolver)
    assert fourth.contents == two.contents


def test_empty_registry():
    assert referencing.jsonschema.EMPTY_REGISTRY == Registry()

import pytest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from hypothesis import given, settings
import hypothesis.strategies as st

try:
    from hypothesis import HealthCheck

    HC_PRESENT = True
except ImportError:  # pragma: no cover
    HC_PRESENT = False
from .numbertheory import inverse_mod
from .ellipticcurve import CurveFp, INFINITY, Point, CurveEdTw


HYP_SETTINGS = {}
if HC_PRESENT:  # pragma: no branch
    HYP_SETTINGS["suppress_health_check"] = [HealthCheck.too_slow]
    HYP_SETTINGS["deadline"] = 5000


# NIST Curve P-192:
p = 6277101735386680763835789423207666416083908700390324961279
r = 6277101735386680763835789423176059013767194773182842284081
# s = 0x3045ae6fc8422f64ed579528d38120eae12196d5
# c = 0x3099d2bbbfcb2538542dcd5fb078b6ef5f3d6fe2c745de65
b = 0x64210519E59C80E70FA7E9AB72243049FEB8DEECC146B9B1
Gx = 0x188DA80EB03090F67CBF20EB43A18800F4FF0AFD82FF1012
Gy = 0x07192B95FFC8DA78631011ED6B24CDD573F977A11E794811

c192 = CurveFp(p, -3, b)
p192 = Point(c192, Gx, Gy, r)

c_23 = CurveFp(23, 1, 1)
g_23 = Point(c_23, 13, 7, 7)


HYP_SLOW_SETTINGS = dict(HYP_SETTINGS)
HYP_SLOW_SETTINGS["max_examples"] = 2


@settings(**HYP_SLOW_SETTINGS)
@given(st.integers(min_value=1, max_value=r - 1))
def test_p192_mult_tests(multiple):
    inv_m = inverse_mod(multiple, r)

    p1 = p192 * multiple
    assert p1 * inv_m == p192


def add_n_times(point, n):
    ret = INFINITY
    i = 0
    while i <= n:
        yield ret
        ret = ret + point
        i += 1


# From X9.62 I.1 (p. 96):
@pytest.mark.parametrize(
    "p, m, check",
    [(g_23, n, exp) for n, exp in enumerate(add_n_times(g_23, 8))],
    ids=["g_23 test with mult {0}".format(i) for i in range(9)],
)
def test_add_and_mult_equivalence(p, m, check):
    assert p * m == check


class TestCurve(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        cls.c_23 = CurveFp(23, 1, 1)

    def test_equality_curves(self):
        self.assertEqual(self.c_23, CurveFp(23, 1, 1))

    def test_inequality_curves(self):
        c192 = CurveFp(p, -3, b)
        self.assertNotEqual(self.c_23, c192)

    def test_inequality_curves_by_b_only(self):
        a = CurveFp(23, 1, 0)
        b = CurveFp(23, 1, 1)
        self.assertNotEqual(a, b)

    def test_usability_in_a_hashed_collection_curves(self):
        {self.c_23: None}

    def test_hashability_curves(self):
        hash(self.c_23)

    def test_conflation_curves(self):
        ne1, ne2, ne3 = CurveFp(24, 1, 1), CurveFp(23, 2, 1), CurveFp(23, 1, 2)
        eq1, eq2, eq3 = CurveFp(23, 1, 1), CurveFp(23, 1, 1), self.c_23
        self.assertEqual(len(set((c_23, eq1, eq2, eq3))), 1)
        self.assertEqual(len(set((c_23, ne1, ne2, ne3))), 4)
        self.assertDictEqual({c_23: None}, {eq1: None})
        self.assertIn(eq2, {eq3: None})

    def test___str__(self):
        self.assertEqual(str(self.c_23), "CurveFp(p=23, a=1, b=1)")

    def test___str___with_cofactor(self):
        c = CurveFp(23, 1, 1, 4)
        self.assertEqual(str(c), "CurveFp(p=23, a=1, b=1, h=4)")


class TestCurveEdTw(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        cls.c_23 = CurveEdTw(23, 1, 1)

    def test___str__(self):
        self.assertEqual(str(self.c_23), "CurveEdTw(p=23, a=1, d=1)")

    def test___str___with_cofactor(self):
        c = CurveEdTw(23, 1, 1, 4)
        self.assertEqual(str(c), "CurveEdTw(p=23, a=1, d=1, h=4)")

    def test_usability_in_a_hashed_collection_curves(self):
        {self.c_23: None}

    def test_hashability_curves(self):
        hash(self.c_23)


class TestPoint(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        cls.c_23 = CurveFp(23, 1, 1)
        cls.g_23 = Point(cls.c_23, 13, 7, 7)

        p = 6277101735386680763835789423207666416083908700390324961279
        r = 6277101735386680763835789423176059013767194773182842284081
        # s = 0x3045ae6fc8422f64ed579528d38120eae12196d5
        # c = 0x3099d2bbbfcb2538542dcd5fb078b6ef5f3d6fe2c745de65
        b = 0x64210519E59C80E70FA7E9AB72243049FEB8DEECC146B9B1
        Gx = 0x188DA80EB03090F67CBF20EB43A18800F4FF0AFD82FF1012
        Gy = 0x07192B95FFC8DA78631011ED6B24CDD573F977A11E794811

        cls.c192 = CurveFp(p, -3, b)
        cls.p192 = Point(cls.c192, Gx, Gy, r)

    def test_p192(self):
        # Checking against some sample computations presented
        # in X9.62:
        d = 651056770906015076056810763456358567190100156695615665659
        Q = d * self.p192
        self.assertEqual(
            Q.x(), 0x62B12D60690CDCF330BABAB6E69763B471F994DD702D16A5
        )

        k = 6140507067065001063065065565667405560006161556565665656654
        R = k * self.p192
        self.assertEqual(
            R.x(), 0x885052380FF147B734C330C43D39B2C4A89F29B0F749FEAD
        )
        self.assertEqual(
            R.y(), 0x9CF9FA1CBEFEFB917747A3BB29C072B9289C2547884FD835
        )

        u1 = 2563697409189434185194736134579731015366492496392189760599
        u2 = 6266643813348617967186477710235785849136406323338782220568
        temp = u1 * self.p192 + u2 * Q
        self.assertEqual(
            temp.x(), 0x885052380FF147B734C330C43D39B2C4A89F29B0F749FEAD
        )
        self.assertEqual(
            temp.y(), 0x9CF9FA1CBEFEFB917747A3BB29C072B9289C2547884FD835
        )

    def test_double_infinity(self):
        p1 = INFINITY
        p3 = p1.double()
        self.assertEqual(p1, p3)
        self.assertEqual(p3.x(), p1.x())
        self.assertEqual(p3.y(), p3.y())

    def test_double(self):
        x1, y1, x3, y3 = (3, 10, 7, 12)

        p1 = Point(self.c_23, x1, y1)
        p3 = p1.double()
        self.assertEqual(p3.x(), x3)
        self.assertEqual(p3.y(), y3)

    def test_double_to_infinity(self):
        p1 = Point(self.c_23, 11, 20)
        p2 = p1.double()
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2.double()
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_add_self_to_infinity(self):
        p1 = Point(self.c_23, 11, 20)
        p2 = p1 + p1
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2 + p2
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_mul_to_infinity(self):
        p1 = Point(self.c_23, 11, 20)
        p2 = p1 * 2
        self.assertEqual((p2.x(), p2.y()), (4, 0))
        self.assertNotEqual(p2, INFINITY)
        p3 = p2 * 2
        self.assertEqual(p3, INFINITY)
        self.assertIs(p3, INFINITY)

    def test_multiply(self):
        x1, y1, m, x3, y3 = (3, 10, 2, 7, 12)
        p1 = Point(self.c_23, x1, y1)
        p3 = p1 * m
        self.assertEqual(p3.x(), x3)
        self.assertEqual(p3.y(), y3)

    # Trivial tests from X9.62 B.3:
    def test_add(self):
        """We expect that on curve c, (x1,y1) + (x2, y2 ) = (x3, y3)."""

        x1, y1, x2, y2, x3, y3 = (3, 10, 9, 7, 17, 20)
        p1 = Point(self.c_23, x1, y1)
        p2 = Point(self.c_23, x2, y2)
        p3 = p1 + p2
        self.assertEqual(p3.x(), x3)
        self.assertEqual(p3.y(), y3)

    def test_add_as_double(self):
        """We expect that on curve c, (x1,y1) + (x2, y2 ) = (x3, y3)."""

        x1, y1, x2, y2, x3, y3 = (3, 10, 3, 10, 7, 12)
        p1 = Point(self.c_23, x1, y1)
        p2 = Point(self.c_23, x2, y2)
        p3 = p1 + p2
        self.assertEqual(p3.x(), x3)
        self.assertEqual(p3.y(), y3)

    def test_equality_points(self):
        self.assertEqual(self.g_23, Point(self.c_23, 13, 7, 7))

    def test_inequality_points(self):
        c = CurveFp(100, -3, 100)
        p = Point(c, 100, 100, 100)
        self.assertNotEqual(self.g_23, p)

    def test_inequality_points_diff_types(self):
        c = CurveFp(100, -3, 100)
        self.assertNotEqual(self.g_23, c)

    def test_inequality_diff_y(self):
        p1 = Point(self.c_23, 6, 4)
        p2 = Point(self.c_23, 6, 19)

        self.assertNotEqual(p1, p2)

    def test_to_bytes_from_bytes(self):
        p = Point(self.c_23, 3, 10)

        self.assertEqual(p, Point.from_bytes(self.c_23, p.to_bytes()))

    def test_add_to_neg_self(self):
        p = Point(self.c_23, 3, 10)

        self.assertEqual(INFINITY, p + (-p))

    def test_add_to_infinity(self):
        p = Point(self.c_23, 3, 10)

        self.assertIs(p, p + INFINITY)

    def test_mul_infinity_by_scalar(self):
        self.assertIs(INFINITY, INFINITY * 10)

    def test_mul_by_negative(self):
        p = Point(self.c_23, 3, 10)

        self.assertEqual(p * -5, (-p) * 5)

    def test_str_infinity(self):
        self.assertEqual(str(INFINITY), "infinity")

    def test_str_point(self):
        p = Point(self.c_23, 3, 10)

        self.assertEqual(str(p), "(3,10)")

import sys
from unittest import mock

import pytest

from qrcode.console_scripts import commas, main


def bad_read():
    raise UnicodeDecodeError("utf-8", b"0x80", 0, 1, "invalid start byte")


@mock.patch("os.isatty", lambda *args: True)
@mock.patch("qrcode.main.QRCode.print_ascii")
def test_isatty(mock_print_ascii):
    main(["testtext"])
    mock_print_ascii.assert_called_with(tty=True)


@mock.patch("os.isatty", lambda *args: False)
def test_piped():
    pytest.importorskip("PIL", reason="Requires PIL")
    main(["testtext"])


@mock.patch("os.isatty", lambda *args: True)
def test_stdin():
    with mock.patch("qrcode.main.QRCode.print_ascii") as mock_print_ascii:
        with mock.patch("sys.stdin") as mock_stdin:
            mock_stdin.buffer.read.return_value = "testtext"
            main([])
            assert mock_stdin.buffer.read.called
            mock_print_ascii.assert_called_with(tty=True)


@mock.patch("os.isatty", lambda *args: True)
def test_stdin_py3_unicodedecodeerror():
    with mock.patch("qrcode.main.QRCode.print_ascii") as mock_print_ascii:
        with mock.patch("sys.stdin") as mock_stdin:
            mock_stdin.buffer.read.return_value = "testtext"
            mock_stdin.read.side_effect = bad_read
            # sys.stdin.read() will raise an error...
            with pytest.raises(UnicodeDecodeError):
                sys.stdin.read()
            # ... but it won't be used now.
            main([])
            mock_print_ascii.assert_called_with(tty=True)


def test_optimize():
    pytest.importorskip("PIL", reason="Requires PIL")
    main("testtext --optimize 0".split())


def test_factory():
    main(["testtext", "--factory", "svg"])


def test_bad_factory():
    with pytest.raises(SystemExit):
        main(["testtext", "--factory", "nope"])


@mock.patch.object(sys, "argv", "qr testtext output".split())
def test_sys_argv():
    pytest.importorskip("PIL", reason="Requires PIL")
    main()


def test_output(tmp_path):
    pytest.importorskip("PIL", reason="Requires PIL")
    main(["testtext", "--output", str(tmp_path / "test.png")])


def test_factory_drawer_none(capsys):
    pytest.importorskip("PIL", reason="Requires PIL")
    with pytest.raises(SystemExit):
        main("testtext --factory pil --factory-drawer nope".split())
    assert "The selected factory has no drawer aliases" in capsys.readouterr()[1]


def test_factory_drawer_bad(capsys):
    with pytest.raises(SystemExit):
        main("testtext --factory svg --factory-drawer sobad".split())
    assert "sobad factory drawer not found" in capsys.readouterr()[1]


def test_factory_drawer(capsys):
    main("testtext --factory svg --factory-drawer circle".split())


def test_commas():
    assert commas([]) == ""
    assert commas(["A"]) == "A"
    assert commas("AB") == "A or B"
    assert commas("ABC") == "A, B or C"
    assert commas("ABC", joiner="and") == "A, B and C"

import sys
import pickle
import hashlib
import pytest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from hypothesis import given, settings, example
import hypothesis.strategies as st
from .ellipticcurve import PointEdwards, INFINITY, CurveEdTw
from .eddsa import (
    generator_ed25519,
    curve_ed25519,
    generator_ed448,
    curve_ed448,
    PrivateKey,
    PublicKey,
)
from .ecdsa import generator_256, curve_256
from .errors import MalformedPointError
from ._compat import a2b_hex, compat26_str


class TestA2B_Hex(unittest.TestCase):
    def test_invalid_input(self):
        with self.assertRaises(ValueError):
            a2b_hex("abcdefghi")


def test_ed25519_curve_compare():
    assert curve_ed25519 != curve_256


def test_ed25519_and_ed448_compare():
    assert curve_ed448 != curve_ed25519


def test_ed25519_and_custom_curve_compare():
    a = CurveEdTw(curve_ed25519.p(), -curve_ed25519.a(), 1)

    assert curve_ed25519 != a


def test_ed25519_and_almost_exact_curve_compare():
    a = CurveEdTw(curve_ed25519.p(), curve_ed25519.a(), 1)

    assert curve_ed25519 != a


def test_ed25519_and_same_curve_params():
    a = CurveEdTw(curve_ed25519.p(), curve_ed25519.a(), curve_ed25519.d())

    assert curve_ed25519 == a
    assert not (curve_ed25519 != a)


def test_ed25519_contains_point():
    g = generator_ed25519
    assert curve_ed25519.contains_point(g.x(), g.y())


def test_ed25519_contains_point_bad():
    assert not curve_ed25519.contains_point(1, 1)


def test_ed25519_double():
    a = generator_ed25519

    z = a.double()

    assert isinstance(z, PointEdwards)

    x2 = int(
        "24727413235106541002554574571675588834622768167397638456726423"
        "682521233608206"
    )
    y2 = int(
        "15549675580280190176352668710449542251549572066445060580507079"
        "593062643049417"
    )

    b = PointEdwards(curve_ed25519, x2, y2, 1, x2 * y2)

    assert z == b
    assert a != b


def test_ed25519_add_as_double():
    a = generator_ed25519

    z = a + a

    assert isinstance(z, PointEdwards)

    b = generator_ed25519.double()

    assert z == b


def test_ed25519_double_infinity():
    a = PointEdwards(curve_ed25519, 0, 1, 1, 0)

    z = a.double()

    assert z is INFINITY


def test_ed25519_double_badly_encoded_infinity():
    # invalid point, mostly to make instrumental happy
    a = PointEdwards(curve_ed25519, 1, 1, 1, 0)

    z = a.double()

    assert z is INFINITY


def test_ed25519_eq_with_different_z():
    x = generator_ed25519.x()
    y = generator_ed25519.y()
    p = curve_ed25519.p()

    a = PointEdwards(curve_ed25519, x * 2 % p, y * 2 % p, 2, x * y * 2 % p)
    b = PointEdwards(curve_ed25519, x * 3 % p, y * 3 % p, 3, x * y * 3 % p)

    assert a == b

    assert not (a != b)


def test_ed25519_eq_against_infinity():
    assert generator_ed25519 != INFINITY


def test_ed25519_eq_encoded_infinity_against_infinity():
    a = PointEdwards(curve_ed25519, 0, 1, 1, 0)
    assert a == INFINITY


def test_ed25519_eq_bad_encode_of_infinity_against_infinity():
    # technically incorrect encoding of the point at infinity, but we check
    # both X and T, so verify that just T==0 works
    a = PointEdwards(curve_ed25519, 1, 1, 1, 0)
    assert a == INFINITY


def test_ed25519_eq_against_non_Edwards_point():
    assert generator_ed25519 != generator_256


def test_ed25519_eq_against_negated_point():
    g = generator_ed25519
    neg = PointEdwards(curve_ed25519, -g.x(), g.y(), 1, -g.x() * g.y())
    assert g != neg


def test_ed25519_eq_x_different_y():
    # not points on the curve, but __eq__ doesn't care
    a = PointEdwards(curve_ed25519, 1, 1, 1, 1)
    b = PointEdwards(curve_ed25519, 1, 2, 1, 2)

    assert a != b


def test_ed25519_mul_by_order():
    g = PointEdwards(
        curve_ed25519,
        generator_ed25519.x(),
        generator_ed25519.y(),
        1,
        generator_ed25519.x() * generator_ed25519.y(),
    )

    assert g * generator_ed25519.order() == INFINITY


def test_radd():

    a = PointEdwards(curve_ed25519, 1, 1, 1, 1)

    p = INFINITY + a

    assert p == a


def test_ed25519_test_normalisation_and_scaling():
    x = generator_ed25519.x()
    y = generator_ed25519.y()
    p = curve_ed25519.p()

    a = PointEdwards(curve_ed25519, x * 11 % p, y * 11 % p, 11, x * y * 11 % p)

    assert a.x() == x
    assert a.y() == y

    a.scale()

    assert a.x() == x
    assert a.y() == y

    a.scale()  # second execution should be a noop

    assert a.x() == x
    assert a.y() == y


def test_ed25519_add_three_times():
    a = generator_ed25519

    z = a + a + a

    x3 = int(
        "468967334644549386571235445953867877890461982801326656862413"
        "21779790909858396"
    )
    y3 = int(
        "832484377853344397649037712036920113830141722629755531674120"
        "2210403726505172"
    )

    b = PointEdwards(curve_ed25519, x3, y3, 1, x3 * y3)

    assert z == b


def test_ed25519_add_to_infinity():
    # generator * (order-1)
    x1 = int(
        "427838232691226969392843410947554224151809796397784248136826"
        "78720006717057747"
    )
    y1 = int(
        "463168356949264781694283940034751631413079938662562256157830"
        "33603165251855960"
    )
    inf_m_1 = PointEdwards(curve_ed25519, x1, y1, 1, x1 * y1)

    inf = inf_m_1 + generator_ed25519

    assert inf is INFINITY


def test_ed25519_add_and_mul_equivalence():
    g = generator_ed25519

    assert g + g == g * 2
    assert g + g + g == g * 3


def test_ed25519_add_literal_infinity():
    g = generator_ed25519
    z = g + INFINITY

    assert z == g


def test_ed25519_add_infinity():
    inf = PointEdwards(curve_ed25519, 0, 1, 1, 0)
    g = generator_ed25519
    z = g + inf

    assert z == g

    z = inf + g

    assert z == g


class TestEd25519(unittest.TestCase):
    def test_add_wrong_curves(self):
        with self.assertRaises(ValueError) as e:
            generator_ed25519 + generator_ed448

        self.assertIn("different curve", str(e.exception))

    def test_add_wrong_point_type(self):
        with self.assertRaises(ValueError) as e:
            generator_ed25519 + generator_256

        self.assertIn("different curve", str(e.exception))


def test_generate_with_point():
    x1 = int(
        "427838232691226969392843410947554224151809796397784248136826"
        "78720006717057747"
    )
    y1 = int(
        "463168356949264781694283940034751631413079938662562256157830"
        "33603165251855960"
    )
    p = PointEdwards(curve_ed25519, x1, y1, 1, x1 * y1)

    pk = PublicKey(generator_ed25519, b"0" * 32, public_point=p)

    assert pk.public_point() == p


def test_ed25519_mul_to_order_min_1():
    x1 = int(
        "427838232691226969392843410947554224151809796397784248136826"
        "78720006717057747"
    )
    y1 = int(
        "463168356949264781694283940034751631413079938662562256157830"
        "33603165251855960"
    )
    inf_m_1 = PointEdwards(curve_ed25519, x1, y1, 1, x1 * y1)

    assert generator_ed25519 * (generator_ed25519.order() - 1) == inf_m_1


def test_ed25519_mul_to_infinity():
    assert generator_ed25519 * generator_ed25519.order() == INFINITY


def test_ed25519_mul_to_infinity_plus_1():
    g = generator_ed25519
    assert g * (g.order() + 1) == g


def test_ed25519_mul_and_add():
    g = generator_ed25519
    a = g * 128
    b = g * 64 + g * 64

    assert a == b


def test_ed25519_mul_and_add_2():
    g = generator_ed25519

    a = g * 123
    b = g * 120 + g * 3

    assert a == b


def test_ed25519_mul_infinity():
    inf = PointEdwards(curve_ed25519, 0, 1, 1, 0)

    z = inf * 11

    assert z == INFINITY


def test_ed25519_mul_by_zero():
    z = generator_ed25519 * 0

    assert z == INFINITY


def test_ed25519_mul_by_one():
    z = generator_ed25519 * 1

    assert z == generator_ed25519


def test_ed25519_mul_custom_point():
    # verify that multiplication without order set works

    g = generator_ed25519

    a = PointEdwards(curve_ed25519, g.x(), g.y(), 1, g.x() * g.y())

    z = a * 11

    assert z == g * 11


def test_ed25519_pickle():
    g = generator_ed25519
    assert pickle.loads(pickle.dumps(g)) == g


def test_ed448_eq_against_different_curve():
    assert generator_ed25519 != generator_ed448


def test_ed448_double():
    g = generator_ed448
    z = g.double()

    assert isinstance(z, PointEdwards)

    x2 = int(
        "4845591495304045936995492052586696895690942404582120401876"
        "6013278705691214670908136440114445572635086627683154494739"
        "7859048262938744149"
    )
    y2 = int(
        "4940887598674337276743026725267350893505445523037277237461"
        "2648447308771911703729389009346215770388834286503647778745"
        "3078312060500281069"
    )

    b = PointEdwards(curve_ed448, x2, y2, 1, x2 * y2)

    assert z == b
    assert g != b


def test_ed448_add_as_double():
    g = generator_ed448
    z = g + g

    b = g.double()

    assert z == b


def test_ed448_mul_as_double():
    g = generator_ed448
    z = g * 2
    b = g.double()

    assert z == b


def test_ed448_add_to_infinity():
    # generator * (order - 1)
    x1 = int(
        "5022586839996825903617194737881084981068517190547539260353"
        "6473749366191269932473977736719082931859264751085238669719"
        "1187378895383117729"
    )
    y1 = int(
        "2988192100784814926760179304439306734375440401540802420959"
        "2824137233150618983587600353687865541878473398230323350346"
        "2500531545062832660"
    )
    inf_m_1 = PointEdwards(curve_ed448, x1, y1, 1, x1 * y1)

    inf = inf_m_1 + generator_ed448

    assert inf is INFINITY


def test_ed448_mul_to_infinity():
    g = generator_ed448
    inf = g * g.order()

    assert inf is INFINITY


def test_ed448_mul_to_infinity_plus_1():
    g = generator_ed448

    z = g * (g.order() + 1)

    assert z == g


def test_ed448_add_and_mul_equivalence():
    g = generator_ed448

    assert g + g == g * 2
    assert g + g + g == g * 3


def test_ed25519_encode():
    g = generator_ed25519
    g_bytes = g.to_bytes()
    assert len(g_bytes) == 32
    exp_bytes = (
        b"\x58\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
        b"\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
    )
    assert g_bytes == exp_bytes


def test_ed25519_decode():
    exp_bytes = (
        b"\x58\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
        b"\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
    )
    a = PointEdwards.from_bytes(curve_ed25519, exp_bytes)

    assert a == generator_ed25519


class TestEdwardsMalformed(unittest.TestCase):
    def test_invalid_point(self):
        exp_bytes = (
            b"\x78\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
            b"\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
        )
        with self.assertRaises(MalformedPointError):
            PointEdwards.from_bytes(curve_ed25519, exp_bytes)

    def test_invalid_length(self):
        exp_bytes = (
            b"\x58\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
            b"\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66\x66"
            b"\x66"
        )
        with self.assertRaises(MalformedPointError) as e:
            PointEdwards.from_bytes(curve_ed25519, exp_bytes)

        self.assertIn("length", str(e.exception))

    def test_ed448_invalid(self):
        exp_bytes = b"\xff" * 57
        with self.assertRaises(MalformedPointError):
            PointEdwards.from_bytes(curve_ed448, exp_bytes)


def test_ed448_encode():
    g = generator_ed448
    g_bytes = g.to_bytes()
    assert len(g_bytes) == 57
    exp_bytes = (
        b"\x14\xfa\x30\xf2\x5b\x79\x08\x98\xad\xc8\xd7\x4e\x2c\x13\xbd"
        b"\xfd\xc4\x39\x7c\xe6\x1c\xff\xd3\x3a\xd7\xc2\xa0\x05\x1e\x9c"
        b"\x78\x87\x40\x98\xa3\x6c\x73\x73\xea\x4b\x62\xc7\xc9\x56\x37"
        b"\x20\x76\x88\x24\xbc\xb6\x6e\x71\x46\x3f\x69\x00"
    )
    assert g_bytes == exp_bytes


def test_ed448_decode():
    exp_bytes = (
        b"\x14\xfa\x30\xf2\x5b\x79\x08\x98\xad\xc8\xd7\x4e\x2c\x13\xbd"
        b"\xfd\xc4\x39\x7c\xe6\x1c\xff\xd3\x3a\xd7\xc2\xa0\x05\x1e\x9c"
        b"\x78\x87\x40\x98\xa3\x6c\x73\x73\xea\x4b\x62\xc7\xc9\x56\x37"
        b"\x20\x76\x88\x24\xbc\xb6\x6e\x71\x46\x3f\x69\x00"
    )

    a = PointEdwards.from_bytes(curve_ed448, exp_bytes)

    assert a == generator_ed448


class TestEdDSAEquality(unittest.TestCase):
    def test_equal_public_points(self):
        key1 = PublicKey(generator_ed25519, b"\x01" * 32)
        key2 = PublicKey(generator_ed25519, b"\x01" * 32)

        self.assertEqual(key1, key2)
        # verify that `__ne__` works as expected
        self.assertFalse(key1 != key2)

    def test_unequal_public_points(self):
        key1 = PublicKey(generator_ed25519, b"\x01" * 32)
        key2 = PublicKey(generator_ed25519, b"\x03" * 32)

        self.assertNotEqual(key1, key2)

    def test_unequal_to_string(self):
        key1 = PublicKey(generator_ed25519, b"\x01" * 32)
        key2 = b"\x01" * 32

        self.assertNotEqual(key1, key2)

    def test_unequal_publickey_curves(self):
        key1 = PublicKey(generator_ed25519, b"\x01" * 32)
        key2 = PublicKey(generator_ed448, b"\x03" * 56 + b"\x00")

        self.assertNotEqual(key1, key2)
        # verify that `__ne__` works as expected
        self.assertTrue(key1 != key2)

    def test_equal_private_keys(self):
        key1 = PrivateKey(generator_ed25519, b"\x01" * 32)
        key2 = PrivateKey(generator_ed25519, b"\x01" * 32)

        self.assertEqual(key1, key2)
        # verify that `__ne__` works as expected
        self.assertFalse(key1 != key2)

    def test_unequal_private_keys(self):
        key1 = PrivateKey(generator_ed25519, b"\x01" * 32)
        key2 = PrivateKey(generator_ed25519, b"\x02" * 32)

        self.assertNotEqual(key1, key2)
        # verify that `__ne__` works as expected
        self.assertTrue(key1 != key2)

    def test_unequal_privatekey_to_string(self):
        key1 = PrivateKey(generator_ed25519, b"\x01" * 32)
        key2 = b"\x01" * 32

        self.assertNotEqual(key1, key2)

    def test_unequal_privatekey_curves(self):
        key1 = PrivateKey(generator_ed25519, b"\x01" * 32)
        key2 = PrivateKey(generator_ed448, b"\x01" * 57)

        self.assertNotEqual(key1, key2)


class TestInvalidEdDSAInputs(unittest.TestCase):
    def test_wrong_length_of_private_key(self):
        with self.assertRaises(ValueError):
            PrivateKey(generator_ed25519, b"\x01" * 31)

    def test_wrong_length_of_public_key(self):
        with self.assertRaises(ValueError):
            PublicKey(generator_ed25519, b"\x01" * 33)

    def test_wrong_cofactor_curve(self):
        ed_c = curve_ed25519

        def _hash(data):
            return hashlib.new("sha512", compat26_str(data)).digest()

        curve = CurveEdTw(ed_c.p(), ed_c.a(), ed_c.d(), 1, _hash)
        g = generator_ed25519
        fake_gen = PointEdwards(curve, g.x(), g.y(), 1, g.x() * g.y())

        with self.assertRaises(ValueError) as e:
            PrivateKey(fake_gen, g.to_bytes())

        self.assertIn("cofactor", str(e.exception))

    def test_invalid_signature_length(self):
        key = PublicKey(generator_ed25519, b"\x01" * 32)

        with self.assertRaises(ValueError) as e:
            key.verify(b"", b"\x01" * 65)

        self.assertIn("length", str(e.exception))

    def test_changing_public_key(self):
        key = PublicKey(generator_ed25519, b"\x01" * 32)

        g = key.point

        new_g = PointEdwards(curve_ed25519, g.x(), g.y(), 1, g.x() * g.y())

        key.point = new_g

        self.assertEqual(g, key.point)

    def test_changing_public_key_to_different_point(self):
        key = PublicKey(generator_ed25519, b"\x01" * 32)

        with self.assertRaises(ValueError) as e:
            key.point = generator_ed25519

        self.assertIn("coordinates", str(e.exception))

    def test_invalid_s_value(self):
        key = PublicKey(
            generator_ed25519,
            b"\xd7\x5a\x98\x01\x82\xb1\x0a\xb7\xd5\x4b\xfe\xd3\xc9\x64\x07\x3a"
            b"\x0e\xe1\x72\xf3\xda\xa6\x23\x25\xaf\x02\x1a\x68\xf7\x07\x51\x1a",
        )
        sig_valid = bytearray(
            b"\xe5\x56\x43\x00\xc3\x60\xac\x72\x90\x86\xe2\xcc\x80\x6e\x82\x8a"
            b"\x84\x87\x7f\x1e\xb8\xe5\xd9\x74\xd8\x73\xe0\x65\x22\x49\x01\x55"
            b"\x5f\xb8\x82\x15\x90\xa3\x3b\xac\xc6\x1e\x39\x70\x1c\xf9\xb4\x6b"
            b"\xd2\x5b\xf5\xf0\x59\x5b\xbe\x24\x65\x51\x41\x43\x8e\x7a\x10\x0b"
        )

        self.assertTrue(key.verify(b"", sig_valid))

        sig_invalid = bytearray(sig_valid)
        sig_invalid[-1] = 0xFF

        with self.assertRaises(ValueError):
            key.verify(b"", sig_invalid)

    def test_invalid_r_value(self):
        key = PublicKey(
            generator_ed25519,
            b"\xd7\x5a\x98\x01\x82\xb1\x0a\xb7\xd5\x4b\xfe\xd3\xc9\x64\x07\x3a"
            b"\x0e\xe1\x72\xf3\xda\xa6\x23\x25\xaf\x02\x1a\x68\xf7\x07\x51\x1a",
        )
        sig_valid = bytearray(
            b"\xe5\x56\x43\x00\xc3\x60\xac\x72\x90\x86\xe2\xcc\x80\x6e\x82\x8a"
            b"\x84\x87\x7f\x1e\xb8\xe5\xd9\x74\xd8\x73\xe0\x65\x22\x49\x01\x55"
            b"\x5f\xb8\x82\x15\x90\xa3\x3b\xac\xc6\x1e\x39\x70\x1c\xf9\xb4\x6b"
            b"\xd2\x5b\xf5\xf0\x59\x5b\xbe\x24\x65\x51\x41\x43\x8e\x7a\x10\x0b"
        )

        self.assertTrue(key.verify(b"", sig_valid))

        sig_invalid = bytearray(sig_valid)
        sig_invalid[0] = 0xE0

        with self.assertRaises(ValueError):
            key.verify(b"", sig_invalid)


HYP_SETTINGS = dict()
if "--fast" in sys.argv:  # pragma: no cover
    HYP_SETTINGS["max_examples"] = 2
else:
    HYP_SETTINGS["max_examples"] = 10


@settings(**HYP_SETTINGS)
@example(1)
@example(5)  # smallest multiple that requires changing sign of x
@given(st.integers(min_value=1, max_value=int(generator_ed25519.order() - 1)))
def test_ed25519_encode_decode(multiple):
    a = generator_ed25519 * multiple

    b = PointEdwards.from_bytes(curve_ed25519, a.to_bytes())

    assert a == b


@settings(**HYP_SETTINGS)
@example(1)
@example(2)  # smallest multiple that requires changing the sign of x
@given(st.integers(min_value=1, max_value=int(generator_ed448.order() - 1)))
def test_ed448_encode_decode(multiple):
    a = generator_ed448 * multiple

    b = PointEdwards.from_bytes(curve_ed448, a.to_bytes())

    assert a == b


@settings(**HYP_SETTINGS)
@example(1)
@example(2)
@given(st.integers(min_value=1, max_value=int(generator_ed25519.order()) - 1))
def test_ed25519_mul_precompute_vs_naf(multiple):
    """Compare multiplication with and without precomputation."""
    g = generator_ed25519
    new_g = PointEdwards(curve_ed25519, g.x(), g.y(), 1, g.x() * g.y())

    assert g * multiple == multiple * new_g


# Test vectors from RFC 8032
TEST_VECTORS = [
    # TEST 1
    (
        generator_ed25519,
        "9d61b19deffd5a60ba844af492ec2cc4" "4449c5697b326919703bac031cae7f60",
        "d75a980182b10ab7d54bfed3c964073a" "0ee172f3daa62325af021a68f707511a",
        "",
        "e5564300c360ac729086e2cc806e828a"
        "84877f1eb8e5d974d873e06522490155"
        "5fb8821590a33bacc61e39701cf9b46b"
        "d25bf5f0595bbe24655141438e7a100b",
    ),
    # TEST 2
    (
        generator_ed25519,
        "4ccd089b28ff96da9db6c346ec114e0f" "5b8a319f35aba624da8cf6ed4fb8a6fb",
        "3d4017c3e843895a92b70aa74d1b7ebc" "9c982ccf2ec4968cc0cd55f12af4660c",
        "72",
        "92a009a9f0d4cab8720e820b5f642540"
        "a2b27b5416503f8fb3762223ebdb69da"
        "085ac1e43e15996e458f3613d0f11d8c"
        "387b2eaeb4302aeeb00d291612bb0c00",
    ),
    # TEST 3
    (
        generator_ed25519,
        "c5aa8df43f9f837bedb7442f31dcb7b1" "66d38535076f094b85ce3a2e0b4458f7",
        "fc51cd8e6218a1a38da47ed00230f058" "0816ed13ba3303ac5deb911548908025",
        "af82",
        "6291d657deec24024827e69c3abe01a3"
        "0ce548a284743a445e3680d7db5ac3ac"
        "18ff9b538d16f290ae67f760984dc659"
        "4a7c15e9716ed28dc027beceea1ec40a",
    ),
    # TEST 1024
    (
        generator_ed25519,
        "f5e5767cf153319517630f226876b86c" "8160cc583bc013744c6bf255f5cc0ee5",
        "278117fc144c72340f67d0f2316e8386" "ceffbf2b2428c9c51fef7c597f1d426e",
        "08b8b2b733424243760fe426a4b54908"
        "632110a66c2f6591eabd3345e3e4eb98"
        "fa6e264bf09efe12ee50f8f54e9f77b1"
        "e355f6c50544e23fb1433ddf73be84d8"
        "79de7c0046dc4996d9e773f4bc9efe57"
        "38829adb26c81b37c93a1b270b20329d"
        "658675fc6ea534e0810a4432826bf58c"
        "941efb65d57a338bbd2e26640f89ffbc"
        "1a858efcb8550ee3a5e1998bd177e93a"
        "7363c344fe6b199ee5d02e82d522c4fe"
        "ba15452f80288a821a579116ec6dad2b"
        "3b310da903401aa62100ab5d1a36553e"
        "06203b33890cc9b832f79ef80560ccb9"
        "a39ce767967ed628c6ad573cb116dbef"
        "efd75499da96bd68a8a97b928a8bbc10"
        "3b6621fcde2beca1231d206be6cd9ec7"
        "aff6f6c94fcd7204ed3455c68c83f4a4"
        "1da4af2b74ef5c53f1d8ac70bdcb7ed1"
        "85ce81bd84359d44254d95629e9855a9"
        "4a7c1958d1f8ada5d0532ed8a5aa3fb2"
        "d17ba70eb6248e594e1a2297acbbb39d"
        "502f1a8c6eb6f1ce22b3de1a1f40cc24"
        "554119a831a9aad6079cad88425de6bd"
        "e1a9187ebb6092cf67bf2b13fd65f270"
        "88d78b7e883c8759d2c4f5c65adb7553"
        "878ad575f9fad878e80a0c9ba63bcbcc"
        "2732e69485bbc9c90bfbd62481d9089b"
        "eccf80cfe2df16a2cf65bd92dd597b07"
        "07e0917af48bbb75fed413d238f5555a"
        "7a569d80c3414a8d0859dc65a46128ba"
        "b27af87a71314f318c782b23ebfe808b"
        "82b0ce26401d2e22f04d83d1255dc51a"
        "ddd3b75a2b1ae0784504df543af8969b"
        "e3ea7082ff7fc9888c144da2af58429e"
        "c96031dbcad3dad9af0dcbaaaf268cb8"
        "fcffead94f3c7ca495e056a9b47acdb7"
        "51fb73e666c6c655ade8297297d07ad1"
        "ba5e43f1bca32301651339e22904cc8c"
        "42f58c30c04aafdb038dda0847dd988d"
        "cda6f3bfd15c4b4c4525004aa06eeff8"
        "ca61783aacec57fb3d1f92b0fe2fd1a8"
        "5f6724517b65e614ad6808d6f6ee34df"
        "f7310fdc82aebfd904b01e1dc54b2927"
        "094b2db68d6f903b68401adebf5a7e08"
        "d78ff4ef5d63653a65040cf9bfd4aca7"
        "984a74d37145986780fc0b16ac451649"
        "de6188a7dbdf191f64b5fc5e2ab47b57"
        "f7f7276cd419c17a3ca8e1b939ae49e4"
        "88acba6b965610b5480109c8b17b80e1"
        "b7b750dfc7598d5d5011fd2dcc5600a3"
        "2ef5b52a1ecc820e308aa342721aac09"
        "43bf6686b64b2579376504ccc493d97e"
        "6aed3fb0f9cd71a43dd497f01f17c0e2"
        "cb3797aa2a2f256656168e6c496afc5f"
        "b93246f6b1116398a346f1a641f3b041"
        "e989f7914f90cc2c7fff357876e506b5"
        "0d334ba77c225bc307ba537152f3f161"
        "0e4eafe595f6d9d90d11faa933a15ef1"
        "369546868a7f3a45a96768d40fd9d034"
        "12c091c6315cf4fde7cb68606937380d"
        "b2eaaa707b4c4185c32eddcdd306705e"
        "4dc1ffc872eeee475a64dfac86aba41c"
        "0618983f8741c5ef68d3a101e8a3b8ca"
        "c60c905c15fc910840b94c00a0b9d0",
        "0aab4c900501b3e24d7cdf4663326a3a"
        "87df5e4843b2cbdb67cbf6e460fec350"
        "aa5371b1508f9f4528ecea23c436d94b"
        "5e8fcd4f681e30a6ac00a9704a188a03",
    ),
    # TEST SHA(abc)
    (
        generator_ed25519,
        "833fe62409237b9d62ec77587520911e" "9a759cec1d19755b7da901b96dca3d42",
        "ec172b93ad5e563bf4932c70e1245034" "c35467ef2efd4d64ebf819683467e2bf",
        "ddaf35a193617abacc417349ae204131"
        "12e6fa4e89a97ea20a9eeee64b55d39a"
        "2192992a274fc1a836ba3c23a3feebbd"
        "454d4423643ce80e2a9ac94fa54ca49f",
        "dc2a4459e7369633a52b1bf277839a00"
        "201009a3efbf3ecb69bea2186c26b589"
        "09351fc9ac90b3ecfdfbc7c66431e030"
        "3dca179c138ac17ad9bef1177331a704",
    ),
    # Blank
    (
        generator_ed448,
        "6c82a562cb808d10d632be89c8513ebf"
        "6c929f34ddfa8c9f63c9960ef6e348a3"
        "528c8a3fcc2f044e39a3fc5b94492f8f"
        "032e7549a20098f95b",
        "5fd7449b59b461fd2ce787ec616ad46a"
        "1da1342485a70e1f8a0ea75d80e96778"
        "edf124769b46c7061bd6783df1e50f6c"
        "d1fa1abeafe8256180",
        "",
        "533a37f6bbe457251f023c0d88f976ae"
        "2dfb504a843e34d2074fd823d41a591f"
        "2b233f034f628281f2fd7a22ddd47d78"
        "28c59bd0a21bfd3980ff0d2028d4b18a"
        "9df63e006c5d1c2d345b925d8dc00b41"
        "04852db99ac5c7cdda8530a113a0f4db"
        "b61149f05a7363268c71d95808ff2e65"
        "2600",
    ),
    # 1 octet
    (
        generator_ed448,
        "c4eab05d357007c632f3dbb48489924d"
        "552b08fe0c353a0d4a1f00acda2c463a"
        "fbea67c5e8d2877c5e3bc397a659949e"
        "f8021e954e0a12274e",
        "43ba28f430cdff456ae531545f7ecd0a"
        "c834a55d9358c0372bfa0c6c6798c086"
        "6aea01eb00742802b8438ea4cb82169c"
        "235160627b4c3a9480",
        "03",
        "26b8f91727bd62897af15e41eb43c377"
        "efb9c610d48f2335cb0bd0087810f435"
        "2541b143c4b981b7e18f62de8ccdf633"
        "fc1bf037ab7cd779805e0dbcc0aae1cb"
        "cee1afb2e027df36bc04dcecbf154336"
        "c19f0af7e0a6472905e799f1953d2a0f"
        "f3348ab21aa4adafd1d234441cf807c0"
        "3a00",
    ),
    # 11 octets
    (
        generator_ed448,
        "cd23d24f714274e744343237b93290f5"
        "11f6425f98e64459ff203e8985083ffd"
        "f60500553abc0e05cd02184bdb89c4cc"
        "d67e187951267eb328",
        "dcea9e78f35a1bf3499a831b10b86c90"
        "aac01cd84b67a0109b55a36e9328b1e3"
        "65fce161d71ce7131a543ea4cb5f7e9f"
        "1d8b00696447001400",
        "0c3e544074ec63b0265e0c",
        "1f0a8888ce25e8d458a21130879b840a"
        "9089d999aaba039eaf3e3afa090a09d3"
        "89dba82c4ff2ae8ac5cdfb7c55e94d5d"
        "961a29fe0109941e00b8dbdeea6d3b05"
        "1068df7254c0cdc129cbe62db2dc957d"
        "bb47b51fd3f213fb8698f064774250a5"
        "028961c9bf8ffd973fe5d5c206492b14"
        "0e00",
    ),
    # 12 octets
    (
        generator_ed448,
        "258cdd4ada32ed9c9ff54e63756ae582"
        "fb8fab2ac721f2c8e676a72768513d93"
        "9f63dddb55609133f29adf86ec9929dc"
        "cb52c1c5fd2ff7e21b",
        "3ba16da0c6f2cc1f30187740756f5e79"
        "8d6bc5fc015d7c63cc9510ee3fd44adc"
        "24d8e968b6e46e6f94d19b945361726b"
        "d75e149ef09817f580",
        "64a65f3cdedcdd66811e2915",
        "7eeeab7c4e50fb799b418ee5e3197ff6"
        "bf15d43a14c34389b59dd1a7b1b85b4a"
        "e90438aca634bea45e3a2695f1270f07"
        "fdcdf7c62b8efeaf00b45c2c96ba457e"
        "b1a8bf075a3db28e5c24f6b923ed4ad7"
        "47c3c9e03c7079efb87cb110d3a99861"
        "e72003cbae6d6b8b827e4e6c143064ff"
        "3c00",
    ),
    # 13 octets
    (
        generator_ed448,
        "7ef4e84544236752fbb56b8f31a23a10"
        "e42814f5f55ca037cdcc11c64c9a3b29"
        "49c1bb60700314611732a6c2fea98eeb"
        "c0266a11a93970100e",
        "b3da079b0aa493a5772029f0467baebe"
        "e5a8112d9d3a22532361da294f7bb381"
        "5c5dc59e176b4d9f381ca0938e13c6c0"
        "7b174be65dfa578e80",
        "64a65f3cdedcdd66811e2915e7",
        "6a12066f55331b6c22acd5d5bfc5d712"
        "28fbda80ae8dec26bdd306743c5027cb"
        "4890810c162c027468675ecf645a8317"
        "6c0d7323a2ccde2d80efe5a1268e8aca"
        "1d6fbc194d3f77c44986eb4ab4177919"
        "ad8bec33eb47bbb5fc6e28196fd1caf5"
        "6b4e7e0ba5519234d047155ac727a105"
        "3100",
    ),
    # 64 octets
    (
        generator_ed448,
        "d65df341ad13e008567688baedda8e9d"
        "cdc17dc024974ea5b4227b6530e339bf"
        "f21f99e68ca6968f3cca6dfe0fb9f4fa"
        "b4fa135d5542ea3f01",
        "df9705f58edbab802c7f8363cfe5560a"
        "b1c6132c20a9f1dd163483a26f8ac53a"
        "39d6808bf4a1dfbd261b099bb03b3fb5"
        "0906cb28bd8a081f00",
        "bd0f6a3747cd561bdddf4640a332461a"
        "4a30a12a434cd0bf40d766d9c6d458e5"
        "512204a30c17d1f50b5079631f64eb31"
        "12182da3005835461113718d1a5ef944",
        "554bc2480860b49eab8532d2a533b7d5"
        "78ef473eeb58c98bb2d0e1ce488a98b1"
        "8dfde9b9b90775e67f47d4a1c3482058"
        "efc9f40d2ca033a0801b63d45b3b722e"
        "f552bad3b4ccb667da350192b61c508c"
        "f7b6b5adadc2c8d9a446ef003fb05cba"
        "5f30e88e36ec2703b349ca229c267083"
        "3900",
    ),
    # 256 octets
    (
        generator_ed448,
        "2ec5fe3c17045abdb136a5e6a913e32a"
        "b75ae68b53d2fc149b77e504132d3756"
        "9b7e766ba74a19bd6162343a21c8590a"
        "a9cebca9014c636df5",
        "79756f014dcfe2079f5dd9e718be4171"
        "e2ef2486a08f25186f6bff43a9936b9b"
        "fe12402b08ae65798a3d81e22e9ec80e"
        "7690862ef3d4ed3a00",
        "15777532b0bdd0d1389f636c5f6b9ba7"
        "34c90af572877e2d272dd078aa1e567c"
        "fa80e12928bb542330e8409f31745041"
        "07ecd5efac61ae7504dabe2a602ede89"
        "e5cca6257a7c77e27a702b3ae39fc769"
        "fc54f2395ae6a1178cab4738e543072f"
        "c1c177fe71e92e25bf03e4ecb72f47b6"
        "4d0465aaea4c7fad372536c8ba516a60"
        "39c3c2a39f0e4d832be432dfa9a706a6"
        "e5c7e19f397964ca4258002f7c0541b5"
        "90316dbc5622b6b2a6fe7a4abffd9610"
        "5eca76ea7b98816af0748c10df048ce0"
        "12d901015a51f189f3888145c03650aa"
        "23ce894c3bd889e030d565071c59f409"
        "a9981b51878fd6fc110624dcbcde0bf7"
        "a69ccce38fabdf86f3bef6044819de11",
        "c650ddbb0601c19ca11439e1640dd931"
        "f43c518ea5bea70d3dcde5f4191fe53f"
        "00cf966546b72bcc7d58be2b9badef28"
        "743954e3a44a23f880e8d4f1cfce2d7a"
        "61452d26da05896f0a50da66a239a8a1"
        "88b6d825b3305ad77b73fbac0836ecc6"
        "0987fd08527c1a8e80d5823e65cafe2a"
        "3d00",
    ),
    # 1023 octets
    (
        generator_ed448,
        "872d093780f5d3730df7c212664b37b8"
        "a0f24f56810daa8382cd4fa3f77634ec"
        "44dc54f1c2ed9bea86fafb7632d8be19"
        "9ea165f5ad55dd9ce8",
        "a81b2e8a70a5ac94ffdbcc9badfc3feb"
        "0801f258578bb114ad44ece1ec0e799d"
        "a08effb81c5d685c0c56f64eecaef8cd"
        "f11cc38737838cf400",
        "6ddf802e1aae4986935f7f981ba3f035"
        "1d6273c0a0c22c9c0e8339168e675412"
        "a3debfaf435ed651558007db4384b650"
        "fcc07e3b586a27a4f7a00ac8a6fec2cd"
        "86ae4bf1570c41e6a40c931db27b2faa"
        "15a8cedd52cff7362c4e6e23daec0fbc"
        "3a79b6806e316efcc7b68119bf46bc76"
        "a26067a53f296dafdbdc11c77f7777e9"
        "72660cf4b6a9b369a6665f02e0cc9b6e"
        "dfad136b4fabe723d2813db3136cfde9"
        "b6d044322fee2947952e031b73ab5c60"
        "3349b307bdc27bc6cb8b8bbd7bd32321"
        "9b8033a581b59eadebb09b3c4f3d2277"
        "d4f0343624acc817804728b25ab79717"
        "2b4c5c21a22f9c7839d64300232eb66e"
        "53f31c723fa37fe387c7d3e50bdf9813"
        "a30e5bb12cf4cd930c40cfb4e1fc6225"
        "92a49588794494d56d24ea4b40c89fc0"
        "596cc9ebb961c8cb10adde976a5d602b"
        "1c3f85b9b9a001ed3c6a4d3b1437f520"
        "96cd1956d042a597d561a596ecd3d173"
        "5a8d570ea0ec27225a2c4aaff26306d1"
        "526c1af3ca6d9cf5a2c98f47e1c46db9"
        "a33234cfd4d81f2c98538a09ebe76998"
        "d0d8fd25997c7d255c6d66ece6fa56f1"
        "1144950f027795e653008f4bd7ca2dee"
        "85d8e90f3dc315130ce2a00375a318c7"
        "c3d97be2c8ce5b6db41a6254ff264fa6"
        "155baee3b0773c0f497c573f19bb4f42"
        "40281f0b1f4f7be857a4e59d416c06b4"
        "c50fa09e1810ddc6b1467baeac5a3668"
        "d11b6ecaa901440016f389f80acc4db9"
        "77025e7f5924388c7e340a732e554440"
        "e76570f8dd71b7d640b3450d1fd5f041"
        "0a18f9a3494f707c717b79b4bf75c984"
        "00b096b21653b5d217cf3565c9597456"
        "f70703497a078763829bc01bb1cbc8fa"
        "04eadc9a6e3f6699587a9e75c94e5bab"
        "0036e0b2e711392cff0047d0d6b05bd2"
        "a588bc109718954259f1d86678a579a3"
        "120f19cfb2963f177aeb70f2d4844826"
        "262e51b80271272068ef5b3856fa8535"
        "aa2a88b2d41f2a0e2fda7624c2850272"
        "ac4a2f561f8f2f7a318bfd5caf969614"
        "9e4ac824ad3460538fdc25421beec2cc"
        "6818162d06bbed0c40a387192349db67"
        "a118bada6cd5ab0140ee273204f628aa"
        "d1c135f770279a651e24d8c14d75a605"
        "9d76b96a6fd857def5e0b354b27ab937"
        "a5815d16b5fae407ff18222c6d1ed263"
        "be68c95f32d908bd895cd76207ae7264"
        "87567f9a67dad79abec316f683b17f2d"
        "02bf07e0ac8b5bc6162cf94697b3c27c"
        "d1fea49b27f23ba2901871962506520c"
        "392da8b6ad0d99f7013fbc06c2c17a56"
        "9500c8a7696481c1cd33e9b14e40b82e"
        "79a5f5db82571ba97bae3ad3e0479515"
        "bb0e2b0f3bfcd1fd33034efc6245eddd"
        "7ee2086ddae2600d8ca73e214e8c2b0b"
        "db2b047c6a464a562ed77b73d2d841c4"
        "b34973551257713b753632efba348169"
        "abc90a68f42611a40126d7cb21b58695"
        "568186f7e569d2ff0f9e745d0487dd2e"
        "b997cafc5abf9dd102e62ff66cba87",
        "e301345a41a39a4d72fff8df69c98075"
        "a0cc082b802fc9b2b6bc503f926b65bd"
        "df7f4c8f1cb49f6396afc8a70abe6d8a"
        "ef0db478d4c6b2970076c6a0484fe76d"
        "76b3a97625d79f1ce240e7c576750d29"
        "5528286f719b413de9ada3e8eb78ed57"
        "3603ce30d8bb761785dc30dbc320869e"
        "1a00",
    ),
]


@pytest.mark.parametrize(
    "generator,private_key,public_key,message,signature",
    TEST_VECTORS,
)
def test_vectors(generator, private_key, public_key, message, signature):
    private_key = a2b_hex(private_key)
    public_key = a2b_hex(public_key)
    message = a2b_hex(message)
    signature = a2b_hex(signature)

    sig_key = PrivateKey(generator, private_key)
    ver_key = PublicKey(generator, public_key)

    assert sig_key.public_key().public_key() == ver_key.public_key()

    gen_sig = sig_key.sign(message)

    assert gen_sig == signature

    assert ver_key.verify(message, signature)\n\n# From test_single_paper.py\n

# From test_supplementary_reproducible_science.py\n

# From test_microtype_validation_hardcore.py\n

# From test_glossary_acronym_index.py\n

# From test_ligature_checker.py\n

# From test_cli_simple.py\n

# From test_final_polishing_checklist.py\n

# From test_expect_prob_property.py\n

# From test_engine.py\n

# From test_basic.py\n

# From test_graphics_accessibility_hardcore.py\n

# From test_bibtex_perfectionist_integrated.py\n

# From test_orthography_grammar_hardcore.py\n

# From test_expect_prob.py\n

# From test_quotations_epigraphs_hardcore.py\n

# From test_config_schema_hardcore.py\n

# From test_math_canonical_hardcore.py\n

# From test_math_operator_declaration_hardcore.py\n

# From test_double_periods.py\n

# From test_theorem_proof_validation_hardcore.py\n

# From test_document_structure.py\n

# From test_accessibility_hardcore.py\n

# From test_hardcore_punctuation.py\n

# From test_preamble_analyzer_hardcore.py\n

# From test_nested_scripts.py\n

# From test_hardcore_property.py\n

# From test_double_periods_debug.py\n

# From test_nested_scripts_property.py\n

# From test_inclusive_language_hardcore.py\n

# From test_multilingual_hardcore.py\n

# From test_format_command.py\n

# From test_orchestrator.py\n

# From test_robust_rules_hardcore.py\n

# From test_double_periods_quote.py\n

# From test_math_semantic_ast_hardcore.py\n

# From test_color_contrast.py\n

# From test_bibliography_services_hardcore.py\n

# From test_structure_semantic.py\n

# From test_config_system.py\n

# From test_rule_orchestrator.py\n

# From test_ties.py\n

# From test_security_hardcore.py\n

# From test_bibliography_validator_hardcore.py\n

# From test_math_spacing_advanced_hardcore.py\n

# From test_bibliography_validator.py\n

# From test_docker_hardcore.py\n

# From test_gray_contrasts.py\n

# From test_typography_advanced_hardcore.py\n

# From test_git_hardcore.py\n

# From test_suite_diagnostics.py\n

# From test_dash_ranges_property.py\n

# From test_doc_structure.py\n

# From test_languagetool_service_hardcore.py\n

# From test_cli.py\n

# From test_init.py\n

# From test_dash_ranges.py\n

# From test_engine_integration.py\n

# From test_codemod_cli.py\n

# From test_ext_django.py\n

# From test_detect_config.py\n

# From test_supplementary_reproducible_science.py\n

# From test_comment.py\n

# From test_microtype_validation_hardcore.py\n

# From test_glossary_acronym_index.py\n

# From test_codegen_clean.py\n

# From test_contracts.py\n

# From test_release.py\n

# From test_type_alias.py\n

# From test_ifexp.py\n

# From test_fstring.py\n

# From test_ligature_checker.py\n

# From test_visitors.py\n

# From test_cli_simple.py\n

# From test_metadata_wrapper.py\n

# From test_while.py\n

# From test_gather_imports.py\n

# From test_registry.py\n

# From test_jsonschema.py\n

# From test_final_polishing_checklist.py\n

# From test_mutation.py\n

# From test_tabs.py\n

# From test_expect_prob_property.py\n

# From test_removal_behavior.py\n

# From test_file_path_provider.py\n

# From test_engine.py\n

# From test_span_provider.py\n

# From test_unnecessary_format_string.py\n

# From test_basic.py\n

# From test_utils.py\n

# From test_graphics_accessibility_hardcore.py\n

# From test_await.py\n

# From test_bibtex_perfectionist_integrated.py\n

# From test_connections.py\n

# From test_jacobi.py\n

# From test_list.py\n

# From test_arxiv_documents.py\n

# From test_unicode.py\n

# From test_retrieval.py\n

# From test_whitespace_parser.py\n

# From test_apply_type_annotations.py\n

# From test_rw_lock.py\n

# From test_sniffio.py\n

# From test_orthography_grammar_hardcore.py\n

# From test_full_repo_manager.py\n

# From test_remove_unused_imports.py\n

# From test_ecdsa.py\n

# From test_decorators.py\n

# From test_expect_prob.py\n

# From test_assign.py\n

# From test_misc.py\n

# From test_qrcode_pil.py\n

# From test_indented_block.py\n

# From test_base_provider.py\n

# From test_with.py\n

# From test_handlers.py\n

# From test_expression_context_provider.py\n

# From test_mutmut3.py\n

# From test_codemod.py\n

# From test_handlers_django.py\n

# From test_curves.py\n

# From test_matchers_with_metadata.py\n

# From test_type_enforce.py\n

# From test_convert_type_comments.py\n

# From test_accessor_provider.py\n

# From test_quotations_epigraphs_hardcore.py\n

# From test_cst_node.py\n

# From test_type_inference_provider.py\n

# From test_expression.py\n

# From test_docstring.py\n

# From test_config_schema_hardcore.py\n

# From test_subscript.py\n

# From test_math_canonical_hardcore.py\n

# From test_totp.py\n

# From test_module.py\n

# From test_unary_op.py\n

# From test_convert_format_to_fstring.py\n

# From test_real_world_documents.py\n

# From test_name_provider.py\n

# From test_ext_django_source.py\n

# From test_try.py\n

# From test_gather_unused_imports.py\n

# From test_posix.py\n

# From test_math_operator_declaration_hardcore.py\n

# From test_remove_imports.py\n

# From test_apps.py\n

# From test_double_periods.py\n

# From test_yield.py\n

# From test_theorem_proof_validation_hardcore.py\n

# From test_node_fields.py\n

# From test_handlers_argon2.py\n

# From test_gather_global_names.py\n

# From test_del.py\n

# From test_script.py\n

# From test_convert_union_to_or.py\n

# From test_document_structure.py\n

# From test_linux.py\n

# From test_node_identity.py\n

# From test_eddsa.py\n

# From test_handlers_scrypt.py\n

# From test_accessibility_hardcore.py\n

# From test_core.py\n

# From test_deprecations.py\n

# From test_keys.py\n

# From test_hardcore_punctuation.py\n

# From test_simple_string.py\n

# From test_preamble_analyzer_hardcore.py\n

# From test_comparison.py\n

# From test_return.py\n

# From test_nested_scripts.py\n

# From test_hardcore_property.py\n

# From test_metadata.py\n

# From test_double_periods_debug.py\n

# From test_sunos.py\n

# From test_exceptions.py\n

# From test_regex.py\n

# From test_nested_scripts_property.py\n

# From test_namedexpr.py\n

# From test_qrcode_svg.py\n

# From test_inclusive_language_hardcore.py\n

# From test_numbertheory.py\n

# From test_multilingual_hardcore.py\n

# From test_format_command.py\n

# From test_deep_replace.py\n

# From test_nonlocal.py\n

# From test_gather_string_annotation_names.py\n

# From test_rename_typing_generic_aliases.py\n

# From test_match.py\n

# From test_util.py\n

# From test_jsonschema_test_suite.py\n

# From test_gather_exports.py\n

# From test_scope_provider.py\n

# From test_orchestrator.py\n

# From test_roundtrip.py\n

# From test_for.py\n

# From test_convert_percent_format_to_fstring.py\n

# From test_else.py\n

# From test_e2e_result_snapshots.py\n

# From test_metadata_provider.py\n

# From test_parent_node_provider.py\n

# From test_binary_op.py\n

# From test_crypto_des.py\n

# From test_jsonschema_specifications.py\n

# From test_qrcode_pypng.py\n

# From test_version_compare.py\n

# From test_matchers.py\n

# From test_double_periods_quote.py\n

# From test_funcdef.py\n

# From test_aix.py\n

# From test_validators.py\n

# From test_import.py\n

# From test_parse_errors.py\n

# From test_ensure_import_present.py\n

# From test_math_semantic_ast_hardcore.py\n

# From test_flatten_behavior.py\n

# From test_process_all.py\n

# From test_color_contrast.py\n

# From test_attribute.py\n

# From test_process.py\n

# From test_noop.py\n

# From test_reentrant_codegen.py\n

# From test_bibliography_services_hardcore.py\n

# From test_handlers_bcrypt.py\n

# From test_batched_visitor.py\n

# From test_bsd.py\n

# From test_structure_semantic.py\n

# From test_config_system.py\n

# From test_system.py\n

# From test_runner.py\n

# From test_tuple.py\n

# From test_set.py\n

# From test_simple_comp.py\n

# From test_der.py\n

# From test_boolean_op.py\n

# From test_raise.py\n

# From test_convert_namedtuple_to_dataclass.py\n

# From test_ellipticcurve.py\n

# From test_wrapped_tokenize.py\n

# From test_simple_whitespace.py\n

# From test_handlers_pbkdf2.py\n

# From test_osx.py\n

# From test_ties.py\n

# From test_tokenize.py\n

# From test_dump_graphviz.py\n

# From test_add_trailing_commas.py\n

# From test_strip_strings_from_types.py\n

# From test_security_hardcore.py\n

# From test_config.py\n

# From test_utils_pbkdf2.py\n

# From test_bibliography_validator_hardcore.py\n

# From test_empty_line.py\n

# From test_visitor.py\n

# From test_gather_comments.py\n

# From test_crypto_digest.py\n

# From test_math_spacing_advanced_hardcore.py\n

# From test_bibliography_validator.py\n

# From test_global.py\n

# From test_docker_hardcore.py\n

# From test_paths.py\n

# From test_example.py\n

# From test_rename.py\n

# From test_sha3.py\n

# From test_context.py\n

# From test_dump_text.py\n

# From test_pyecdsa.py\n

# From test_memleaks.py\n

# From test_e2e.py\n

# From test_context_deprecated.py\n

# From test_crypto_scrypt.py\n

# From test_classdef.py\n

# From test_dict_comp.py\n

# From test_pwd.py\n

# From test_referencing_suite.py\n

# From test_add_slots.py\n

# From test_position_provider.py\n

# From test_gray_contrasts.py\n

# From test_typography_advanced_hardcore.py\n

# From test_git_hardcore.py\n

# From test_lambda.py\n

# From test_utils_md4.py\n

# From test_apache.py\n

# From test_trailing_whitespace.py\n

# From test_findall.py\n

# From test_extract.py\n

# From test_suite_diagnostics.py\n

# From test_handlers_cisco.py\n

# From test_if.py\n

# From test_dash_ranges_property.py\n

# From test_atom.py\n

# From test_number.py\n

# From test_leaf_small_statements.py\n

# From test_small_statement.py\n

# From test_ecdh.py\n

# From test_doc_structure.py\n

# From test_languagetool_service_hardcore.py\n

# From test_replace.py\n

# From test_utils_handlers.py\n

# From test_tools.py\n

# From test_cli.py\n

# From test_hosts.py\n

# From test_newline.py\n

# From test_call.py\n

# From test_windows.py\n

# From test_remove_pyre_directive.py\n

# From test_init.py\n

# From test_scripts.py\n

# From test_cases.py\n

# From test_crypto_builtin_md4.py\n

# From test_fuzz.py\n

# From test_add_pyre_directive.py\n

# From test_single_paper.py\n

# From test_matrix_multiply.py\n

# From test_deep_clone.py\n

# From test_dash_ranges.py\n

# From test_format.py\n

# From test_dict.py\n

# From test_malformed_sigs.py\n

# From test_assert.py\n

# From test_cli_version.py\n

# From test_add_imports.py\n

# From test_qrcode.py\n

# From test_types.py\n

# From test_footer_behavior.py\n

# From test_template.py\n

# From test_testutils.py\n

# From test_win32.py\n

# From test_simple_statement.py\n

# From test_arxiv_documents.py\n

# From test_real_world_documents.py\n

# From test_engine_integration.py\n

# From test_robust_rules_hardcore.py\n

# From test_rule_orchestrator.py\n

# From test_utils.py\n

# From test_jacobi.py\n

# From test_rw_lock.py\n

# From test_ecdsa.py\n

# From test_curves.py\n

# From test_eddsa.py\n

# From test_keys.py\n

# From test_numbertheory.py\n

# From test_der.py\n

# From test_ellipticcurve.py\n

# From test_sha3.py\n

# From test_pyecdsa.py\n

# From test_ecdh.py\n

# From test_malformed_sigs.py\n

# From test_cases.py\n

# From test_tools.py\n

# From test_mutation.py\n

# From test_mutmut3.py\n

# From test_regex.py\n

# From test_jsonschema.py\n

# From test_retrieval.py\n

# From test_core.py\n

# From test_exceptions.py\n

# From test_referencing_suite.py\n

# From test_e2e_result_snapshots.py\n

# From test_cli_version.py\n

# From test_tabs.py\n

# From test_type_enforce.py\n

# From test_exceptions.py\n

# From test_deep_replace.py\n

# From test_roundtrip.py\n

# From test_batched_visitor.py\n

# From test_visitor.py\n

# From test_e2e.py\n

# From test_add_slots.py\n

# From test_fuzz.py\n

# From test_deep_clone.py\n

# From test_comment.py\n

# From test_type_alias.py\n

# From test_ifexp.py\n

# From test_while.py\n

# From test_removal_behavior.py\n

# From test_await.py\n

# From test_list.py\n

# From test_assign.py\n

# From test_indented_block.py\n

# From test_with.py\n

# From test_cst_node.py\n

# From test_docstring.py\n

# From test_subscript.py\n

# From test_module.py\n

# From test_unary_op.py\n

# From test_try.py\n

# From test_yield.py\n

# From test_del.py\n

# From test_simple_string.py\n

# From test_comparison.py\n

# From test_return.py\n

# From test_namedexpr.py\n

# From test_nonlocal.py\n

# From test_match.py\n

# From test_for.py\n

# From test_else.py\n

# From test_binary_op.py\n

# From test_funcdef.py\n

# From test_import.py\n

# From test_flatten_behavior.py\n

# From test_attribute.py\n

# From test_tuple.py\n

# From test_set.py\n

# From test_simple_comp.py\n

# From test_boolean_op.py\n

# From test_raise.py\n

# From test_simple_whitespace.py\n

# From test_empty_line.py\n

# From test_global.py\n

# From test_classdef.py\n

# From test_dict_comp.py\n

# From test_lambda.py\n

# From test_trailing_whitespace.py\n

# From test_if.py\n

# From test_atom.py\n

# From test_number.py\n

# From test_leaf_small_statements.py\n

# From test_small_statement.py\n

# From test_newline.py\n

# From test_call.py\n

# From test_matrix_multiply.py\n

# From test_dict.py\n

# From test_assert.py\n

# From test_simple_statement.py\n

# From test_codegen_clean.py\n

# From test_detect_config.py\n

# From test_whitespace_parser.py\n

# From test_node_identity.py\n

# From test_version_compare.py\n

# From test_parse_errors.py\n

# From test_wrapped_tokenize.py\n

# From test_config.py\n

# From test_footer_behavior.py\n

# From test_config.py\n

# From test_fstring.py\n

# From test_utils.py\n

# From test_tokenize.py\n

# From test_dump_graphviz.py\n

# From test_dump_text.py\n

# From test_visitors.py\n

# From test_decorators.py\n

# From test_matchers_with_metadata.py\n

# From test_matchers.py\n

# From test_findall.py\n

# From test_extract.py\n

# From test_replace.py\n

# From test_metadata_wrapper.py\n

# From test_file_path_provider.py\n

# From test_span_provider.py\n

# From test_full_repo_manager.py\n

# From test_base_provider.py\n

# From test_expression_context_provider.py\n

# From test_accessor_provider.py\n

# From test_type_inference_provider.py\n

# From test_name_provider.py\n

# From test_scope_provider.py\n

# From test_metadata_provider.py\n

# From test_parent_node_provider.py\n

# From test_reentrant_codegen.py\n

# From test_position_provider.py\n

# From test_expression.py\n

# From test_module.py\n

# From test_node_fields.py\n

# From test_paths.py\n

# From test_template.py\n

# From test_codemod_cli.py\n

# From test_codemod.py\n

# From test_metadata.py\n

# From test_runner.py\n

# From test_gather_imports.py\n

# From test_apply_type_annotations.py\n

# From test_gather_unused_imports.py\n

# From test_remove_imports.py\n

# From test_gather_global_names.py\n

# From test_gather_string_annotation_names.py\n

# From test_gather_exports.py\n

# From test_gather_comments.py\n

# From test_add_imports.py\n

# From test_unnecessary_format_string.py\n

# From test_remove_unused_imports.py\n

# From test_convert_type_comments.py\n

# From test_convert_format_to_fstring.py\n

# From test_convert_union_to_or.py\n

# From test_rename_typing_generic_aliases.py\n

# From test_convert_percent_format_to_fstring.py\n

# From test_ensure_import_present.py\n

# From test_noop.py\n

# From test_convert_namedtuple_to_dataclass.py\n

# From test_add_trailing_commas.py\n

# From test_strip_strings_from_types.py\n

# From test_rename.py\n

# From test_remove_pyre_directive.py\n

# From test_add_pyre_directive.py\n

# From test_release.py\n

# From test_qrcode_pil.py\n

# From test_script.py\n

# From test_qrcode_svg.py\n

# From test_util.py\n

# From test_qrcode_pypng.py\n

# From test_example.py\n

# From test_qrcode.py\n

# From test_sniffio.py\n

# From test_utils.py\n

# From test_deprecations.py\n

# From test_exceptions.py\n

# From test_jsonschema_test_suite.py\n

# From test_validators.py\n

# From test_cli.py\n

# From test_format.py\n

# From test_types.py\n

# From test_jsonschema_specifications.py\n

# From test_contracts.py\n

# From test_connections.py\n

# From test_unicode.py\n

# From test_misc.py\n

# From test_posix.py\n

# From test_linux.py\n

# From test_sunos.py\n

# From test_aix.py\n

# From test_process_all.py\n

# From test_process.py\n

# From test_bsd.py\n

# From test_system.py\n

# From test_osx.py\n

# From test_memleaks.py\n

# From test_windows.py\n

# From test_scripts.py\n

# From test_testutils.py\n

# From test_ext_django.py\n

# From test_registry.py\n

# From test_utils.py\n

# From test_handlers.py\n

# From test_handlers_django.py\n

# From test_totp.py\n

# From test_ext_django_source.py\n

# From test_apps.py\n

# From test_handlers_argon2.py\n

# From test_handlers_scrypt.py\n

# From test_crypto_des.py\n

# From test_handlers_bcrypt.py\n

# From test_handlers_pbkdf2.py\n

# From test_utils_pbkdf2.py\n

# From test_crypto_digest.py\n

# From test_context.py\n

# From test_context_deprecated.py\n

# From test_crypto_scrypt.py\n

# From test_pwd.py\n

# From test_utils_md4.py\n

# From test_apache.py\n

# From test_handlers_cisco.py\n

# From test_utils_handlers.py\n

# From test_hosts.py\n

# From test_crypto_builtin_md4.py\n

# From test_win32.py\n

# From test_runner.py\n\n